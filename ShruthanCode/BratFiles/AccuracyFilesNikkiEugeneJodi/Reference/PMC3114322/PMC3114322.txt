Guidelines and Recommendations for Laboratory Analysis in the Diagnosis and Management of Diabetes Mellitus

Abstract

BACKGROUND

Multiple laboratory tests are used to diagnose and manage patients with diabetes mellitus. The quality of the scientific evidence supporting the use of these tests varies substantially.

APPROACH

An expert committee compiled evidence-based recommendations for the use of laboratory testing for patients with diabetes. A new system was developed to grade the overall quality of the evidence and the strength of the recommendations. Draft guidelines were posted on the Internet and presented at the 2007 Arnold O. Beckman Conference. The document was modified in response to oral and written comments, and a revised draft was posted in 2010 and again modified in response to written comments. The National Academy of Clinical Biochemistry and the Evidence-Based Laboratory Medicine Committee of the American Association for Clinical Chemistry jointly reviewed the guidelines, which were accepted after revisions by the Professional Practice Committee and subsequently approved by the Executive Committee of the American Diabetes Association.

CONTENT

In addition to long-standing criteria based on measurement of plasma glucose, diabetes can be diagnosed by demonstrating increased blood hemoglobin A  (HbA ) concentrations. Monitoring of glycemic control is performed by self-monitoring of plasma or blood glucose with meters and by laboratory analysis of HbA . The potential roles of noninvasive glucose monitoring, genetic testing, and measurement of autoantibodies, urine albumin, insulin, proinsulin, C-peptide, and other analytes are addressed.

SUMMARY

The guidelines provide specific recommendations that are based on published data or derived from expert consensus. Several analytes have minimal clinical value at present, and their measurement is not recommended.

Diabetes mellitus is a group of metabolic disorders of carbohydrate metabolism in which glucose is underutilized and overproduced, causing hyperglycemia. The disease is classified into several categories. The revised classification, published in 1997 (1), is presented in Table 1. Type 1 diabetes mellitus, formerly known as insulin-dependent diabetes mellitus (IDDM) or juvenile-onset diabetes mellitus, is usually caused by autoimmune destruction of the pancreatic islet β-cells, rendering the pancreas unable to synthesize and secrete insulin (2). Type 2 diabetes mellitus, formerly known as non-IDDM or adult-onset diabetes, is caused by a combination of insulin resistance and inadequate insulin secretion (3,4). Gestational diabetes mellitus (GDM), which resembles type 2 diabetes more than type 1, develops during approximately 7% (range, 5%–15%) of pregnancies, usually remits after delivery, and constitutes a major risk factor for the development of type 2 diabetes later in life. Other types of diabetes are rare. Type 2 is the most common form, accounting for 85%–95% of diabetes in developed countries. Some patients cannot be clearly classified as type 1 or type 2 diabetes (5).

 Classification of diabetes mellitusa  From the ADA (378). 

Diabetes is a common disease. The current worldwide prevalence is estimated to be approximately 250 x 106, and it is expected to reach 380 x 106 by 2025 (6). The prevalence of diabetes [based on fasting plasma glucose (FPG) results] in U.S. adults in 1999–2002 was 9.3%, of which 30% of the cases were undiagnosed (7). The most recent data, which were derived from the 2005–2006 National Health and Nutrition Examination Survey (NHANES) with both FPG and 2-h oral glucose tolerance test (OGTT) results, show a prevalence of diabetes in U.S. persons ≥20 years old of 12.9% (approximately 40 x 106) (8). Of these individuals, 40% (approximately 16 million) are undiagnosed. The prevalence of diabetes has also increased in other parts of the world. For example, recent estimates suggest 110 x 106 diabetic individuals in Asia in 2007 (9), but the true number is likely to be substantially greater, because China alone was thought to have 92.4 x 106 adults with diabetes in 2008 (10).

The worldwide costs of diabetes were approximately $232 billion in 2007 and are likely to be $302 billion by 2025 (6). In 2007, the costs of diabetes in the U.S. were estimated to be $174 billion (11). The mean annual per capita healthcare costs for an individual with diabetes are approximately 2.3-fold higher than those for individuals who do not have diabetes (11). Similarly, diabetes in the U.K. accounts for roughly 10% of the National Health Service budget (equivalent in 2008 to £9 billion/year). The high costs of diabetes are attributable to care for both acute conditions (such as hypoglycemia and ketoacidosis) and debilitating complications (12). The latter include both microvascular complications—predominantly retinopathy, nephropathy, and neuropathy—and macrovascular complications, particularly stroke and coronary artery disease. Together, they make diabetes the fourth most common cause of death in the developed world (13). About 3.8 x 106 people worldwide were estimated to have died from diabetes-related causes in 2007 (6).

The National Academy of Clinical Biochemistry (NACB) issued its “Guidelines and Recommendations for Laboratory Analysis in the Diagnosis and Management of Diabetes Mellitus” in 2002 (14). These recommendations were reviewed and updated with an evidence-based approach, especially in key areas in which new evidence has emerged since the 2002 publication. The process of updating guideline recommendations followed the standard operating procedures for preparing, publishing, and editing NACB laboratory medicine practice guidelines, and the key steps are detailed in the Supplementary Data that accompanies this special report. A new system was developed to grade both the overall quality of the evidence (Table 2) and the strength of recommendations (Table 3).

 Rating scale for the quality of evidence  

 Grading the strength of recommendations  

This guideline focuses primarily on the laboratory aspects of testing in diabetes. It does not address any issues related to the clinical management of diabetes, which are already covered in the American Diabetes Association (ADA) guidelines. The NACB guideline intends to supplement the ADA guidelines in order to avoid duplication or repetition of information. Therefore, it focuses on practical aspects of care to assist with decisions related to the use or interpretation of laboratory tests while screening, diagnosing, or monitoring patients with diabetes. Additional details concerning the scope, purpose, key topics, and targets of this guideline are described in the accompanying Supplementary Data.

To facilitate comprehension and assist the reader, we divide each analyte into several headings and subheadings (in parentheses), which are as follows: use (diagnosis, screening, monitoring, and prognosis); rationale (diagnosis and screening); analytical considerations (preanalytical, including reference intervals; and analytical, such as methods); interpretation (including frequency of measurement and turnaround time); and, where applicable, emerging considerations, which alert the reader to ongoing studies and potential future aspects relevant to that analyte.

GLUCOSE

1. Use

RECOMMENDATION: WHEN GLUCOSE IS USED TO ESTABLISH THE DIAGNOSIS OF DIABETES, IT SHOULD BE MEASURED IN VENOUS PLASMA A (high). RECOMMENDATION: WHEN GLUCOSE IS USED FOR SCREENING OF HIGH-RISK INDIVIDUALS, IT SHOULD BE MEASURED IN VENOUS PLASMA B (moderate). RECOMMENDATION: PLASMA GLUCOSE SHOULD BE MEASURED IN AN ACCREDITED LABORATORY WHEN USED FOR DIAGNOSIS OF OR SCREENING FOR DIABETES Good Practice Point (GPP). RECOMMENDATION: OUTCOME STUDIES ARE NEEDED TO DETERMINE THE EFFECTIVENESS OF SCREENING C (moderate). 

A. Diagnosis/screening.

The diagnosis of diabetes is established by identifying the presence of hyperglycemia. For many years the only method recommended for diagnosis was a direct demonstration of hyperglycemia by measuring increased glucose concentrations in the plasma (15,16). In 1979, a set of criteria based on the distribution of glucose concentrations in high-risk populations was established to standardize the diagnosis (15). These recommendations were endorsed by the WHO (16). In 1997, the diagnostic criteria were modified (1) to better identify individuals at risk of retinopathy and nephropathy (17,18). The revised criteria comprised: 1) an FPG value ≥7.0 mmol/L (126 mg/dL); 2) a 2-h postload glucose concentration ≥11.1 mmol/L (200 mg/dL) during an OGTT; or 3) symptoms of diabetes and a casual (i.e., regardless of the time of the preceding meal) plasma glucose concentration ≥11.1 mmol/L (200 mg/dL) (Table 4) (1). If any one of these three criteria is met, confirmation by repeat testing on a subsequent day is necessary to establish the diagnosis [note that repeat testing is not required for patients who have unequivocal hyperglycemia, i.e., >11.1 mmol/L (200 mg/dL) with symptoms consistent with hyperglycemia]. The WHO and the International Diabetes Federation (IDF) recommend either an FPG test or a 2-h postload glucose test that uses the same cutoffs as the ADA (19) (Table 5). In 2009, the International Expert Committee (20), which comprised members appointed by the ADA, the European Association for the Study of Diabetes, and the IDF, recommended that diabetes be diagnosed by measurement of hemoglobin A  (HbA ), which reflects long-term blood glucose concentrations (see HbA  section below). The ADA (21) and the WHO have endorsed the use of HbA  for diagnosis of diabetes.

Testing to detect type 2 diabetes in asymptomatic people, previously controversial, is now recommended for those at risk of developing the disease (21,22). The ADA proposes that all asymptomatic people ≥45 years of age be screened in a healthcare setting. An HbA , FPG, or 2-h OGTT evaluation is appropriate for screening (21). The IDF recommends that the health service in each country decide whether to implement screening for diabetes (23). FPG is the suggested test. In contrast, the International Expert Committee and the ADA have recommended that HbA  can be used for screening for diabetes (20,21,24) (see section on HbA  below). If an FPG result is <5.6 mmol/L (100 mg/dL) and/or a 2-h plasma glucose concentration is <7.8 mmol/L (140 mg/dL), testing should be repeated at 3-year intervals. Screening should be considered at a younger age or be carried out more frequently in individuals who are overweight (BMI ≥25 kg/m2) or obese and who have a least one additional risk factor for diabetes [see (21) for conditions associated with increased risk]. Because of the increasing prevalence of type 2 diabetes in children, screening of children is now advocated (25). Starting at age 10 years (or at the onset of puberty if puberty occurs at a younger age), testing should be performed every 3 years in overweight individuals who have two other risk factors—namely, family history, a race/ethnicity recognized to increase risk, signs of insulin resistance, and a maternal history of diabetes or GDM during the child's gestation (25). Despite these recommendations and the demonstration that interventions can delay and sometimes prevent the onset of type 2 diabetes in individuals with impaired glucose tolerance (26,27), there is as yet no published evidence that treatment based on screening has an effect on long-term complications. In addition, the published literature lacks consensus as to which screening procedure (FPG, OGTT, and/or HbA ) is the most appropriate (20,28–30). On the basis of an evaluation of NHANES III data, a strategy has been proposed to use FPG to screen whites ≥40 years and other populations ≥30 years of age (31). The cost-effectiveness of screening for type 2 diabetes has been estimated. The incremental cost of screening all persons ≥25 years of age has been estimated to be $236,449 per life-year gained and $56,649 per quality-adjusted life-year (QALY) gained (32). Interestingly, screening was more cost-effective at ages younger than the 45 years currently recommended. In contrast, screening targeted to individuals with hypertension reduces the QALY from $360,966 to $34,375, with ages between 55 and 75 years being the most cost-effective (33). Modeling run on 1 x 106 individuals suggests considerable uncertainty as to whether screening for diabetes would be cost-effective (34). By contrast, the results of a more recent modeling study imply that screening commencing at 30 or 45 years is highly cost-effective (<$11,000 per QALY gained) (35). Long-term outcome studies are necessary to provide evidence to resolve the question of the efficacy of diabetes screening (36).

In 2003, the ADA lowered the threshold for “normal” FPG from <6.1 mmol/L (110 mg/dL) to <5.6 mmol/L (100 mg/dL) (37). This change has been contentious and has not been accepted by all organizations (19,38). The rationale is based on data that individuals with FPG values between 5.6 mmol/L (100 mg/dL) and 6.05 mmol/L (109 mg/dL) are at increased risk for developing type 2 diabetes (39,40). More-recent evidence indicates that FPG concentrations even lower than 5.6 mmol/L (100 mg/dL) are associated with a graded risk for type 2 diabetes (41). Data were obtained from 13,163 men between 26 and 45 years of age who had FPG values <5.55 mmol/L (100 mg/dL) and were followed for a mean of 5.7 years. Men with FPG values of 4.83–5.05 mmol/L (87–91 mg/dL) have a significantly increased risk of type 2 diabetes, compared with men with FPG values <4.5 mmol/L (81 mg/dL). Although the prevalence of diabetes is low at these glucose concentrations, the data support the concept of a continuum between FPG and the risk of diabetes.

RECOMMENDATION: ROUTINE MEASUREMENT OF PLASMA GLUCOSE CONCENTRATIONS IN AN ACCREDITED LABORATORY IS NOT RECOMMENDED AS THE PRIMARY MEANS OF MONITORING OR EVALUATING THERAPY IN INDIVIDUALS WITH DIABETES B (low). 

B. Monitoring/prognosis.

There is a direct relationship between the degree of chronic plasma glucose control and the risk of late renal, retinal, and neurologic complications. This correlation has been documented in epidemiologic studies and clinical trials for both type 1 (42) and type 2 (43) diabetes. The important causal role of hyperglycemia in the development and progression of complications has been documented in clinical trials. Persons with type 1 diabetes who maintain lower mean plasma glucose concentrations exhibit a significantly lower incidence of microvascular complications—namely, diabetic retinopathy, nephropathy, and neuropathy (44). Although intensive insulin therapy reduced hypercholesterolemia by 34%, the risk of macrovascular disease was not significantly decreased in the original analysis (44). Longer follow-up documented a significant reduction in cardiovascular disease in patients with type 1 diabetes treated with intensive glycemic control (45). The effects of tight glycemic control on microvascular complications in patients with type 2 diabetes (46) are similar to those with type 1 diabetes, given the differences in glycemia achieved between the active-intervention and control groups in the various trials. Intensive plasma glucose control significantly reduced microvascular complications in patients with type 2 diabetes. Although meta-analyses have suggested that intensive glycemic control reduces cardiovascular disease in individuals with type 2 diabetes (47,48), clinical trials have not consistently demonstrated a reduction in macrovascular disease (myocardial infarction or stroke) with intensive therapy aimed at lowering glucose concentrations in type 2 diabetes. Long-term follow-up of the United Kingdom Prospective Diabetes Study (UKPDS) population supported a benefit of intensive therapy on macrovascular disease (49), but three other recent trials failed to demonstrate a significant difference in macrovascular disease outcomes between very intensive treatment strategies, which achieved HbA  concentrations of approximately 6.5% (48 mmol/mol), and the control groups, which had HbA  concentrations 0.8%–1.1% higher (50–52). One study even observed higher cardiovascular mortality in the intensive-treatment arm (50). In both the Diabetes Control and Complications Trial (DCCT) and the UKPDS, patients in the intensive-treatment group maintained lower median plasma glucose concentrations; however, analyses of the outcomes were linked to HbA , which was used to evaluate glycemic control, rather than glucose concentration. Moreover, most clinicians use the recommendations of the ADA and other organizations, which define a target HbA  concentration as the goal for optimum glycemic control (21,53).

Neither random nor fasting glucose concentrations should be measured in an accredited laboratory as the primary means of routine outpatient monitoring of patients with diabetes. Laboratory plasma glucose testing can be used to supplement information from other testing, to test the accuracy of self-monitoring (see below), or to adjust the dosage of oral hypoglycemic agents (22,54). In addition, individuals with well-controlled type 2 diabetes who are not on insulin therapy can be monitored with periodic measurement of the FPG concentration, although analysis need not be done in an accredited laboratory (54,55).

2. Rationale

A. Diagnosis.

The disordered carbohydrate metabolism that underlies diabetes manifests as hyperglycemia. Therefore, measurement of either plasma glucose or HbA  is the diagnostic criterion. This strategy is indirect, because hyperglycemia reflects the consequence of the metabolic derangement, not the cause; however, until the underlying molecular pathophysiology of the disease is identified, measurement of glycemia is likely to remain an essential diagnostic modality.

B. Screening.

Screening is recommended for several reasons. The onset of type 2 diabetes is estimated to occur approximately 4–7 years (or more) before clinical diagnosis (56), and epidemiologic evidence indicates that complications may begin several years before clinical diagnosis. Furthermore, it is estimated that 40% of people in the U.S. with type 2 diabetes are undiagnosed (8). Notwithstanding this recommendation, there is no published evidence that population screening for hyperglycemia provides any long-term benefit. Outcome studies examining the potential long-term benefits of screening are ongoing.

3. Analytical considerations

RECOMMENDATION: BLOOD FOR FPG ANALYSIS SHOULD BE DRAWN IN THE MORNING AFTER THE INDIVIDUAL HAS FASTED OVERNIGHT (AT LEAST 8 h) B (low). RECOMMENDATION: TO MINIMIZE GLYCOLYSIS, ONE SHOULD PLACE THE SAMPLE TUBE IMMEDIATELY IN AN ICE–WATER SLURRY, AND THE PLASMA SHOULD BE SEPARATED FROM THE CELLS WITHIN 30 MIN. IF THAT CANNOT BE ACHIEVED, A TUBE CONTAINING A RAPIDLY EFFECTIVE GLYCOLYSIS INHIBITOR, SUCH AS CITRATE BUFFER, SHOULD BE USED FOR COLLECTING THE SAMPLE. TUBES WITH ONLY ENOLASE INHIBITORS, SUCH AS SODIUM FLUORIDE, SHOULD NOT BE RELIED ON TO PREVENT GLYCOLYSIS B (moderate). 

A. Preanalytical.

Blood should be drawn in the morning after an overnight fast (no caloric intake for at least 8 h), during which time the individual may consume water ad libitum (1). Published evidence reveals diurnal variation in FPG, with the mean FPG being higher in the morning than in the afternoon, indicating that many diabetes cases would be missed in patients seen in the afternoon (57).

Loss of glucose from sample containers is a serious and underappreciated problem (58). Decreases in glucose concentrations in whole blood ex vivo are due to glycolysis. The rate of glycolysis—reported to average 5%–7%/h [approximately 0.6 mmol/L (10 mg/dL)] (59)—varies with the glucose concentration, temperature, leukocyte count, and other factors (60). Such decreases in glucose concentration will lead to missed diabetes diagnoses in the large proportion of the population who have glucose concentrations near the cut points for diagnosis of diabetes.

The commonly used glycolysis inhibitors are unable to prevent short-term glycolysis. Glycolysis can be attenuated by inhibiting enolase with sodium fluoride (2.5 mg/mL of blood) or, less commonly, lithium iodoacetate (0.5 mg/mL of blood). These reagents can be used alone or, more commonly, with such anticoagulants as potassium oxalate, EDTA, citrate, or lithium heparin. Unfortunately, although fluoride helps to maintain long-term glucose stability, the rates of decline in the glucose concentration in the first hour after sample collection are virtually identical for tubes with and without fluoride, and glycolysis continues for up to 4 h in samples containing fluoride (59). After 4 h, the concentration of glucose in whole blood in the presence of fluoride remains stable for 72 h at room temperature (59) (leukocytosis will increase glycolysis even in the presence of fluoride if the leukocyte count is very high).

Few effective and practical methods are available for prompt stabilization of glucose in whole-blood samples. Loss of glucose can be minimized in two classic ways: 1) immediate separation of plasma from blood cells after blood collection [the glucose concentration is stable for 8 h at 25°C and 72 h at 4°C in separated, nonhemolyzed, sterile serum without fluoride (61)]; and 2) placing the blood tube in an ice–water slurry immediately after blood collection and separating the plasma from the cells within 30 min (19,62). These methods are not always practical and are not widely used.

A recent study showed that acidification of blood with citrate buffer inhibits in vitro glycolysis far more effectively than fluoride (62). The mean glucose concentration in samples stored at 37°C decreased by only 0.3% at 2 h and 1.2% at 24 h when blood was drawn into tubes containing citrate buffer, sodium fluoride, and EDTA. The use of these blood-collection tubes, where they are available, appears to offer a practical solution to the glycolysis problem.

Glucose can be measured in whole blood, serum, or plasma, but plasma is recommended for diagnosis [note that although both the ADA and WHO recommend venous plasma, the WHO also accepts measurement of glucose in capillary blood (19,21)]. The molality of glucose (i.e., the amount of glucose per unit water mass) in whole blood is identical to that in plasma. Although erythrocytes are essentially freely permeable to glucose (glucose is taken up by facilitated transport), the concentration of water (in kilograms per liter) in plasma is approximately 11% higher than in whole blood. Therefore, glucose concentrations are approximately 11% higher in plasma than in whole blood if the hematocrit is normal. Glucose concentrations in heparinized plasma were reported in 1974 to be 5% lower than in serum (63). The reasons for the difference are not apparent but have been attributed to the shift in fluid from erythrocytes to plasma caused by anticoagulants. In contrast, some more recent studies found that glucose concentrations are slightly higher in plasma than in serum. The observed differences were approximately 0.2 mmol/L (3.6 mg/dL) (64), or approximately 2% (65), or 0.9% (62). Other studies have found that glucose values measured in serum and plasma are essentially the same (66,67). Given these findings, it is unlikely that values for plasma and serum glucose will be substantially different when glucose is assayed with current instruments, and any differences will be small compared with the day-to-day biological variation of glucose. Clinical organizations do not recommend the measurement of glucose in serum (rather than plasma) for the diagnosis of diabetes (19,21). Use of plasma allows samples to be centrifuged promptly to prevent glycolysis without waiting for the blood to clot. The glucose concentrations in capillary blood obtained during an OGTT are significantly higher than those in venous blood [mean, 1.7 mmol/L (30 mg/dL), which is equivalent to 20%–25% higher (68)], probably owing to glucose consumption in the tissues. In contrast, the mean difference in fasting samples is only 0.1 mmol/L (2 mg/dL) (68,69).

Reference intervals.

Glucose concentrations vary with age in healthy individuals. The reference interval for children is 3.3–5.6 mmol/L (60–100 mg/dL), which is similar to the adult interval of 4.1–6.1 mmol/L (74–110 mg/dL) (70). Note that the ADA and WHO criteria (19,21), not the reference intervals, are used for the diagnosis of diabetes. Moreover, the threshold for the diagnosis of hypoglycemia is variable. Reference intervals are not useful for diagnosing these conditions. In adults, the mean FPG concentration increases with increasing age from the third to the sixth decade (71) but does not increase significantly after 60 years of age (72,73). By contrast, glucose concentrations after a glucose challenge are substantially higher in older individuals (72,73). The evidence for an association between increasing insulin resistance and age is inconsistent (74). Aging appears to influence glucose homeostasis, and visceral obesity seems to be responsible for the reported continuous decrease in glucose tolerance that begins in middle age (75).

B. Analytical.

Glucose is measured almost exclusively by enzymatic methods. An analysis of proficiency surveys conducted by the College of American Pathologists (CAP) reveals that hexokinase or glucose oxidase is used in virtually all analyses performed in the U.S. (70). A very few laboratories (<1%) use glucose dehydrogenase. Enzymatic methods for glucose analysis are relatively well standardized. At a plasma glucose concentration of approximately 7.5 mmol/L (135 mg/dL), the imprecision (CV) among laboratories that used the same method was ≤2.6% (70). Similar findings have been reported for glucose analyses of samples from patients. The method of glucose measurement does not influence the result. A comparison of results from approximately 6,000 clinical laboratories reveals that the mean glucose concentrations measured in serum samples by the hexokinase and glucose oxidase methods are essentially the same (76). Compared with a reference measurement procedure, significant bias (P < 0.001) was observed for 40.6% of the peer groups (76). If similar biases occur with plasma, patients near the diagnostic threshold could be misclassified.

No consensus has been achieved on the goals for glucose analysis. Numerous criteria have been proposed to establish analytical goals. These criteria include expert opinion (consensus conferences), the opinion of clinicians, regulation, the state of the art, and biological variation (77). A rational and realistic recommendation that has received some support is to use biological criteria as the basis for analytical goals. It has been suggested that imprecision should not exceed one-half of the within-individual biological CV (78,79). For plasma glucose, a CV ≤2.2% has been suggested as a target for imprecision, with a 0% bias (79). Although this recommendation was proposed for within-laboratory error, it would be desirable to achieve this goal for interlaboratory imprecision to minimize differences among laboratories in the diagnosis of diabetes in individuals with glucose concentrations close to the threshold value. Therefore, the goal for glucose analysis should be to minimize total analytical error, and methods should be without measurable bias. A national or international program that uses commutable samples (e.g., fresh frozen plasma) to eliminate matrix effects and has accuracy-based grading with values derived with a reference measurement procedure should be developed to assist in achieving this objective.

4. Interpretation

Despite the low analytical imprecision at the diagnostic decision limits of 7.0 mmol/L (126 mg/dL) and 11.1 mmol/L (200 mg/dL), classification errors may occur. Knowledge of intraindividual (within-person) variation in FPG concentrations is essential for meaningful interpretation of patient values (although total biological variation includes within-person and between-person variation, most discussions focus on the within-person variation). An early study, which repeated the OGTT in 31 nondiabetic adults at a 48-h interval, revealed that the FPG concentration varied between the 2 values by <10% in 22 participants (77%) and by <20% in 30 participants (97%) (80). A careful evaluation of healthy individuals over several consecutive days revealed that the biological variation in FPG [mean glucose, 4.9 mmol/L (88 mg/dL)] exhibited within- and between-individual CVs of 4.8%–6.1% and 7.5%–7.8%, respectively (81–83). Larger studies have revealed intraindividual CVs of 4.8% and 7.1% for FPG in 246 healthy individuals and 80 previously undiagnosed individuals with diabetes, respectively (83). Similar findings were obtained from an analysis of 685 adults from NHANES III, in which the mean within-person variation in FPG measured 2–4 weeks apart was 5.7% (95% CI, 5.3%–6.1%) (84). An analysis of larger numbers of individuals from the same NHANES III database yielded within- and between-person CVs of 8.3% and 12.5%, respectively, at a glucose concentration of approximately 5.1 mmol/L (92 mg/dL) (85). If a within-person biological CV of 5.7% is applied to a true glucose concentration of 7.0 mmol/L (126 mg/dL), the 95% CI would encompass glucose concentrations of 6.2–7.8 mmol/L (112–140 mg/dL). If the analytical CV of the glucose assay (approximately 3%) is included, the 95% CI is approximately ±12.88%. Thus, the 95% CI for a fasting glucose concentration of 7.0 mmol/L (126 mg/dL) would be 7.0 mmol/L ± 6.4% (126 mg/dL ± 6.4%), i.e., 6.1–7.9 mmol/L (110–142 mg/dL). Use of an assay CV of 3% only (excluding biological variation) would yield a 95% CI of 6.6–7.4 mmol/L (118–134 mg/dL) among laboratories, for a true glucose concentration of 7.0 mmol/L (126 mg/dL). Performing the same calculations at the cutoff for impaired fasting glucose yields a 95% CI of 5.6 mmol/L ± 6.4% (100 mg/dL ± 6.4%), i.e., 4.9–6.3 mmol/L (87–113 mg/dL). One should bear in mind that these intervals include 95% of the results and that the remaining 5% will be outside this interval. Thus, the biological variation is substantially greater than the analytical variation. Using biological variation as the basis for deriving analytical performance characteristics (77), Westgard proposed the following desirable specifications for glucose (86): analytical imprecision, ≤2.9%; bias, ≤2.2%; and total error, ≤6.9%.

A. Turnaround time.

A short turnaround time for glucose analysis is not usually necessary for diagnosis of diabetes. In some clinical situations, such as acute hyper- or hypoglycemic episodes in the emergency department or treatment of diabetic ketoacidosis (DKA), rapid analysis is desirable. A turnaround time of 30 min has been proposed (87). This value is based on the suggestions of clinicians, however, and no outcome data that validate this time interval have been published. Inpatient management of diabetic patients on occasion may require a rapid turnaround time (minutes, not hours). Similarly, for protocols with intensive glucose control in critically ill patients (88), rapid glucose results are required in order to calculate the insulin dose. Bedside monitoring with glucose meters (see below) has been adopted by many as a practical solution.

B. Frequency of measurement.

The frequency of measurement of plasma glucose is dictated by the clinical situation. The ADA, WHO, and IDF recommend that an increased FPG or an abnormal OGTT result must be confirmed to establish the diagnosis of diabetes (19,89). Screening by FPG is recommended every 3 years, beginning at 45 years of age and more frequently in high-risk individuals; however, the frequency of analysis has not been specified for the latter group. Monitoring is performed by patients who measure their glucose themselves with meters and by assessment of HbA  in an accredited laboratory (see below). The appropriate interval between glucose measurements in acute clinical situations (e.g., patients admitted to a hospital, patients with DKA, neonatal hypoglycemia, and so forth) is highly variable and may range from 30 min to 24 h or more.

5. Emerging considerations

Continuous minimally invasive and noninvasive analysis of glucose is addressed below.

GLUCOSE METERS

Portable meters for the measurement of blood glucose concentrations are used in three major settings: 1) in acute- and chronic-care facilities, including intensive care units (ICUs); 2) in physicians’ offices; and 3) by patients at home, work, and school. Measurement in the last setting, self-monitoring of blood glucose (SMBG), was performed at least once per day by 40% and 26% of individuals with type 1 and type 2 diabetes, respectively, in the U.S. in 1993 (90). The overall rate of daily SMBG among adults with diabetes in the U.S. increased to 40.6% in 1997 and to 63.4% in 2006 (91). The ADA summarized the uses of SMBG as early as 1987 [see (92) and references therein] and currently recommends that SMBG be carried out ≥3 times daily by patients who use multiple insulin injections or insulin pump therapy (92,93). It is recommended that most individuals with diabetes attempt to achieve and maintain blood glucose concentrations as close to those in nondiabetic individuals as is safely possible.

1. Use

RECOMMENDATION: THERE ARE INSUFFICIENT PUBLISHED DATA OUTCOME TO SUPPORT A ROLE FOR PORTABLE METERS AND SKIN-PRICK (FINGER-STICK) BLOOD SAMPLES IN THE DIAGNOSIS OF DIABETES OR FOR POPULATION SCREENING C (moderate). RECOMMENDATION: THE IMPRECISION OF THE RESULTS, COUPLED WITH THE SUBSTANTIAL DIFFERENCES AMONG METERS, PRECLUDES THE USE OF GLUCOSE METERS FROM THE DIAGNOSIS OF DIABETES AND LIMITS THEIR USEFULNESS IN SCREENING FOR DIABETES A (moderate). 

A. Diagnosis/screening.

The glucose-based criteria for the diagnosis of diabetes are based on outcome data (the risk of micro- and macrovascular disease) correlated with plasma glucose concentrations—both fasting and 2 h after a glucose load—assayed in an accredited laboratory (1). Whole blood is used in portable meters. Although most portable meters have been programmed to report a plasma glucose concentration, the imprecision of the current meters (see below) precludes their use from the diagnosis of diabetes. Similarly, screening with portable meters—although attractive because of convenience, ease, and accessibility—would generate many false positives and false negatives.

B. Monitoring/prognosis.

SMBG is recommended for all insulin-treated patients with diabetes. Intensive glycemic control can decrease microvascular complications in individuals with type 1 (44) or type 2 (46) diabetes. In the DCCT, patients with type 1 diabetes achieved intensive glycemic control by performing SMBG at least 4 times per day (44). Therapy in patients with type 2 diabetes in the UKPDS (46) was adjusted according to FPG concentration; SMBG was not evaluated.

The role of SMBG in individuals with type 2 diabetes has generated considerable controversy (94,95). Faas et al. (96) reviewed 11 studies published between 1976 and 1996 that evaluated SMBG in patients with type 2 diabetes. Only one of the published studies reported that SMBG produced a significant improvement in glycated Hb (GHb). The review's authors concluded that the efficacy of SMBG in type 2 diabetes is questionable (96). Similar conclusions were drawn in an early (2000) meta-analysis (97) of a sample of patients with type 2 diabetes in the NHANES (98) and the Freemantle Diabetes Study (99). Two early randomized trials assessed the use of glucose meters in individuals with type 2 diabetes (100,101). One of these trials (100) had statistical power to detect a 0.5% reduction in HbA  but reported only a modest decrease (0.3%) in HbA  among poorly controlled patients treated with oral agents. The second study (101) failed to demonstrate a significant difference in HbA  in patients who were assigned to use meters, compared with those who were not.

For individuals with type 2 diabetes, cross-sectional and longitudinal observational studies in several countries have failed to demonstrate an improvement in glycemic control (as measured by mean HbA  concentration) associated with the use of SMBG (102–104). This lack of effect was seen in individuals treated with insulin, oral agents, or both. Frequency of meter use did not predict HbA .

A 2005 Cochrane review (105,106) of self-monitoring in individuals with type 2 diabetes not using insulin concluded that SMBG might be effective in improving glucose control. There was insufficient evidence to evaluate whether it was beneficial in improving quality of life, improving well-being or patient satisfaction, or decreasing the number of hypoglycemic episodes.

The randomized controlled Diabetes Glycaemic Education and Monitoring (DiGEM) trial (107) studied people with type 2 diabetes, a third of whom were treated with diet alone. In 2007, the investigators reported, “Evidence is not convincing of an effect of self monitoring blood glucose … in improving glycaemic control [as assessed by HbA ] compared with usual care in reasonably well controlled non-insulin treated patients with type 2 diabetes.” A cost-effectiveness analysis of data from the DiGEM trial concluded, “Self monitoring of blood glucose with or without additional training in incorporating the results into self care was associated with higher costs and lower quality of life in patients with non-insulin treated type 2 diabetes. In light of this, and no clinically significant differences in other outcomes, self monitoring of blood glucose is unlikely to be cost effective in addition to standardised usual care” (108).

The later ESMON study (109), a randomized controlled trial of SMBG in newly diagnosed people with diabetes not treated with insulin, found no benefit of SMBG on glycemic control but did find higher scores on a depression subscale.

Two recent systematic reviews of randomized controlled studies of SMBG in people with type 2 diabetes not treated with insulin reported small but significantly greater decreases in HbA  among patients using SMBG than in controls (110,111). In the first review (110), SMBG was associated with a larger reduction in HbA  compared with non-SMBG (weighted mean difference, −0.31%; 95% CI, −0.44 to −0.17). In the second study (111), the relative decrease in HbA  was −0.24% (95% CI, −0.34% to −0.14%). The effect of SMBG was limited to patients with HbA  values ≥8% (64 mmol/mol).

A 2009 review of studies of patients with type 2 diabetes (112) addressed recent large randomized trials of tight glycemic control, a major rationale for SMBG use in these patients. It concluded that “tight glycemic control burdens patients with complex treatment programs, hypoglycemia, weight gain, and costs and offers uncertain benefits in return,” thus raising additional uncertainty about the use of SMBG in people with type 2 diabetes.

2. Rationale

Knowledge of ambient plasma or blood glucose concentrations is used by insulin-requiring patients, particularly those with type 1 diabetes, as an aid in determining appropriate insulin doses at different times of the day (92). Patients adjust the amount of insulin according to their plasma or blood glucose concentration. Frequent SMBG is particularly important for tight glycemic control in type 1 diabetes.

Hypoglycemia is a major, potentially life-threatening complication of the treatment of diabetes. The risk of hypoglycemia is seen primarily in patients treated with insulin or insulin secretagogues, and it increases substantially when pharmacologic therapy is directed towards maintaining the glycemic concentrations as close to those found in nondiabetic individuals as is safely possible (44,46). The incidence of major hypoglycemic episodes—requiring third-party help or medical intervention—was 2- to 3-fold higher in the intensive-treatment group than in the conventional group in clinical trials of patients with type 1 and type 2 diabetes (44,46). Furthermore, many patients with diabetes, particularly those with type 1, lose the autonomic warning symptoms that normally precede neuroglycopenia (“hypoglycemic unawareness”) (113), increasing the risk of hypoglycemia. SMBG can be useful for detecting asymptomatic hypoglycemia and allowing patients to avoid major hypoglycemic episodes.

3. Analytical considerations

RECOMMENDATION: PATIENTS SHOULD BE INSTRUCTED IN THE CORRECT USE OF GLUCOSE METERS, INCLUDING QUALITY CONTROL. COMPARISON BETWEEN SMBG AND CONCURRENT LABORATORY GLUCOSE ANALYSIS SHOULD BE PERFORMED AT REGULAR INTERVALS TO EVALUATE THE PERFORMANCE OF THE METERS IN THE PATIENT'S HANDS B (moderate). 

A. Preanalytical.

Numerous factors can interfere with glucose analysis with portable meters. Several of these factors, such as improper application, timing, and removal of excess blood (61), have been mitigated or eliminated by advances in technology. Important variables that may influence the results of bedside glucose monitoring include changes in hematocrit (114), altitude, environmental temperature or humidity, hypotension, hypoxia and high triglyceride concentrations (115), and various drugs. Furthermore, most meters are inaccurate at very high or very low glucose concentrations. Another important factor is variation in results among different glucose meters. Different assay methods and architectures lead to a lack of correlation among meters, even from a single manufacturer. In fact, two meters of the same brand have been observed to differ substantially in accuracy (116,117). Patient factors are also important, particularly adequate training. Recurrent education at clinic visits and comparison of SMBG with concurrent laboratory glucose analysis improved the accuracy of patients’ blood glucose readings (118). Thus, it is important to evaluate the patient's technique at regular intervals (21). In addition to these technical issues, the anatomic site where skin-puncture samples are obtained influences results. Testing blood from so-called alternative sites may introduce a temporal lag in changes in measured blood glucose.

B. Analytical.

Virtually all glucose meters use strips that contain enzymes, such as glucose oxidase or glucose dehydrogenase. A drop of whole blood is applied to a strip that contains all the reagents necessary for the assay. Some meters have a porous membrane that separates erythrocytes, and analysis is performed on the resultant plasma. Meters can be calibrated to report plasma glucose values, even when the sample is whole blood. An IFCC working group recommended that glucose meters report the plasma glucose concentration, irrespective of the sample type or technology (119,120). This approach can improve harmonization and allow comparison with laboratory-generated results (121). The meters use reflectance photometry or electrochemistry to measure the rate of the reaction or the final concentration of the products, and they provide digital readouts of glucose concentration. Manufacturers claim reportable concentration ranges as large as 33.3 mmol/L (600 mg/dL), e.g., 0–33.3 mmol/L (0–600 mg/dL).

Several important technological advances decrease operator error. These improvements include automatic commencement of timing when both the sample and the strip are in the meter, smaller sample-volume requirements, an error signal if the sample volume is inadequate, “lock out” if controls are not assayed, and bar code readers to identify the lot of the strips. Moreover, meters store up to several hundred results that can subsequently be downloaded for analysis. Together, these improvements have improved the performance of new meters (122,123). Nonetheless, meter performance in the hands of patients does not equal potential performance as judged by performance in the hands of skilled medical technologists (124).

Numerous analytical goals have been proposed for the performance of glucose meters. The rationale for these goals is not always clear. In 1987, the ADA recommended a goal of total error (user plus analytical) of <10% at glucose concentrations of 1.7–22.2 mmol/L (30–400 mg/dL) 100% of the time (125). In addition, the ADA proposed that values should differ by ≤15% from those obtained by a laboratory reference method. The recommendation was modified in response to the significant reduction in complications obtained by tight glucose control in the DCCT. A revised performance goal, published in 1996 (92), was for a total analytical error of <5%. To our knowledge, there are no published studies of diabetic patients achieving the goal of an analytical error of <5% with any glucose meters.

The less stringent CLSI (formerly NCCLS) recommendations are that, for 95% of the samples, the difference between meter and laboratory measurements of glucose be 1) <20% when the laboratory glucose value is >5.5 mmol/L (100 mg/dL) and 2) <0.83 mmol/L (15 mg/dL) of the laboratory glucose value when the glucose concentration is ≤5.5 mmol/L (100 mg/dL) (126). The 2003 International Organization for Standardization (ISO) recommendations (127) propose that for test readings >4.2 mmol/L (75 mg/dL), the discrepancy between meters and an accredited laboratory should be <20%; for glucose readings ≤4.2 mmol/L (75 mg/dL), the discrepancy should not exceed 0.83 mmol/L (15 mg/dL) in 95% of the samples. In both the CLSI and ISO guidelines, 5% of these results can be substantially outside these limits. At the time of writing, both the CLSI and ISO recommendations were undergoing revision.

These criteria serve as de facto minimal quality requirements for manufacturers wishing to sell meters. With these criteria, a concentration of 2.5 mmol/L (45 mg/dL) may be read as 1.7 mmol/L (30 mg/dL) or 3.3 mmol/L (60 mg/dL) and be considered acceptable. Such errors do not appear to be acceptable for reliably detecting hypoglycemia. Similarly, errors of 20% can lead to errors in insulin dosing, which, when combined with other factors, can lead to hypoglycemia.

Others have proposed different approaches to establishing quality requirements. Clarke et al. (128) developed an error grid that attempts to define clinically important errors by identifying fairly broad target ranges. In another approach, 201 patients with long-standing type 1 diabetes were questioned to estimate quality expectations for glucose meters (129). On the basis of patients’ perceptions of their needs and their reported actions in response to changes in measured glucose concentrations, a goal for analytical quality at hypoglycemic concentrations was a CV of 3.1%. With hypoglycemia excluded, the analytical CV to meet the expectations of 75% of the patients was 6.4% to 9.7%. The authors recommended an analytical CV of 5% with a bias ≤5% (129). A third approach used simulation modeling of errors in insulin dose (130). The results revealed that meters that achieve both a CV and a bias <5% rarely lead to major errors in insulin dose. To provide the intended insulin dosage 95% of the time, however, the bias and CV needed to be <1%–2%, depending on the dosing schedule for insulin and the intervals of glucose concentrations for the individual patient (130). No meters have been shown to achieve CVs of 1%–2% in routine use in the hands of patients.

The lack of consensus on quality goals for glucose meters reflects the absence of agreed objective criteria. With the same biological-variation criteria described above for glucose analysis in accredited laboratories (section 4, Interpretation), a biological goal would be a total error ≤6.9% with an imprecision (as the CV of measurements over several days or weeks) ≤2.9% and a bias ≤2.2% (86). Additional studies, however, are necessary to define a goal that is related to medical needs.

Current meters exhibit performance superior to prior generations of meters (122,123). A variety of studies of newer analyzers have documented CVs of about 2% in the hands of trained workers. Nonetheless, there is room for improvement. In a study conducted under carefully controlled conditions in which a single medical technologist performed all of the assays, about 50% of the analyses met the 1996 ADA criterion of <5% deviation from reference intervals (122). Another study that evaluated meter performance in 226 hospitals with split samples analyzed simultaneously on meters and laboratory glucose analyzers revealed that 45.6%, 25%, and 14% of the split samples differed from each other by >10%, >15%, and >20%, respectively (131). In another study, none of the meters met the 1996 ADA criterion (132). In an evaluation in which “all testing was performed by trained study staff in an inpatient Clinical Research Center setting,” only 81% of results with a meter that used a hexokinase method were within 10% of results obtained from an accredited laboratory (133). We are aware of no studies that document patient-generated results that meet the 1996 ADA criteria. Moreover, an analysis of published studies of glucose meters demonstrated that the studies suffered from deficiencies in study design, methodology, and reporting (134), raising the possibility that the reported total error underestimates the true total error of the meters. A standardized method for evaluating meters has been developed in Norway (134), and the Norwegian health authorities have decided that all SMBG instruments marketed in Norway should be examined by a similar procedure (135). Results of evaluations of nine brands of meters according to this method showed that three of nine meters did not meet the ISO criteria, and none met the 1996 ADA criteria in the hands of patients (135).

Glucose meters are also used to support tight control of glucose in patients in ICU settings. A 2001 report of a seminal randomized controlled trial by van den Berghe et al. described a 34% reduction in mortality in surgical ICU patients managed according to a tight glucose-control protocol (88). A meta-analysis of multiple randomized controlled trials of tight glucose control conducted 7 years later failed to identify any improved outcomes but did find an increased incidence of hypoglycemia (136). A Clinical Chemistry Perspective article (137) pointed out that the study of van den Berghe et al. used a precise and accurate glucose analyzer and collected arterial blood samples, whereas subsequent studies often used glucose meters and capillary blood samples obtained by finger stick. The integrity of results obtained with finger-stick samples can be compromised by such factors as shock, hypoxia, and low hematocrit, which are common in these settings (138). Moreover, the error of glucose meters may compound the problem and compromise the ability to control blood glucose and avoid hypoglycemia. Simulation modeling studies have demonstrated that errors in glucose measurement (which include errors related to sample type and sample collection) lead to marked degradation of glycemic control in tight glucose-control protocols (139). In this study, frequencies of both hyperglycemia and hypoglycemia were increased with increasing assay imprecision. In a 2005 study of ICU patients (140), the agreement of meter results with accredited laboratory results was poor: Among 767 paired results, the 95% limits of agreement were +2.4 to −1.5 mmol/L (+43.1 to −27.2 mg/dL). Hoedemaekers et al. (141), in a study of 197 arterial blood samples from ICU patients, reported that the evaluated meter did not meet the ISO total-error criteria. They also demonstrated that the total error of meters used in ICU patients was greater than in non-ICU patients. A later report, which also studied arterial blood from ICU patients, measured glucose in 239 samples by a portable meter and by a laboratory method and found that the meter results did not meet the CLSI/ISO criteria (142). Similarly, a 2005 study of arterial, venous, and capillary samples from a mixed medical/surgical ICU of a tertiary care hospital in Canada found that meters did not meet proposed CLSI goals but that a blood gas analyzer did (143).

4. Interpretation

A. Frequency of measurement.

SMBG should be performed at least 3 times per day in patients with type 1 diabetes. Monitoring less frequently than 3 times per day leads to deterioration in glycemic control (92,144,145). Patients perform self-monitoring much less frequently than recommended. Data from NHANES III collected between 1988 and 1994 reveal that SMBG was performed at least once a day by 39% of patients taking insulin and by 5%–6% of patients treated with oral agents or diet alone (98). Moreover, 29% and 65% of patients treated with insulin and oral agents, respectively, monitored their blood glucose less than once per month; however, no evaluation has been performed to verify that 3 times per day is ideal or whether a different frequency would improve glycemic control. For example, adjustment of insulin therapy in women with GDM according to the results of postprandial, rather than preprandial, plasma glucose concentrations improved glycemic control and reduced the risk of neonatal complications (146). The optimal frequency of SMBG for patients with type 2 diabetes is unknown.

The ADA recommends that patients treated with multiple daily injections of insulin perform SMBG ≥3 times per day (21) and states that “SMBG is useful in achieving glycemic goals” in other patients. The last statement is based on expert opinion.

CONTINUOUS MINIMALLY INVASIVE GLUCOSE ANALYSES

1. Use

RECOMMENDATION: REAL-TIME CONTINUOUS GLUCOSE MONITORING (CGM) IN CONJUNCTION WITH INTENSIVE INSULIN REGIMENS CAN BE A USEFUL TOOL TO LOWER HbA1c IN SELECTED ADULTS (AGE >25 YEARS) WITH TYPE 1 DIABETES A (high). RECOMMENDATION: ALTHOUGH THE EVIDENCE FOR LOWERING HbA1c IS NOT AS STRONG FOR CHILDREN, TEENS, AND YOUNGER ADULTS, REAL-TIME CGM MAY BE HELPFUL IN THESE GROUPS. SUCCESS CORRELATES WITH ADHERENCE TO ONGOING USE OF THE DEVICE B (moderate). RECOMMENDATION: REAL-TIME CGM MAY BE A SUPPLEMENTAL TOOL TO SMBG IN INDIVIDUALS WITH HYPOGLYCEMIA UNAWARENESS AND/OR FREQUENT EPISODES OF HYPOGLYCEMIA B (low). RECOMMENDATION: PATIENTS REQUIRE EXTENSIVE TRAINING IN USING THE DEVICE. AVAILABLE DEVICES MUST BE CALIBRATED WITH SMBG READINGS, AND THE LATTER ARE RECOMMENDED FOR MAKING TREATMENT CHANGES GPP. 

The development of a device for “continuous” in vivo monitoring of glucose concentrations in blood has become a very high priority as patients are required to control their plasma glucose more closely (21,44,147). The first device approved by the U.S. Food and Drug Administration (FDA) for minimally invasive interstitial fluid glucose sensing, the transcutaneous GlucoWatch Biographer, is no longer on the market. Several implanted-catheter systems have subsequently been approved. The initial device in the latter category is the Continuous Glucose Monitoring System (CGMS) (Medtronic), a system that does not provide real-time data to the patient, but rather one the patient wears for 3 days and then returns to the provider's office for its data to be downloaded for trend analyses. More recently, a number of real-time devices that allow patients to read both current glucose concentrations and trends have become commercially available. In the U.S., these devices include the Guardian Real-Time (Medtronic Diabetes), the Seven Plus System (DexCom), and the Freestyle Navigator (Abbott Laboratories). CGM devices require calibration and confirmation of accuracy with conventional SMBG, and the FDA advises using the latter for treatment decisions, such as calculating premeal insulin doses.

The clinical studies of these devices, generally in highly selected populations, had primarily been limited to assessments of their accuracy or to short-term trials demonstrating reductions in the time patients spend within hypo- and hyperglycemic intervals (148). A systematic review of trials of the non–real-time CGM system device suggests that it does not lead to significantly lower HbA  values compared with SMBG (149). In 2008, a large 26-week randomized trial of 322 type 1 diabetic patients showed that adults ≥25 years of age who used intensive insulin therapy and real-time CGM experienced a 0.5% reduction in HbA , from approximately 7.6% to 7.1% (approximately 60 to 54 mmol/mol), compared with the usual intensive insulin therapy with SMBG (150). Sensor use in children, teens, and adults to 24 years of age did not lower HbA  significantly, and there was no significant difference in hypoglycemia for any group. The greatest predictor of HbA  reduction in this study among all age-groups was frequency of sensor use, which was lower in younger age-groups. Although CGM is an evolving technology, the emerging data suggest that it may offer benefit in appropriately selected patients who are motivated to wear it most of the time. CGM may be particularly useful for patients with hypoglycemia unawareness and/or frequent episodes of hypoglycemia; studies in this area are ongoing.

2. Rationale

The first goal for developing a reliable in vivo continuous glucose sensor is to detect unsuspected hypoglycemia. The importance of this goal has been increasingly appreciated with the recognition that strict glucose control is accompanied by a marked increase in the risk of hypoglycemia (44,147). Therefore, a sensor designed to detect severe hypoglycemia alone would be of value. In contrast, a full-range, reliable continuous in vivo glucose monitor is a prerequisite for the development of a closed-loop pump or “artificial pancreas” that would measure blood glucose concentrations and automatically adjust insulin administration.

3. Analytical considerations

The methods to sample biological fluids in a continuous and minimally invasive way vary among test systems. The underlying fundamental concept is that the concentration of glucose in the interstitial fluid correlates with blood glucose. The implanted sensors use multiple detection systems, including enzyme- (usually glucose oxidase), electrode-, and fluorescence-based techniques. Alternatives to enzymes, including artificial glucose “receptors,” as glucose-recognition molecules are being developed (151,152). Fluorescence technologies include the use of engineered molecules that exhibit altered fluorescence intensity or spectral characteristics on binding glucose, or the use of competitive-binding assays that use two fluorescent molecules in the fluorescent resonance energy transfer technique (153–157).

4. Interpretation

The subcutaneous sensors are generally worn for a number of days and require calibration with SMBG readings several times per day. A few small studies have examined their accuracy compared with SMBG and/or plasma glucose assays. For the Medtronic CGMS System Gold device, the mean (SD) absolute difference between sensor readings and blood glucose readings was 15.0% (12.2%) for 735 paired samples, whereas the GlucoDay microdialysis device (Menarini) had a mean absolute difference of 13.6% (10.2%) for 1,156 paired samples (158). For both devices, accuracy was lowest in the hypoglycemic ranges. Approximately 97% of the values for both devices were within zones A and B of a Clarke error grid, with none falling in zone E (158). A study of 91 insulin-treated patients using the DexCom device showed that 95% of 6,767 paired glucose values fell within Clarke error grid zones A and B, with a mean absolute difference of 21.2% (148).

Currently, there are no analytical goals for noninvasive and minimally invasive glucose analyses. Such standards will clearly need to be different for different proposed uses. For example, the reliability, precision, and accuracy requirements for a glucose sensor that is linked to a system that automatically adjusts insulin doses will be much more stringent than those for a sensor designed to trigger an alarm in cases of apparent extreme hyper- or hypoglycemia. It seems intuitively obvious that a larger imprecision can be tolerated in instruments that make frequent readings during each hour than in an instrument used only 2 or 3 times per day to adjust a major portion of a person's daily insulin dose.

5. Emerging considerations

With FDA approval of several self-monitoring continuous glucose sensors, it is anticipated that there will be renewed efforts to bring other technologies forward into clinical studies. Ultimately, we shall see improved methods for noninvasive or minimally invasive glucose measurements that will complement current glucose self-monitoring techniques.

NONINVASIVE GLUCOSE ANALYSIS

RECOMMENDATION: NO NONINVASIVE SENSING TECHNOLOGY IS CURRENTLY APPROVED FOR CLINICAL GLUCOSE MEASUREMENTS OF ANY KIND. MAJOR TECHNOLOGICAL HURDLES MUST BE OVERCOME BEFORE NONINVASIVE SENSING TECHNOLOGY WILL BE SUFFICIENTLY RELIABLE TO REPLACE EXISTING PORTABLE METERS, IMPLANTABLE BIOSENSORS, OR MINIMALLY INVASIVE TECHNOLOGIES C (very low). 

1. Use

Noninvasive glucose-sensing technologies represent a group of potential analytical methods for measuring blood glucose concentrations without implanting a probe or collecting a sample of any type. The most commonly explored methods involve passing a selected band of nonionizing electromagnetic radiation (light) through a vascular region of the body and then determining the in vivo glucose concentration from an analysis of the resulting light or spectrum. The distinguishing feature of this approach is a lack of physical contact between the sample matrix and a measurement probe. The only functional interaction is the light passing through the sample.

A truly noninvasive method would be painless in operation and capable of continuous readings over time. In addition, noninvasive sensing technology may be less expensive to implement than existing technologies that demand either a fresh test strip for each measurement or a new implantable probe that requires multiple daily calibration measurements with fresh test strips. Furthermore, most noninvasive strategies offer the potential for measuring multiple analytes from a single noninvasive measurement. The development of this technology is driven by the features of both low cost and painless, continuous operation with no reagents or waste for disposal.

Reports in the peer-reviewed literature describe noninvasive measurements based on a variety of techniques, such as absorption spectroscopy, photoacoustic spectroscopy, Raman scattering, static light scattering, polarimetry, and optical coherent tomography (159–162). Potential applications include discrete home glucose testing, continuous home glucose monitoring, nocturnal hypoglycemia alarm, measurements in a physician's office, point-of-care monitoring, screening for diabetes, and control of hyperglycemia in critically ill patients. To date, none of these applications has been realized.

2. Rationale

Indirect and direct methods are being developed for noninvasive glucose sensing. Indirect methods rely on the effect of in vivo glucose concentrations on a measurable parameter. The classic example of this approach is the effect of blood glucose concentrations on the scattering properties of skin (163). Changes in blood glucose substantially affect the difference in refractive index between skin cells and the surrounding interstitial fluid and thereby alter the scattering coefficient of skin. This parameter can be measured in a number of ways, including ocular coherent tomography. Skin impedance and the aggregation properties of erythrocytes are other indirect approaches.

Direct methods measure a property of the glucose molecule itself. Vibrational spectroscopy is the primary direct method and generally involves mid-infrared, near-infrared, photoacoustic, or Raman scattering spectroscopy. The basis of these measurements is the unique spectral signature of glucose relative to the background tissue matrix.

Selectivity is the primary factor that must be addressed for either indirect or direct approaches. The lack of an isolated sample precludes the use of physical separations or chemical reactions to enhance measurement selectivity. All of the analytical information must originate from the noninvasive signal. Ultimately, the success of any approach demands a full understanding of the fundamental basis of selectivity. To this end, basic research efforts are paramount to establish such a level of understanding.

3. Analytical considerations

It should no longer be acceptable to publish results that simply demonstrate the ability to follow glucose transients during simple glucose tolerance tests (164). This ability is well established in the literature for numerous approaches, both indirect and direct. In fact, it is rather easy to monitor optical changes that correlate with in vivo glucose concentrations during glucose tolerance tests. It is considerably more difficult, however, to demonstrate that such measurements are reliable and selective. Reliability and selectivity must be the focus of the next generation of research. Indeed, the FDA considers all noninvasive sensing technologies to be high-risk medical devices, and premarket approval documentation will be required for commercialization in the U.S. (165).

Many reports of attempts to measure glucose noninvasively lack sufficient information to judge the likelihood that glucose is actually being measured. The interpretation of such clinical data is complicated by the common use of multivariate statistical methods, such as partial least squares regression and artificial neural networks. These multivariate methods are prone to spurious correlations that can generate apparently functional glucose measurements in the complete absence of glucose-specific analytical information (166,167). Given this known limitation of these multivariate methods, care must be used in their implementation. Tests for spurious correlations (168–170) must be developed and implemented with all future clinical data to avoid reports of false success.

Despite the limitations noted above, real progress is being made to further the development of noninvasive glucose-sensing technologies (171,172). Rigorous testing of noninvasive technologies must be continued in concert with efforts to understand the underlying chemical basis of selectivity. Issues of calibration stability must also be investigated. Overall progress demands advances in both instrumentation and methods of data analysis. For each, meaningful benchmarks must be established to allow rigorous inter- and intralaboratory comparisons.

GESTATIONAL DIABETES MELLITUS

1. Use

RECOMMENDATION: ALL PREGNANT WOMEN NOT PREVIOUSLY KNOWN TO HAVE DIABETES SHOULD UNDERGO TESTING FOR GDM At 24–28 WEEKS OF GESTATION A (high). 

GDM has been defined as any degree of glucose intolerance with onset or first recognition occurring during pregnancy (1). After recent discussions, the International Association of the Diabetes and Pregnancy Study Groups (IADPSG) recommended that high-risk women who have diabetes established according to standard criteria (Table 4) at their initial prenatal visit receive a diagnosis of overt, not gestational, diabetes (21). The IADPSG recommendations are not identical to the criteria for nonpregnant individuals, in that an OGTT result with an FPG value <7.0 mmol/L (126 mg/dL) and 2-h value >11.1 mmol/L (200 mg/dL) is not called “overt diabetes.” As the prevalence of obesity and type 2 diabetes has increased, the number of women with undiagnosed diabetes has risen (173). Therefore, the ADA now recommends that women with risk factors for type 2 diabetes be screened for diabetes according to standard diagnostic criteria (Table 4) at the first prenatal visit (93). Women with diabetes diagnosed with this approach should receive a diagnosis of overt diabetes.

Two randomized clinical trials have now demonstrated a benefit from the treatment of “mild” GDM. Both studies found that treatment of GDM can reduce both serious adverse outcomes and the frequency of large babies (macrosomia) (174,175).

2. Rationale

The ADA states that because of the risks of GDM to the mother and the neonate, screening and diagnosis are warranted (21). The screening and diagnostic criteria for GDM have recently been modified extensively. The Hyperglycemia and Adverse Pregnancy Outcome (HAPO) study was a large (approximately 25,000 pregnant women) prospective, multinational epidemiologic study to assess adverse outcomes as a function of maternal glycemia (176). The study revealed strong, graded, predominantly linear associations between maternal glycemia and primary study outcomes, i.e., birth weight >90th percentile, delivery by cesarean section, clinical neonatal hypoglycemia, and cord serum insulin (C-peptide) concentrations >90th percentile of values in the HAPO study population. The associations remain strong after adjustments for multiple potentially confounding factors. Strong associations were also found with infant adiposity (177), with some secondary outcomes (including risks of shoulder dystocia and/or birth injury), and with preeclampsia (176). On the strength of these results, an expert consensus panel appointed by the IADPSG recommended “outcome based” criteria for the classification of glucose concentrations in pregnancy (178). All pregnant women not previously known to have diabetes should be evaluated by a 75-g OGTT for GDM at 24–28 weeks of gestation (178). Diagnostic cut points for fasting, 1-h, and 2-h plasma glucose concentrations have been established (Table 6). These recommendations were adopted by the ADA in 2011 (93) and are currently under consideration by the American College of Obstetrics and Gynecology in the U.S. and by corresponding groups in other countries. Using the new criteria substantially increases the incidence of GDM, mainly because only one increased glucose value is required to diagnose GDM (prior recommendations required two increased glucose concentrations). Treatment will require additional resources, and outcome studies will be necessary to ascertain whether therapy is beneficial for GDM diagnosed with the new criteria; however, the two trials that focused on the treatment of “mild GDM” (identified with the old criteria) achieved an improvement in outcomes, with only 10%–20% of the patients requiring pharmacologic treatment in addition to medical nutritional therapy (174,175).

3. Analytical considerations

These considerations have been addressed earlier in the Glucose sections. Given the strict cutoffs, it is very important that close attention be paid to stringent sample-handling procedures to minimize glycolysis after phlebotomy.

4. Interpretation

RECOMMENDATION: GDM SHOULD BE DIAGNOSED BY A 75-g OGTT ACCORDING TO THE IADPSG CRITERIA DERIVED FROM THE HAPO STUDY A (moderate). 

The ADA previously recommended that a “risk assessment” (based on age, weight, past history, and so on) be performed and that patients at average or high risk receive a glucose-challenge test. Several diagnostic strategies could be used. They were a “1-step” approach, in which an OGTT was performed initially, or a “2-step” approach, in which an administered 50-g oral glucose load (regardless of whether the patient was fasting) was followed by a plasma glucose measurement at 1 h. A plasma glucose value ≥7.8 mmol/L (140 mg/dL) indicates the need for definitive testing with an OGTT; however, a consensus was lacking as to whether a 100-g or 75-g OGTT should be performed and what cutoff values should be used for diagnosis.

Some GDM cases may represent preexisting, but undiagnosed, type 2 diabetes. Therefore, women with GDM should be screened for diabetes 6–12 weeks postpartum according to the OGTT criteria for nonpregnant women (Table 5) (93). In addition, because women with GDM are at a considerably increased risk of developing diabetes later (179), lifelong screening for diabetes should be performed at least every 3 years according to standard criteria for nonpregnant women (Table 4) (93).

URINARY GLUCOSE

RECOMMENDATION: SEMIQUANTITATIVE URINE GLUCOSE TESTING IS NOT RECOMMENDED FOR ROUTINE CARE OF PATIENTS WITH DIABETES MELLITUSB (low). 

1. Use

Semiquantitative urine glucose testing, once the hallmark of diabetes care in the home setting, has now been replaced by SMBG (see above). Semiquantitative urine glucose monitoring should be considered only for patients who are unable or refuse to perform SMBG, because the urine glucose concentration does not accurately reflect the plasma glucose concentration (147,180). Notwithstanding these limitations, urine glucose monitoring is supported by the IDF in those situations in which blood glucose monitoring is not accessible or affordable, particularly in resource-poor settings (23).

2. Rationale

Although urine glucose is detectable in patients with grossly increased blood glucose concentrations, it provides no information about blood glucose concentrations below the variable renal glucose threshold [approximately 10 mmol/L (180 mg/dL)]. This fact alone limits its usefulness for monitoring diabetes under modern care recommendations. Semiquantitative urine glucose tests also cannot distinguish between euglycemia and hypoglycemia. Furthermore, the extent to which the kidney concentrates the urine will affect urine glucose concentrations, and only mean glucose values between voidings are reflected. These facts further minimize the value of urine glucose measurements.

3. Analytical considerations

Semiquantitative test-strip methods that use reactions specific for glucose are recommended. Commercially available strips use the glucose oxidase reaction (181). Test methods that detect reducing substances are not recommended because they are subject to numerous interferences, including numerous drugs and nonglucose sugars. When used, single voided urine samples are recommended (147).

4. Interpretation

Because of the limited use of urine glucose measurements, semiquantitative specific reaction–based test-strip methods are adequate.

KETONE TESTING

1. Use

RECOMMENDATION: KETONES MEASURED IN URINE OR BLOOD IN THE HOME SETTING BY PATIENTS WITH DIABETES AND IN THE CLINIC/HOSPITAL SETTING SHOULD BE CONSIDERED ONLY AN ADJUNCT TO THE DIAGNOSIS OF DKA GPP. 

The ketone bodies acetoacetate (AcAc), acetone, and β-hydroxybutyric acid (βHBA) are catabolic products of free fatty acids. Measurements of ketones in urine and blood are widely used in the management of patients with diabetes as adjuncts for both diagnosis and ongoing monitoring of DKA. Measurements of ketone bodies are routinely performed, both in an office/hospital setting and by patients at home. The ADA recommends that ketosis-prone patients with diabetes check urine or blood ketones in situations characterized by deterioration in glycemic control in order to detect and preempt the development of DKA (21,182).

2. Rationale

Ketone bodies are usually present in urine and blood, but in very low concentrations (e.g., total serum ketones, <0.5 mmol/L). Increased ketone concentrations detected in patients with known diabetes or in previously undiagnosed patients presenting with hyperglycemia suggest impending or established DKA, a medical emergency. The two major mechanisms for high ketone concentrations in patients with diabetes are increased production from triglycerides and decreased utilization in the liver—both of which are due to an absolute or relative insulin deficiency and increased counter-regulatory hormones, including cortisol, epinephrine, glucagon, and growth hormone (183).

The principal ketone bodies βHBA and AcAc are typically present in approximately equimolar amounts. Acetone, usually present in only small quantities, is derived from spontaneous decarboxylation of AcAc. The equilibrium between AcAc and βHBA is shifted towards βHBA formation in any condition that alters the redox state of hepatic mitochondria to increase NADH concentrations, such as hypoxia, fasting, metabolic disorders (including DKA), and alcoholic ketoacidosis (184–186). Thus, assay methods for ketones that do not include βHBA measurement may provide misleading clinical information by underestimating total ketone body concentration (187).

3. Analytical considerations

A. Urine ketones

1. Preanalytical.

The concentrations of ketones in the urine of healthy individuals are below the detection limits of commercially available testing materials. False-positive results have been reported with highly colored urine and in the presence of several sulfhydryl-containing drugs, including angiotensin-converting enzyme inhibitors (188). Urine test reagents deteriorate with exposure to air, giving false-negative readings; therefore, testing material should be stored in tightly sealed containers and discarded after the expiration date on the manufacturer's label (189). False-negative readings have also been reported with highly acidic urine samples, such as after large intakes of ascorbic acid. Loss of ketones from urine attributable to microbial action can also cause false-negative readings. Because acetone is a highly volatile substance, samples should be kept in a closed container. For point-of-care analyses in medical facilities and for patients in the home setting, control materials (that give both negative and positive readings) are not commercially available but would be desirable to ensure accuracy of test results.

2. Analytical.

Several assay principles have been described. Most commonly used is the colorimetric reaction that occurs between AcAc and nitroprusside (sodium nitroferricyanide) to produce a purple color (181). This method is widely available in the form of dipsticks and tablets and is used to measure ketones in both the urine and blood (either serum or plasma). Several manufacturers offer dipsticks for measuring glucose and ketones. A combination dipstick is necessary only if the patient monitors urine glucose instead of or in addition to blood glucose. The nitroprusside method measures only AcAc unless the reagent contains glycine, in which case acetone is also measured. The nitroprusside-containing reagent is much more sensitive to AcAc than acetone with respect to color generation. Importantly, this reagent cannot be used to measure βHBA (181).

B. Blood ketones

1. Preanalytical.

Serum/plasma ketones can be measured with the tablets or dipsticks routinely used for urine ketone measurements. Although samples can be diluted with saline to “titer” the ketone concentration (results are typically reported as “positive at a 1/x dilution”), βHBA, the predominant ketone body in DKA, is not detected, as with urine ketone testing.

For specific βHBA measurements, sample requirements differ among methods, as is described below. In general, blood samples can be collected into tubes containing heparin, EDTA, fluoride, citrate, or oxalate. Ascorbic acid interferes with some assay methods. AcAc interferes with some assay methods unless the samples are highly dilute. Sample stability differs among methods, but whole-blood samples are generally stable at 4°C for up to 24 h. Serum/plasma samples are stable for up to 1 week at 4°C and for at least several weeks at −20°C (long-term stability data are not available for most assay methods).

2. Analytical.

Although several different assay methods (e.g., colorimetric, gas chromatography, capillary electrophoresis, and enzymatic) have been described for blood ketones, including specific measurement of βHBA, enzymatic methods appear to be the most widely used for the quantification of βHBA for routine clinical management (190–192). The principle of the enzymatic methods is that β-hydroxybutyrate dehydrogenase in the presence of NAD+ converts βHBA to AcAc and NADH. Under alkaline conditions (pH 8.5–9.5), the reaction favors the formation of AcAc from βHBA. The NADH produced can be quantified spectrophotometrically (usually kinetically) with the use of a peroxidase reagent. Most methods permit the use of whole-blood, plasma, or serum samples (required volumes are generally ≤200 μL). Some methods permit the analysis of multiple analytes; these methods are designed for point-of-care testing. Several methods are available as handheld meters, which have been FDA cleared for both laboratory use and home use by patients. These methods use dry-chemistry test strips to which a drop of whole blood, serum, or plasma is added. Results are displayed on the instruments within approximately 2 min.

4. Interpretation

RECOMMENDATION: KETONES MEASURED IN URINE OR BLOOD IN THE HOME SETTING BY PATIENTS WITH DIABETES AND IN THE CLINIC/HOSPITAL SETTING SHOULD BE CONSIDERED ONLY AN ADJUNCT TO THE DIAGNOSIS OF DKA GPP. 

A. Urine ketone measurements.

The presence of positive urine ketone readings in a patient with known diabetes or a patient not previously diagnosed with diabetes but who presents with typical symptoms of diabetes and hyperglycemia suggests the possibility of impending or established DKA. Although DKA is most commonly associated with type 1 diabetes, it may occur rarely in type 2 diabetic patients (193). Patients with alcoholic ketoacidosis will have positive urine ketone readings, but hyperglycemia is not usually present. Positive urine ketone readings are found in up to 30% of first morning urine samples from pregnant women (with or without diabetes), during starvation, and after hypoglycemia (187).

RECOMMENDATION: BLOOD KETONE DETERMINATIONS THAT RELY ON THE NITROPRUSSIDE REACTION SHOULD BE USED ONLY AS AN ADJUNCT TO DIAGNOSE DKA AND SHOULD NOT BE USED TO MONITOR DKA TREATMENT. SPECIFIC MEASUREMENT OF βHBA IN BLOOD CAN BE USED FOR DIAGNOSIS AND MONITORING OF DKA B (moderate). 

B. Blood ketone measurements.

Blood ketone measurements that rely on the nitroprusside reaction should be used with caution for DKA diagnosis, because the results do not quantify βHBA, the predominant ketone in DKA. The test should not be used to monitor the course of therapy, because AcAc and acetone may increase as βHBA decreases during successful therapy (147,183–187). Blood ketone measurements that measure βHBA specifically are useful for both the diagnosis and ongoing monitoring of DKA (194–196). Reference intervals for βHBA differ among assay methods, but concentrations in healthy individuals who have fasted overnight are generally <0.5 mmol/L. Patients with well-documented DKA [serum CO  <17 mmol/L, arterial pH <7.3, plasma glucose >14.9 mmol/L (250 mg/dL)] generally have βHBA concentrations >2 mmol/L.

5. Emerging considerations

Further studies are needed to determine whether blood ketone measurements by patients with diabetes are preferable (e.g., better accepted by patients, more prompt diagnosis of DKA) to urine ketone measurements. Studies are necessary to evaluate whether the test offers any clinical advantage over more traditional management approaches (e.g., measurements of serum CO , anion gap, or pH).

HBA1c

1. Use

RECOMMENDATION: HbA1c SHOULD BE MEASURED ROUTINELY IN ALL PATIENTS WITH DIABETES MELLITUS TO DOCUMENT THEIR DEGREE OF GLYCEMIC CONTROL A (moderate). 

Measurement of glycated proteins, primarily HbA , is widely used for routine monitoring of long-term glycemic status in patients with diabetes. [The terms “glycated hemoglobin,” “glycohemoglobin,” “glycosylated” (which should not be used), “glucosylated hemoglobin,” “HbA ,” and “HbA ” have all been used to refer to hemoglobin that has been modified by the nonenzymatic addition of glucose. These terms are not interchangeable, however. The current acceptable term for glycation of hemoglobin in general is “glycated hemoglobin” (GHb). HbA  is the specific glycated species that is modified by glucose on the N terminus of the hemoglobin β chain. “HbA ” is also the internationally accepted term for reporting all GHb results. Assay methods that measure total GHbs (e.g., boronate affinity methods) should be calibrated to report an equivalent HbA  and be reported as HbA  for purposes of harmonization of results. HbA  is composed of HbA , HbA , and HbA  and should not be measured or reported. The term “A1C test” is used by the ADA in place of HbA  to facilitate communication with patients. As described in the text, most of the clinical-outcome data that are available for the effects of metabolic control on complications (at least for the DCCT and UKPDS) involved the use of assay methods that quantified HbA . In this report, we use the abbreviation GHb to include all forms of glycated hemoglobin.] HbA  is used both as an index of mean glycemia and as a measure of risk for the development of diabetes complications (147,197). HbA  testing and maintenance of specified concentrations during pregnancy in patients with preexisting type 1 or type 2 diabetes are important for maximizing the health of the newborn and decreasing perinatal risks for the mother. Specifically, stringent control of HbA  values during pregnancy decreases the risk of congenital malformations, large-for-date infants, and the complications of pregnancy and delivery that can otherwise occur when glycemic control is not carefully managed (198). A recent consensus statement (198) recommends an HbA  value of <6% (42 mmol/mol) in these patients if it can be achieved without excessive hypoglycemia. HbA  is also being used increasingly by quality-assurance programs to assess the quality of diabetes care (e.g., requiring that healthcare providers document the frequency of HbA  testing in patients with diabetes and the proportion of patients with HbA  values below a specified value) (199,200).

The ADA and other organizations that have addressed this issue recommend HbA  measurement in both type 1 and type 2 diabetic patients to document the degree of glycemic control and to assess response to therapy (21,93,201). The ADA has recommended specific treatment goals for HbA  on the basis of results from prospective randomized clinical trials, most notably the DCCT for type 1 diabetes (44,197) and the UKPDS for type 2 diabetes (46). These trials have documented the relationship between glycemic control (as quantified by longitudinal HbA  measurements) and the risks for the development and progression of chronic complications of diabetes. Because different GHb assays can produce different GHb values, the ADA recommends that laboratories use only assay methods that have been certified as traceable to the DCCT GHb reference (21,187); these results are reported as HbA . The ADA recommends that in general an HbA  target of <7% (53 mmol/mol) is desirable for nonpregnant adults, with higher values recommended for children and adolescents (21). HbA  goals should be individualized according to the potential for benefit with regard to long-term complications and be balanced against the increased risk for the hypoglycemia that attends intensive therapy. For selected individual patients, more-stringent targets could be suggested, provided that this goal can be achieved without substantial hypoglycemia or other adverse effects of treatment. Such patients might include those with a short duration of diabetes, a long life expectancy, and no significant cardiovascular disease (93). Conversely, higher HbA  goals should be chosen for patients with a history of severe hypoglycemia, a limited life expectancy, advanced microvascular or macrovascular complications, or extensive comorbid conditions. Other clinical organizations recommend similar HbA  targets, which range from 6.5% to 7% (48 to 53 mmol/mol) (53,202).

2. Rationale

Glycated proteins are formed posttranslationally from the slow, nonenzymatic reaction between glucose and free amino groups on proteins (203). For Hb, the rate of GHb synthesis is principally a function of the glucose concentration to which the erythrocytes are exposed, integrated over the time of exposure. GHb is a clinically useful index of mean glycemia during the preceding 120 days, the average life span of erythrocytes (147,203–206). Several studies have demonstrated a close mathematical relationship between HbA  concentration and mean glycemia, which should allow the expression of HbA  as an estimated average glucose (eAG) concentration (205,207–209). Analogous to Hb (in erythrocytes), serum proteins become glycated. Commercial assays are available that measure total glycated protein (termed fructosamine) or glycated albumin in the serum. The concentrations of these glycated proteins also reflect mean glycemia, but over a much shorter time (15–30 days) than GHb (60–120 days) (147,203–206,210,211). The clinical utility of glycated proteins other than Hb has not been clearly established, however, and there is no convincing evidence that relates their concentrations to the chronic complications of diabetes (147,187).

3. Analytical considerations

RECOMMENDATION: LABORATORIES SHOULD USE ONLY HbA1c ASSAY METHODS THAT ARE CERTIFIED BY THE NATIONAL GLYCOHEMOGLOBIN STANDARDIZATION PROGRAM (NGSP) AS TRACEABLE TO THE DCCT REFERENCE. THE MANUFACTURERS OF HbA1c ASSAYS SHOULD ALSO SHOW TRACEABILITY TO THE IFCC REFERENCE METHOD GPP. 

RECOMMENDATION: LABORATORIES THAT MEASURE HbA1c SHOULD PARTICIPATE IN A PROFICIENCY-TESTING PROGRAM, SUCH AS THE COLLEGE OF AMERICAN PATHOLOGISTS (CAP) HbA1c SURVEY, THAT USES FRESH BLOOD SAMPLES WITH TARGETS SET BY THE NGSP LABORATORY NETWORK GPP. 

Approximately 100 different GHb assay methods are in current use. They range from low-throughput research laboratory component systems and manual minicolumn methods to high-throughput automated systems dedicated to HbA  measurements. Most methods can be classified into one of two groups according to assay principle (147,181,204). The first group includes methods that quantify GHb on the basis of charge differences between glycated and nonglycated components. Examples include cation-exchange chromatography and agar-gel electrophoresis. The second group includes methods that separate components on the basis of structural differences between glycated and nonglycated components. Examples include boronate affinity chromatography and immunoassay. Most charge-based and immunoassay methods quantify HbA , which is defined as HbA with glucose attached to the N-terminal valine of one or both β chains. Other methods quantify “total glycated hemoglobin,” which includes both HbA  and other Hb–glucose adducts (e.g., glucose–lysine adducts and glucose–α-chain N-terminal valine adducts). Generally, the results of methods that use different assay principles show excellent correlation, and there are no convincing data to show that any method type or analyte is clinically superior to any other. The GHb results reported for the same blood sample could differ considerably among methods, however, unless they have been standardized to a common reference [e.g., without standardization, the same blood sample could be read as 7% (42 mmol/mol) in one laboratory and 9% (75 mmol/mol) in another] (53,147,204,212–215).

In 1996, the NGSP was initiated to standardize GHb test results among laboratories to DCCT-equivalent values (215). The rationale for standardizing GHb test results to DCCT values was that the DCCT had determined the relationship between the results obtained for a specific GHb test (HbA ) and long-term complications in patients with type 1 diabetes (44,147,187). The NGSP was developed under the auspices of the American Association for Clinical Chemistry (AACC) and is endorsed by the ADA, which recommends that laboratories use only GHb methods that have passed certification testing by the NGSP (21,147). In addition, the ADA recommends that all laboratories performing GHb testing participate in the CAP proficiency-testing survey for HbA , which uses fresh whole-blood samples (216).

The NGSP Laboratory Network includes a variety of certified assay methods, each calibrated to the DCCT reference. The DCCT reference is an HPLC cation-exchange method that quantifies HbA ; this method is a CLSI-designated comparison method (217). The assay method has been used since 1978 and has demonstrated good long-term precision (between-run CVs are consistently <3%) (216). Secondary reference laboratories in the Network interact with manufacturers of GHb methods to assist them, first in calibrating their methods and then in providing comparison data for certification of traceability to the DCCT. Certification is valid for 1 year. An important adjunct to the program is the HbA  proficiency-testing survey administered by CAP. Since 1996 (starting with a pilot project including 500 laboratories and expanded to all laboratories in 1998), the survey has used fresh whole-blood samples with NGSP-assigned target values. Since initiation of the NGSP in 1996, the survey has documented a steady improvement in comparability of GHb values among laboratories, both within and between methods (216,218). In 2007, CAP initiated “accuracy-based” grading with the value of each sample assigned by the NGSP Network. The objective is to reduce bias and imprecision among assays. The NGSP Web site (http://www.ngsp.org) provides detailed information on the certification process and maintains a listing of certified assay methods (updated monthly) and factors that are known to interfere with specific methods.

In 1997, the IFCC formed a committee to develop a higher-order reference method and reference materials for HbA  analysis; the method was approved in 2001 (219,220). The analysis is performed by cleaving Hb with endoproteinase Glu-C and separating the resulting glycated and nonglycated N-terminal β-chain hexapeptides by HPLC (220). The hexapeptides are quantified with electrospray ionization mass spectrometry or capillary electrophoresis. The two methods use the same primary reference materials, and the results are essentially identical. HbA  is measured as the ratio of the glycated N-terminal peptide to the nonglycated N-terminal peptide and is reported in millimoles of deoxyfructosyl Hb per mole of Hb. Of note, preparing and measuring samples with this method is laborious, very expensive, and time-consuming. The method was never envisioned as a practical means of assaying clinical samples. It will only be used by manufacturers to standardize the assays. Like the NGSP, the IFCC has established a network of laboratories (221) (11 at the time of writing). The IFCC offers manufacturers calibrators and controls as well as a monitoring program (221). Unlike the NGSP, the IFCC network does not have a certification program.

A comparison of HbA  results obtained with pooled blood samples in the IFCC and NGSP (DCCT-aligned) networks has revealed a linear relationship (termed the “master equation”): NGSP% = (0.915 x IFCC%) + 2.15 (220). Although the clinical values obtained with assays standardized with the new IFCC method correlate tightly with NGSP values, the absolute HbA  values reported differ by 1.5%–2.0% HbA . Concern regarding the clinical impact of changing patients’ HbA  values led in 2007 to an agreement between the IFCC and the major diabetes organizations to report IFCC HbA  results (in millimoles per mole) as the equivalent NGSP DCCT-aligned result (a percentage based on the master equation) and as a calculated eAG based on the A -Derived Average Glucose (ADAG) study (209,222). In the revised agreement, published in 2010 (223), both NGSP and IFCC units were recommended, but the decision to report eAG was left to the discretion of individual countries. Notwithstanding the agreement, it appears unlikely that universal reporting of HbA  will be adopted; however, the master equation allows conversion between IFCC and NGSP numbers.

A. Preanalytical

RECOMMENDATION: LABORATORIES SHOULD BE AWARE OF POTENTIAL INTERFERENCES, INCLUDING HEMOGLOBINOPATHIES, THAT MAY AFFECT HbA1c TEST RESULTS, DEPENDING ON THE METHOD USED. IN SELECTING ASSAY METHODS, LABORATORIES SHOULD CONSIDER THE POTENTIAL FOR INTERFERENCES IN THEIR PARTICULAR PATIENT POPULATION. IN ADDITION, DISORDERS THAT AFFECT ERYTHROCYTE TURNOVER MAY CAUSE SPURIOUS RESULTS, REGARDLESS OF THE METHOD USED GPP. 

1. Patient variables.

HbA  results are not affected significantly by acute fluctuations in blood glucose concentrations, such as those occurring with illness or after meals; however, age and race reportedly influence HbA . Published data show age-related increases in HbA  values of approximately 0.1% per decade after age 30 years (224,225). Careful phenotyping of individuals with OGTT supports an increase in HbA  with age, even after removing from the study population patients with otherwise undiagnosed diabetes and persons with impaired glucose tolerance (224). The clinical implications of the small, but statistically significant, progressive increase in “normal” HbA  levels with aging remain to be determined (226).

The effects of race on HbA  values are controversial. Several studies have suggested a relatively higher HbA  in African American and Hispanic populations than in Caucasian populations at the same level of glycemia (225,227,228). The accumulated evidence suggests that there are differences in HbA  among racial groups; however, the measurement of chronic glucose concentrations in these studies has not been sufficiently frequent to capture adequately the actual mean glycemia. Moreover, it is not clear that the differences in HbA  have clinical significance. A recent analysis of 11,092 adults showed that blacks had mean HbA  values 0.4% higher than whites (229); however, race did not modify the association between HbA  concentration and adverse cardiovascular outcomes or death (229). The ADAG study, which included frequent glucose measurements, did not show a significantly different relationship between the calculated mean glucose concentration during 3 months and the HbA  value at the end of the 3 months for Africans/African Americans and Caucasians. The relatively small size of the African/African American population, however, limits the interpretation of this finding (209).

Any condition that shortens erythrocyte survival or decreases mean erythrocyte age (e.g., recovery from acute blood loss, hemolytic anemia) falsely lowers HbA  test results, regardless of the assay method (147). Vitamins C and E are reported to falsely lower test results, possibly by inhibiting Hb glycation (230,231). Iron deficiency anemia increases test results (232). Food intake has no significant effect on test results. Hypertriglyceridemia, hyperbilirubinemia, uremia, chronic alcoholism, chronic ingestion of salicylates, and opiate addiction reportedly interfere with some assay methods, falsely increasing results (204,233).

Several Hb variants (e.g., Hbs S, C, D, and E) and chemically modified Hb derivatives interfere with some assay methods [independently of any effects due to shortened erythrocyte survival (234–236); for a review, see (233)]. Depending on the particular hemoglobinopathy and assay method, results can be either falsely increased or falsely decreased. Some methods may give a value in the reference interval for a nondiabetic individual with an Hb variant, but that is no assurance that no interference is present. The interference may be subtle in the reference interval but may increase steadily with increasing HbA . Boronate affinity chromatography assay methods are generally considered to be less affected by Hb variants than other methods. In some instances, such as with most cation-exchange HPLC methods, manual inspection of chromatograms or an automated report by the device can alert the laboratory to the presence of either a variant or a possible interference. If an appropriate method is used, HbA  can be measured accurately in the vast majority of individuals heterozygous for Hb variants (for a summary of published studies, see http://www.ngsp.org). If altered erythrocyte turnover interferes with the relationship between mean blood glucose and HbA  values, or if a suitable assay method is not available for interfering Hb variants, alternative non–Hb-based methods for assessing long-term glycemic control (such as fructosamine assay) may be useful (233).

Given that interferences are method specific, product instructions from the manufacturer should be reviewed before the HbA  assay method is used. A list of interfering factors for specific assays is maintained on the NGSP Web site (http://www.ngsp.org). In selecting an assay method, a laboratory should consider characteristics of the patient population served (e.g., a high prevalence of Hb variants).

2. Sample collection, handling, and storage.

Blood can be obtained by venipuncture or by finger-stick capillary sampling (237,238). Blood tubes should contain the anticoagulant specified by the manufacturer of the HbA  assay method (EDTA can be used unless the manufacturer specifies otherwise). Sample stability is assay method specific (239,240). In general, whole-blood samples are stable for up to 1 week at 4°C (240). For most methods, whole-blood samples stored at −70°C or colder are stable over the long term (at least 1 year), but samples are not as stable at −20°C. Improper handling of samples, such as storage at high temperatures, can introduce large artifacts that may not be detectable, depending on the assay method.

Manufacturers have introduced a number of convenient blood-collection systems, including filter paper and small vials containing stabilizing/lysing reagent (241–243). These systems are designed for field collection of samples and routine mailing to the laboratory and are generally matched with specific assay methods. They should be used only if studies have been performed to establish the comparability of test results for these collection systems with standard sample-collection and handling methods for the specific assay method used.

B. Analytical

RECOMMENDATION: DESIRABLE SPECIFICATIONS FOR HbA1c MEASUREMENT ARE AN INTRALABORATORY CV <2% AND AN INTERLABORATORY CV <3.5%. AT LEAST TWO CONTROL MATERIALS WITH DIFFERENT MEAN VALUES SHOULD BE ANALYZED AS AN INDEPENDENT MEASURE OF ASSAY PERFORMANCE B (low). 

1. Performance goals and quality control.

Several expert groups have presented recommendations for assay performance. Early reports recommended that the interassay CV be <5% at normal and diabetic GHb concentrations (244). Subsequent reports have suggested lower CVs [e.g., intralaboratory CVs <3% (245) or <2% (246), and interlaboratory CVs <5% (245)]. Intraindividual CVs for healthy persons are very small (<2%), and many current assay methods can achieve intralaboratory and interlaboratory CVs of <2% and <3%, respectively (247). A recent statistical analysis calculated appropriate goals for HbA  assay performance (218). If the reference change value (also termed “critical difference”) is used, an analytical CV ≤2% will produce a 95% probability that a difference of ≥0.5% HbA  between successive patient samples is due to a significant change in glycemic control [when HbA  is 7% (53 mmol/mol)]. In addition, if a method has no bias, a CV of 3.5% is necessary to have 95% confidence that the HbA  result for a patient with a “true” HbA  of 7% (53 mmol/mol) will be between 6.5% and 7.5% (between 48 and 58 mmol/mol) (218). We recommend an intralaboratory CV <2% and an interlaboratory CV <3.5%. For a single method, the goal should be an interlaboratory CV <3%.

A laboratory should include two control materials with different mean values (high and low) at both the beginning and the end of each day's run. Frozen whole-blood controls stored in single-use aliquots at −70°C or colder are ideal and are stable for months or even years, depending on the assay method. Lyophilized controls are commercially available but, depending on the assay method, may show matrix effects when new reagents or columns are introduced. We recommend that a laboratory consider using both commercial and in-house controls to optimize performance monitoring.

2. Reference intervals.

A laboratory should determine its own reference interval according to CLSI guidelines (CLSI Document C28A), even if the manufacturer has provided one. Nondiabetic test individuals should be nonobese, have an FPG concentration <5.6 mmol/L (100 mg/dL), and, ideally, have a 2-h post-OGTT plasma glucose value of <11.1 mmol/L (200 mg/dL). For NGSP-certified assay methods, reference intervals should not deviate substantially (e.g., >0.5%) from 4%–6% (20–42 mmol/mol). Note that treatment target values recommended by the ADA and other clinical organizations, not reference intervals, are used to evaluate metabolic control in patients.

RECOMMENDATION: SAMPLES WITH HbA1c RESULTS BELOW THE LOWER LIMIT OF THE REFERENCE INTERVAL OR >15% HbA1c SHOULD BE VERIFIED BY REPEAT TESTING B (low). 

RECOMMENDATION: HbA1c VALUES THAT ARE INCONSISTENT WITH THE CLINICAL PRESENTATION SHOULD BE INVESTIGATED FURTHER GPP. 

3. Out-of-range samples.

A laboratory should repeat testing for all sample results below the lower limit of the reference interval, and if these results are confirmed, the physician should be informed to determine whether the patient has a variant Hb or shows evidence of erythrocyte destruction. If possible, the repeat HbA  measurement should be performed with a method based on an analytical principle that is different from the initial assay. In addition, samples with results >15% HbA  (140 mmol/mol) should be assayed a second time; if the results are confirmed, the possibility of an Hb variant should be considered (233). Any result that does not correlate with the clinical impression should also be investigated.

4. Removal of labile GHb.

The formation of HbA  involves an intermediate Schiff base, which is called “pre-A ” or “labile A ” (248). This Schiff base is formed rapidly with hyperglycemia and can interfere with some HbA  assay methods if it is not completely removed or separated. Most currently available automated assays either remove the labile pre-HbA  during the assay process or do not measure the labile product.

4. Interpretation

A. Laboratory–physician interactions.

A laboratory should work closely with physicians who order HbA  testing. Proper interpretation of test results requires an understanding of the assay method, including its known interferences. For example, if the assay method is affected by hemoglobinopathies (independently of any shortened erythrocyte survival) or uremia, the physician should be made aware of this interference.

An important advantage of using an NGSP-certified method is that the laboratory can provide specific information relating HbA  test results to both mean glycemia and outcome risks as defined in the DCCT and UKPDS (44,147,187). This information is available on the NGSP Web site. For example, each 1% (approximately 11 mmol/mol) change in HbA  is related to a change in the mean plasma glucose concentration of approximately 1.6 mmol/L (29 mg/dL). Reporting HbA  results with a calculated eAG will eliminate the need for healthcare providers or patients to perform these calculations themselves. The equation generated by the ADAG study is the most reliable to date (209).

Some evidence suggests that immediate feedback of HbA  test results to patients at the time of the clinic visit leads to an improvement in their long-term glycemic control (249,250). Not all publications have supported this observation (251), however, and additional studies are needed to confirm these findings before this strategy can be generally recommended. It is possible to achieve the goal of having HbA  test results available at the time of the clinic visit by either having the patient send in a blood sample shortly before the scheduled clinic visit or having a rapid-assay system convenient to the clinic.

B. Clinical application

RECOMMENDATION: TREATMENT GOALS SHOULD BE BASED ON ADA RECOMMENDATIONS, WHICH INCLUDE GENERALLY MAINTAINING HbA1c CONCENTRATIONS AT <7% AND MORE-STRINGENT GOALS IN SELECTED INDIVIDUAL PATIENTS IF THEY CAN BE ACHIEVED WITHOUT SIGNIFICANT HYPOGLYCEMIA OR OTHER ADVERSE TREATMENT EFFECTS. SOMEWHAT HIGHER INTERVALS ARE RECOMMENDED FOR CHILDREN AND ADOLESCENTS AND MAY BE APPROPRIATE FOR PATIENTS WITH A LIMITED LIFE EXPECTANCY, EXTENSIVE COMORBID ILLNESSES, A HISTORY OF SEVERE HYPOGLYCEMIA, OR ADVANCED COMPLICATIONS (NOTE THAT THESE VALUES ARE APPLICABLE ONLY IF THE NGSP HAS CERTIFIED THE ASSAY METHOD AS TRACEABLE TO THE DCCT REFERENCE) A (high). 

1. Treatment goals.

HbA  measurements are now a routine component of the clinical management of patients with diabetes. Principally on the basis of the DCCT results, the ADA has recommended that a primary goal of therapy be an HbA  value <7% (53 mmol/mol) (21). Lower targets may be considered for individual patients, e.g., in diet-treated type 2 diabetes. Other major clinical organizations have recommended similar targets (53); however, recent studies that used multiple medications to treat type 2 diabetes and aimed for HbA  concentrations <6.5% (48 mmol/mol) have not demonstrated consistent benefits and failed to observe any benefit with regard to macrovascular disease, compared with interventions that achieved HbA  values 0.8% to 1.1% higher (50–52). The ACCORD (Action to Control Cardiovascular Risk in Diabetes) study demonstrated increased mortality with very intensive diabetes therapy [HbA , 6.4% vs. 7.5% (46 vs. 58 mmol/mol)]. These HbA  values apply only to assay methods that have been certified as traceable to the DCCT reference, with a reference interval of approximately 4%–6% HbA  (20–42 mmol/mol). In the DCCT, each 10% reduction in HbA  (e.g., 12% vs. 10.8% or 8% vs. 7.2%) was associated with an approximately 45% lower risk for the progression of diabetic retinopathy (42). Comparable risk reductions were found in the UKPDS (197). Also of note is that decreases in HbA  were associated in the DCCT and UKPDS with an increased risk for severe hypoglycemia.

RECOMMENDATION: HbA1c TESTING SHOULD BE PERFORMED AT LEAST BIANNUALLY IN ALL PATIENTS AND QUARTERLY FOR PATIENTS WHOSE THERAPY HAS CHANGED OR WHO ARE NOT MEETING TREATMENT GOALS B (low). 

2. Testing frequency.

There is no consensus on the optimal frequency of HbA  testing. The ADA recommends (21), “For any individual patient, the frequency of A1C testing should be dependent on the clinical situation, the treatment regimen used, and the judgment of the clinician.” In the absence of well-controlled studies that suggest a definite testing protocol, expert opinion recommends HbA  testing “at least two times a year in patients who are meeting treatment goals (and who have stable glycemic control) … and quarterly in patients whose therapy has changed or who are not meeting glycemic goals” (21). These testing recommendations are for nonpregnant patients with either type 1 or type 2 diabetes. In addition, all patients with diabetes who are admitted to a hospital should have HbA  measured if the results of testing in the previous 2–3 months are not available (21). Diabetes quality-assurance programs [e.g., Provider Recognition Program and HEDIS (Healthcare Effectiveness Data and Information Set) (199,200)] have generally required documentation of the percentage of diabetic patients who have had at least one HbA  measurement during the preceding year. Studies have established that serial HbA  measurements (quarterly for 1 year) produce large improvements in HbA  values in patients with type 1 diabetes (252).

3. Interpretation.

HbA  values in patients with diabetes constitute a continuum. They range from within the reference interval in a small percentage of patients whose mean plasma glucose concentrations are close to those of nondiabetic individuals, to markedly increased values (e.g., two- to threefold increases in some patients) that reflect an extreme degree of hyperglycemia. A proper interpretation of HbA  test results requires that physicians understand the relationship between HbA  values and mean plasma glucose, the kinetics of HbA , and specific assay limitations/interferences (147). Small changes in HbA  (e.g., ±0.3% HbA ) over time may reflect assay imprecision rather than a true change in glycemic status (218).

5. Emerging considerations

RECOMMENDATION: HbA1c MAY BE USED FOR THE DIAGNOSIS OF DIABETES, WITH VALUES ≥6.5% BEING DIAGNOSTIC. AN NGSP-CERTIFIED METHOD SHOULD BE PERFORMED IN AN ACCREDITED LABORATORY. ANALOGOUS TO ITS USE IN THE MANAGEMENT OF DIABETES, FACTORS THAT INTERFERE WITH OR ADVERSELY AFFECT THE HbA1c ASSAY WILL PRECLUDE ITS USE IN DIAGNOSIS A (moderate). RECOMMENDATION: POINT-OF-CARE HbA1c ASSAYS ARE NOT SUFFICIENTLY ACCURATE TO USE FOR THE DIAGNOSIS OF DIABETES B (moderate). 

A. Use of HbA1c for diabetes screening/diagnosis.

The role of HbA  in the diagnosis of diabetes has been considered for several years (19,24,37,253). In the past, the lack of standardization has been a major barrier. With improved standardization through the NGSP and the IFCC, and new data demonstrating the association between HbA  concentrations and the risk for retinopathy, the International Expert Committee recommended the use of HbA  in the diagnosis of diabetes (20). In making its recommendation, the Committee also considered several technical advantages of HbA  testing compared with glucose testing, such as its preanalytical stability and decreased biological variation. Finally, the clinical convenience of the HbA  assay, which requires no patient fasting or tolerance tests, compared with glucose-based diagnosis, convinced the Committee to recommend HbA  testing for diagnosis. A value ≥6.5% (48 mmol/mol) was considered diagnostic on the basis of the observed relationship with retinopathy. For diagnosis, a positive test result [≥6.5% (48 mmol/mol)] should be confirmed with a repeat assay. The ADA indicates that although either an HbA  assay or a glucose assay (FPG or OGTT) can be used as the confirmatory test, repeating the same test is preferred (93). The frequency of HbA  testing for diagnosis has not been established, but guidelines similar to those for glucose-based testing seem appropriate. Only NGSP-certified HbA  methods should be used to diagnose (or screen for) diabetes. The ADA cautions that point-of-care devices for measuring HbA  should not be used for diagnosis (93). Although several point-of-care HbA  assays are NGSP certified, the test is waived in the U.S., and proficiency testing is not necessary. Therefore, no objective information is available concerning their performance in the hands of those who measure HbA  in patient samples. A recent evaluation revealed that few point-of-care devices that measure HbA  met acceptable analytical performance criteria (254). Absent objective—and ongoing—documentation of performance with accuracy-based proficiency testing that uses whole blood (or other suitable material that is free from matrix effects), point-of-care HbA  devices should not be used for diabetes diagnosis or screening. The ADA has endorsed the use of HbA  for the diagnosis of diabetes (Table 4) (21), as have The Endocrine Society (255) and the WHO. The American Association of Clinical Endocrinologists supports it in a more limited fashion. Other international organizations, including the IDF, are considering HbA  testing for diabetes diagnosis and screening. Note that glucose-based testing for diagnosis remains valid. Analogous to the concept of impaired fasting glucose and impaired glucose tolerance, individuals with HbA  values between 5.7% and 6.4% (39 and 46 mmol/mol) should be considered at high risk for future diabetes and should be counseled about effective measures to reduce their risk (93).

B. Use of other glycated proteins, including advanced glycation end products, for routine management of diabetes.

Further studies are needed to determine whether other glycated proteins, such as fructosamine or glycated serum albumin, are clinically useful for routine monitoring of patients’ glycemic status. Further studies are also needed to determine if measurements of advanced glycation end products are clinically useful as predictors of risk for chronic diabetes complications (256). Only one study of a subset of DCCT patients evaluated advanced glycation end products in dermal collagen obtained with skin biopsies. Interestingly, the concentration of advanced glycation end products in dermal collagen correlated more strongly with the presence of complications than the mean HbA  values (257). The clinical role of such measurements remains undefined. Similarly, the role of noninvasive methods that use light to measure glycation transdermally is undefined.

C. Global harmonization of HbA1c testing and uniform reporting of results.

As noted above, the NGSP has largely succeeded in standardizing the GHb assay across methods and laboratories. Furthermore, the IFCC standardization, which provides a chemically discrete standard, is being implemented worldwide. The reporting recommendations (223) need to be implemented with the education of healthcare providers and patients. Some believe that reporting eAG should complement the current reporting in NGSP/DCCT-aligned units (percentages) and the new IFCC results (millimoles per mole), because the eAG results will be in the same units (millimoles per liter or milligrams per deciliter) as patients’ self-monitoring. Educational campaigns will be necessary, however, to ensure clear understanding of this assay, which is central to diabetes management.

GENETIC MARKERS

1. Use

A. Diagnosis/screening

RECOMMENDATION: ROUTINE MEASUREMENT OF GENETIC MARKERS IS NOT OF VALUE AT THIS TIME FOR THE DIAGNOSIS OR MANAGEMENT OF PATIENTS WITH TYPE 1 DIABETES. FOR SELECTED DIABETIC SYNDROMES, INCLUDING NEONATAL DIABETES, VALUABLE INFORMATION CAN BE OBTAINED WITH DEFINITION OF DIABETES-ASSOCIATED MUTATIONS A (moderate). 

1. Type 1 diabetes.

Genetic markers are currently of limited clinical value in evaluating and managing patients with diabetes; however, mutational analysis is rapidly emerging for classifying diabetes in the neonate (258–260) and in young patients with a dominant family history of diabetes, often referred to as “maturity-onset diabetes of the young” (MODY) (261). Type 1 or autoimmune diabetes is strongly associated with HLA-DR (major histocompatibility complex, class II, DR) and HLA-DQ (major histocompatibility complex, class II, DQ) genes. HLA-DQA1 and HLA-DQB1 genotyping can be useful to indicate the absolute risk of diabetes. The HLA DQA1*0301–DQB1*0302 and DQA1*0501–DQB1*0201 haplotypes, alone or in combination, may account for up to 90% of children and young adults with type 1 diabetes (262). These two haplotypes may be present in 30%–40% of a Caucasian population, and HLA is therefore necessary but not sufficient for disease. The HLA-DQ and HLA-DR genetic factors are by far the most important determinants of type 1 diabetes risk (263). HLA typing may be used in combination with islet autoantibody analyses to exclude type 1 diabetes in assisting in the diagnosis of genetic forms of diabetes.

As indicated below, HLA-DR/DQ typing can be useful to indicate a modified risk of type 1 diabetes in persons positive for islet cell autoantibodies, because protective alleles do not prevent the appearance of islet cell autoantibodies (most often as single autoantibodies) but may delay the onset of clinical diabetes. Typing of the class II major histocompatibility antigens or HLA-DRB1, -DQA1, and -DQB1 is not diagnostic for type 1 diabetes. Some haplotypes induce susceptibility, however, whereas others provide significant delay or even protection. Thus, HLA-DR/DQ typing can be used only to increase or decrease the probability of type 1 diabetes presentation and cannot be recommended for routine clinical diagnosis or classification (264).

The precision in the genetic characterization of type 1 diabetes may be extended by typing for polymorphisms in several genetic factors identified in genome-wide association studies (265). Non-HLA genetic factors include the INS (insulin), PTPN22 [protein tyrosine phosphatase, non-receptor type 22 (lymphoid)], and CTLA4 (cytotoxic T-lymphocyte–associated protein 4) genes and several others (263,265). These additional genetic factors may assist in assigning a probability for a diagnosis of type 1 diabetes of uncertain etiology (266).

It is possible to screen newborn children to identify those at increased risk for developing type 1 diabetes (267–269). This strategy cannot be recommended until a proven intervention is available to delay or prevent the disease (270). There is some evidence that early diagnosis may prevent hospitalization for ketoacidosis and preserve residual β-cells (271). The rationale for the approach is thus discussed below under Emerging Considerations.

RECOMMENDATION: THERE IS NO ROLE FOR ROUTINE GENETIC TESTING IN PATIENTS WITH TYPE 2 DIABETES. THESE STUDIES SHOULD BE CONFINED TO THE RESEARCH SETTING AND EVALUATION OF SPECIFIC SYNDROMES A (moderate). 

2. Type 2 diabetes.

Fewer than 5% of patients with type 2 diabetes have been resolved on a molecular genetic basis, and, not surprisingly, most of these patients have an autosomal dominant form of the disease or very high degrees of insulin resistance. Type 2 diabetes is a heterogeneous polygenic disease with both resistance to the action of insulin and defective insulin secretion (3,4). Multiple genetic factors interact with exogenous influences (e.g., environmental factors such as obesity) to produce the phenotype. Identification of the affected genes is therefore highly complex. Recent genome-wide association studies have identified >30 genetic factors that increase the risk for type 2 diabetes (272,273). The risk alleles in these loci all have relatively small effects (odds ratios of 1.1 to 1.3), however, and do not significantly enhance our ability to predict the risk of type 2 diabetes (274).

3. MODY.

Detecting mutations in MODY patients and their relatives is technically feasible. The reduced costs of sequencing and emerging new technologies make it possible to identify mutations and to properly classify MODY patients on the basis of specific mutations. As direct automated sequencing of genes becomes standard, it is likely that the detection of specific diabetes mutations will become routine.

B. Monitoring/prognosis.

Although genetic screening may provide information about prognosis and could be useful for genetic counseling, genotype may not correlate with the phenotype. In addition to environmental factors, interactions among multiple loci for the expression of quantitative traits may be involved. Genetic identification of a defined MODY will have value for anticipating the prognosis. Infants with neonatal diabetes due to a mutation in the KCNJ11 (potassium inwardly-rectifying channel, subfamily J, member 11; also known as KIR6.2) gene may be treated with sulfonylurea rather than with insulin (258,259).

2. Rationale

The HLA system, which has a fundamental role in the adaptive immune response, exhibits considerable genetic complexity. The HLA complex on chromosome 6 contains class I and class II genes that code for several polypeptide chains (275). The major (classic) class I genes are HLA-A (major histocompatibility complex, class I, A), HLA-B (major histocompatibility complex, class I, B), and HLA-C (major histocompatibility complex, class I, C). The loci of class II genes are designated by three letters: the first (D) indicates the class, the second (M, O, P, Q, or R) indicates the family, and the third (A or B) indicates the chain. Both classes of the encoded molecules are heterodimers. Class I molecules consist of an α chain and β -microglobulin, and class II molecules have α and β chains. The function of the HLA molecules is to present short peptides derived from pathogens or autoantigens to T cells to initiate the adaptive immune response (275). Genetic studies have revealed an association between certain HLA alleles and autoimmune diseases. These diseases include, but are not confined to, ankylosing spondylitis, celiac disease, Addison disease, and type 1 diabetes (275). Not only the disease but also autoantibodies, which are markers of the disease's pathogenesis, are often associated with HLA-DRB1, HLA-DQA1, and HLA-DQB1, indicating that self-peptides may also be presented to T cells (262).

Genetic testing for syndromic forms of diabetes is the same as that for the underlying syndrome itself (1). Such forms of diabetes may be secondary to the obesity associated with Prader–Willi syndrome, which maps to chromosome 15q, or to the absence of adipose tissue inherent to the recessive Seip–Berardinelli syndrome of generalized lipodystrophy, which maps to chromosome 9q34 (1,276). More than 60 distinct genetic disorders are associated with glucose intolerance or frank diabetes. Many forms of type 2 diabetes (which are usually strongly familial) will probably be understood in defined genetic terms. The complexity of the genetic factors that contribute to type 2 diabetes risk is substantial (272,273). Several genetic factors for MODY have been identified, and there are large numbers of individual mutants. Persons at risk within MODY pedigrees can be identified through genetic means. Depending on the specific MODY mutation, the disease can be mild (e.g., glucokinase mutation) and not usually associated with long-term complications of diabetes, or it can be as severe as typical type 1 diabetes [e.g., hepatocyte nuclear factor (HNF) mutations] (277).

Eight different MODYs have been identified. MODY-1, -3, -4, -5, -6, and -7 are all caused by mutations in the genes encoding transcription factors that regulate the expression of genes in pancreatic β-cells. These genes are HNF4A (hepatocyte nuclear factor 4, alpha) in MODY-1, HNF1A (HNF1 homeobox A) in MODY-3, HNF1B (HNF1 homeobox B) in MODY-5, PDX1 (pancreatic and duodenal homeobox 1; formerly known as IPF1) in MODY-4, NEUROD1 (neurogenic differentiation 1; also known as NeuroD and BETA2) in MODY-6, and KLF1 [Kruppel-like factor 1 (erythroid)] in MODY-7. Homozygous mutations of the PDX1 gene have been shown to lead to pancreatic agenesis, and heterozygous PDX1 mutations have been shown to cause MODY-4 (276). The modes of action of the HNF lesions in MODY are still not clear. It is likely that mutations in HNF1A, HNF1B, and HNF4A cause diabetes because they impair insulin secretion. MODY-2 is caused by mutations in the GCK [glucokinase (hexokinase 4)] gene. The product of the gene is an essential enzyme in the glucose-sensing mechanism of β-cells, and mutations in this gene lead to partial deficiencies of insulin secretion. MODY-8 is due to mutations in the CEL [carboxyl ester lipase (bile salt-stimulated lipase)] gene.

3. Analytical considerations

A detailed review of analytical issues will not be attempted here, because genetic testing for diabetes outside of a research setting is currently not recommended for clinical care. Serologic HLA typing should be replaced by molecular methods, because antibodies with a mixture of specificities and cross-reactivities have been estimated to give inaccurate results in approximately 15% of typings.

A. Preanalytical.

Mutations are detected by using genomic DNA extracted from peripheral blood leukocytes. Blood samples should be drawn into test tubes containing EDTA, and the DNA should be extracted within 3 days; longer periods both lower the yield and degrade the quality of the DNA obtained. Genomic DNA can be isolated from fresh or frozen whole blood by lysis, digestion with proteinase K, extraction with phenol, and then dialysis. The average yield is 100–200 μg DNA from 10 mL of whole blood. DNA samples are best kept at −80°C in Tris-EDTA solution. These conditions maintain DNA sample integrity virtually indefinitely.

B. Analytical.

Methods for the detection of mutations vary with the type of mutation. MODY mutations have substitution, deletion, or insertion of nucleotides in the coding regions of the genes. These mutations are detected by the PCR. Detailed protocols for detecting specific mutations are beyond the scope of this review.

4. Interpretation

For screening for the propensity for type 1 diabetes in general populations, HLA-D genes are the most important, contributing as much as 50% of familial susceptibility (278). HLA-DQ genes appear to be central to the HLA-associated risk of type 1 diabetes, albeit HLA-DR genes may be independently involved [for reviews, see (279,280)]. The heterodimeric proteins that are expressed on antigen-presenting cells, B lymphocytes, platelets, and activated T cells—but not other somatic cells—are composed of cis- and trans-complementated α- and β-chain heterodimers. Thus, in any individual, four possible DQ dimers are encoded. Persons at the highest genetic risk for type 1 diabetes are those in whom all four DQ combinations meet this criterion. Thus, persons heterozygous for HLA DRB1*04–DQA1*0301–DQB1*0302 and DRB1*03–DQA1*0501–DQB1*0201 are the most susceptible, with an absolute lifetime risk of type 1 diabetes in the general population of about 1 in 12. Persons who are protected from developing type 1 diabetes at a young age are those with HLA DRB1*15–DQA1*0201–DQB1*0602 haplotypes in particular (281). Individuals with DRB1*11 or 04 who also have DQB1*0301 are not likely to develop type 1 diabetes at a young age. HLA-DR is also involved in susceptibility to type 1 diabetes, in that the B1*0401 and 0405 subtypes of DRB1*04 are susceptible, whereas the 0403 and 0406 subtypes are negatively associated with the disease, even when found in HLA genotypes with the susceptible DQA1*0301–DQB1*0302. DR molecules are heterodimers also; however, the DRα chain is invariant in all persons. Additional DRβ chains (B3, B4, and B5) are not important.

Class II MHC molecules are involved in antigen presentation to CD4 helper cells, and the associations outlined above are likely to be explained by defective affinities to islet cell antigenic peptides, leading to persistence of T-helper cells that escape thymic ablation. Class I HLA molecules are also implicated in type 1 diabetes. Multiple non-HLA loci also contribute to susceptibility to type 1 diabetes (279). For example, the variable nucleotide tandem repeat (VNTR) upstream from the INS gene on chromosome 11q is useful for predicting the development of type 1 diabetes, with alleles with the longest VNTR having protective effects. Typing newborn infants for both HLA-DR and HLA-DQ—and to a lesser degree the INS gene—allows prediction of type 1 diabetes to better than 1 in 10 in the general population. The risk of type 1 diabetes in HLA-identical siblings of a proband with type 1 diabetes is 1 in 4, whereas siblings who have HLA haplotype identity have a 1 in 12 risk and those with no shared haplotype have a 1 in 100 risk (280). Genome-wide association studies have confirmed that the following non-HLA genetic factors increase the risk for type 1 diabetes, both in first-degree relatives of type 1 diabetic patients and in the general population: INS, VNTR, CTLA4, PTPN22, and others (263,265,282,283).

5. Emerging considerations

The sequencing of the human genome and the formation of consortia have produced advances in the identification of the genetic bases for both type 1 and type 2 diabetes. This progress should ultimately lead to family counseling, prognostic information, and the selection of optimal treatments (276,284).

AUTOIMMUNE MARKERS

1. Use

RECOMMENDATION: ISLET CELL AUTOANTIBODIES ARE RECOMMENDED FOR SCREENING NONDIABETIC FAMILY MEMBERS WHO WISH TO DONATE PART OF THEIR PANCREAS FOR TRANSPLANTATION INTO A RELATIVE WITH END-STAGE TYPE 1 DIABETES B (low). RECOMMENDATION: ISLET CELL AUTOANTIBODIES ARE NOT RECOMMENDED FOR ROUTINE DIAGNOSIS OF DIABETES, BUT STANDARDIZED ISLET CELL AUTOANTIBODY TESTS MAY BE USED FOR CLASSIFICATION OF DIABETES IN ADULTS AND IN PROSPECTIVE STUDIES OF CHILDREN AT GENETIC RISK FOR TYPE 1 DIABETES AFTER HLA TYPING AT BIRTH B (low). 

No therapeutic intervention that will prevent diabetes has been identified (279,280). Therefore, although several islet cell autoantibodies have been detected in individuals with type 1 diabetes, their measurement has limited use outside of clinical studies. Currently, islet cell autoantibodies are not used in routine management of patients with diabetes. This section focuses on the pragmatic aspects of clinical laboratory testing for islet cell autoantibodies.

A. Diagnosis/screening

1. Diagnosis.

In type 1 diabetes, the pancreatic islet β-cells are destroyed and lost. In the vast majority of these patients, the destruction is mediated by an autoimmune attack (285). This disease is termed “type 1A” or “immune-mediated diabetes” (Table 1). Islet cell autoantibodies comprise autoantibodies to islet cell cytoplasm (ICA), to native insulin [referred to as “insulin autoantibodies” (IAA) (286)], to the 65-kDa isoform of glutamic acid decarboxylase (GAD65A) (287–289), to two insulinoma antigen 2 proteins [IA-2A (290) and IA-2βA (also known as phogrin) (291)], and to three variants of zinc transporter 8 (ZnT8A) (292,293). Autoantibody markers of immune destruction are usually present in 85% to 90% of individuals with type 1 diabetes when fasting hyperglycemia is initially detected (1). Autoimmune destruction of β-cells has multiple genetic predispositions and is modulated by undefined environmental influences. The autoimmunity may be present for months or years before the onset of hyperglycemia and subsequent symptoms of diabetes. After years of type 1 diabetes, some antibodies fall below detection limits, but GAD65A usually remains increased. Patients with type 1A diabetes have a significantly increased risk of other autoimmune disorders, including celiac disease, Graves disease, thyroiditis, Addison disease, and pernicious anemia (128). As many as 1 in 4 females with type 1 diabetes have autoimmune thyroid disease, whereas 1 in 280 patients develop adrenal autoantibodies and adrenal insufficiency. A minority of patients with type 1 diabetes (type 1B, idiopathic) have no known etiology and no evidence of autoimmunity. Many of these patients are of African or Asian origin.

RECOMMENDATION: SCREENING PATIENTS WITH TYPE 2 DIABETES FOR ISLET CELL AUTOANTIBODIES IS NOT RECOMMENDED AT PRESENT. STANDARDIZED ISLET CELL AUTOANTIBODIES ARE TESTED IN PROSPECTIVE CLINICAL STUDIES OF TYPE 2 DIABETIC PATIENTS TO IDENTIFY POSSIBLE MECHANISMS OF SECONDARY FAILURES OF TREATMENT OF TYPE 2 DIABETES B (low). RECOMMENDATION: SCREENING FOR ISLET CELL AUTOANTIBODIES IN RELATIVES OF PATIENTS WITH TYPE 1 DIABETES OR IN PERSONS FROM THE GENERAL POPULATION IS NOT RECOMMENDED AT PRESENT. STANDARDIZED ISLET CELL AUTOANTIBODIES ARE TESTED IN PROSPECTIVE CLINICAL STUDIES B (low). 

2. Screening.

Only about 15% of patients with newly diagnosed type 1 diabetes have a first-degree relative with the disease (294). The risk of developing type 1 diabetes in relatives of patients with the disease is approximately 5%, which is 15-fold higher than the risk in the general population (1 in 250–300 lifetime risk). Screening relatives of type 1 diabetic patients for islet cell autoantibodies can identify those at high risk for the disease; however, as many as 1%–2% of healthy individuals have a single autoantibody against insulin, IA-2, GAD65, or ZnT8 and are at low risk of developing type 1 diabetes (295). Because of the low prevalence of type 1 diabetes (approximately 0.3% in the general population), the positive predictive value of a single islet cell autoantibody will be low (280). The presence of multiple islet cell autoantibodies (IAA, GAD65A, IA-2A/IA-2βA, or ZnT8A) is associated with a >90% risk of type 1 diabetes (292,295,296); however, until cost-effective screening strategies can be developed for young children and until effective intervention therapy to prevent or delay the onset of the disease becomes available, such testing cannot be recommended outside of a research setting.

Children with certain HLA-DR and/or HLA-DQB1 chains (*0602/*0603/*0301) are mostly protected from type 1 diabetes, but not from developing islet cell autoantibodies (297). Because islet cell autoantibodies in these individuals have substantially reduced predictive significance, they are often excluded from prevention trials.

Approximately 5%–10% of adult Caucasian patients who present with a type 2 diabetes phenotype also have islet cell autoantibodies (298), particularly GAD65A, which predict insulin dependency. This condition has been termed “latent autoimmune diabetes of adulthood” (LADA) (299), “type 1.5 diabetes” (300), or “slowly progressive IDDM” (301). Although GAD65A-positive diabetic patients progress faster to absolute insulinopenia than do antibody-negative patients, many antibody-negative (type 2) diabetic adults also progress (albeit more slowly) to insulin dependency with time. Some of these patients may show T-cell reactivity to islet cell components (300). Islet cell autoantibody testing in patients with type 2 diabetes has limited utility, because the institution of insulin therapy is based on glucose control.

RECOMMENDATION: THERE IS CURRENTLY NO ROLE FOR MEASUREMENT OF ISLET CELL AUTOANTIBODIES IN THE MONITORING OF PATIENTS IN CLINICAL PRACTICE. ISLET CELL AUTOANTIBODIES ARE MEASURED IN RESEARCH PROTOCOLS AND IN SOME CLINICAL TRIALS AS SURROGATE END POINTS B (low). 

B. Monitoring/prognosis.

No acceptable therapy has been demonstrated to prolong the survival of islet cells once diabetes has been diagnosed or to prevent the clinical onset of diabetes in islet cell autoantibody–positive individuals (279). Thus, the use of repeated testing for islet cell autoantibodies to monitor islet cell autoimmunity is not clinically useful at present. In islet cell or pancreas transplantation, the presence or absence of islet cell autoantibodies may clarify whether subsequent failure of the transplanted islets is due to recurrent autoimmune disease or to rejection (302). When a partial pancreas has been transplanted from an identical twin or other HLA-identical sibling, the appearance of islet cell autoantibodies may raise consideration regarding the use of immunosuppressive agents to try to halt the recurrence of diabetes. Notwithstanding these theoretical advantages, the value of this therapeutic strategy has not been established.

Some experts have proposed that testing for islet cell autoantibodies may be useful in the following situations: 1) to identify a subset of adults initially thought to have type 2 diabetes but who have islet cell autoantibody markers of type 1 diabetes and who progress to insulin dependency (303); 2) to screen nondiabetic family members who wish to donate a kidney or part of their pancreas for transplantation; 3) to screen women with GDM to identify those at high risk of progression to type 1 diabetes; and 4) to distinguish type 1 from type 2 diabetes in children to institute insulin therapy at the time of diagnosis (304,305). For example, some pediatric diabetologists now treat children thought to have type 2 diabetes with oral medications but treat autoantibody-positive children immediately with insulin. It is possible, however, to follow patients who are islet cell autoantibody positive to the point of metabolic decompensation and then institute insulin therapy. The Diabetes Prevention Trial of Type 1 Diabetes (DPT-1) study failed to show a protective effect of parenteral insulin (306).

2. Rationale

The presence of islet cell autoantibodies suggests that insulin therapy is the most appropriate therapeutic option, especially in a young person. Conversely, in children or young people without islet cell autoantibodies, consideration may be given to a trial of oral agents and lifestyle changes. There is no unanimity of opinion, but the presence of islet cell autoantibodies may alter therapy for subsets of patients, including Hispanic and African American children with a potential diagnosis of nonautoimmune diabetes, adults with islet cell autoantibodies but clinically classified as type 2 diabetic, and children with transient hyperglycemia. The majority of nondiabetic individuals who have only one autoantibody may never develop diabetes. Although the production of multiple islet cell autoantibodies is associated with considerably increased diabetes risk (295,296), approximately 20% of individuals presenting with new-onset diabetes produce only a single autoantibody. Prospective studies of children reveal that islet cell autoantibodies may be transient, indicating that an islet autoantibody may have disappeared prior to the onset of hyperglycemia or diabetes symptoms (307).

3. Analytical considerations

RECOMMENDATION: IT IS IMPORTANT THAT ISLET CELL AUTOANTIBODIES BE MEASURED ONLY IN AN ACCREDITED LABORATORY WITH AN ESTABLISHED QUALITY-CONTROL PROGRAM AND PARTICIPATION IN A PROFICIENCY-TESTING PROGRAM GPP. 

For IAAs, a radioisotopic method that calculates the displaceable insulin radioligand binding after the addition of excess nonradiolabeled insulin (308) is recommended. Results are reported as positive when specific antibody binding exceeds the 99th percentile or possibly exceeds the mean plus 2 (or 3) SDs for healthy persons. Insulin autoantibody binding has been noted not to be normally distributed. Each laboratory needs to assay at least 100–200 healthy individuals to determine the distribution of binding. An important caveat concerning IAA measurement is that insulin antibodies develop after insulin therapy, even in persons who use human insulin. Data from the Diabetes Autoantibody Standardization Program (DASP) demonstrate that the interlaboratory imprecision for IAA is inappropriately large (309).

GAD65A and IA-2A are measured with standardized radiobinding assays, which are performed with 35S-labeled recombinant human GAD65 or IA-2 generated by coupled in vitro transcription translation with [35S]methionine or other 35S- or 3H-labeled amino acids (310). Commercially available methods for GAD65A and IA-2A are available as a radioimmunoassay with 125I-labeled GAD65 (truncated at the N-terminal end to promote solubility) and IA-2, respectively. In addition, immunoassays without radiolabel are commercially available for both GAD65A and IA-2A. Major efforts have been made to standardize GAD65A and IA-2A measurements (309,311). A WHO standard for both GAD65A and IA-2A has been established, and GAD65A and IA-2A amounts are expressed in international units (312). The binding of labeled autoantigen to autoantibodies is normally distributed. Cutoff values should be determined from 100–200 serum samples obtained from healthy individuals. GAD65A and IA-2A results should be reported as positive when the signal exceeds the 99th percentile. Comparison of multiple laboratories worldwide is carried out in the DASP, a proficiency-testing program organized by the CDC under the auspices of the Immunology of Diabetes Society. That commercially available GAD65A and IA-2A methods are also participating in the DASP program demonstrates that it should be possible not only to harmonize participating laboratories but also eventually to standardize GAD65A and IA-2A (311).

ICAs are measured by indirect immunofluorescence of frozen sections of human pancreas (313). ICA assays measure the degree of immunoglobulin binding to islets, and results are compared with a WHO standard serum available from the National Institute of Biological Standards and Control (312). The results are reported in Juvenile Diabetes Foundation (JDF) units. Positive results depend on the study or context in which they are used, but many laboratories use 10 JDF units measured on two separate occasions or a single result ≥20 JDF units as titers that may indicate a significantly increased risk of type 1 diabetes. The method is cumbersome and has proved difficult to standardize. The number of laboratories that still carry out the ICA assay has decreased markedly, and the test is no longer included in the DASP program.

4. Interpretation

GAD65A may be present in approximately 60%–80% of patients with newly diagnosed type 1 diabetes, but the frequency varies with sex and age. GAD65A is associated with HLA DR3–DQA1*0501–DQB1*0201 in both patients and healthy individuals. IA-2As may be present in 40%–50% of patients with newly diagnosed type 1 diabetes, but the frequency is highest in the young. The frequency decreases with increasing age. IA-2As are associated with HLA DR4–DQA1*0301–DQB1*0302. IAA positivity occurs in >70%–80% of children who develop type 1 diabetes before 5 years of age but occurs in <40% of individuals who develop diabetes after the age of 12 years. IAAs are associated with HLA DR4–DQA1*0301–DQB1*0302 and with INS VNTR (262). ICA is found in about 75%–85% of new-onset patients.

The ICA assay is labor-intensive and difficult to standardize, and marked interlaboratory variation in sensitivity and specificity has been demonstrated in workshops (284,314). Few clinical laboratories are likely to implement this test. The immunoassays are more reproducible and are amenable to standardization (309). Measurement of T-cell reactivity in peripheral blood is theoretically appealing, but the imprecision of such assays precludes their use from a clinical setting (315,316). Autoantibody positivity (by definition) occurs in healthy individuals despite an absence of a family history of autoimmune diseases. Islet cell autoantibodies are no exception. If one autoantibody is found, the others should be assayed, because the risk of type 1 diabetes increases if an individual tests positive for two or more autoantibodies (306).

The following suggestions (279) have been proposed as a rational approach to the use of autoantibodies in diabetes: 1) antibody assays should have a specificity >99%; 2) proficiency testing should be documented; 3) multiple autoantibodies should be assayed; and 4) sequential measurement should be performed. These strategies will reduce false-positive and false-negative results.

5. Emerging considerations

Immunoassays for IAA, GAD65A, IA-2A/IA-2βA, and ZnT8A are now available, and a panel of these autoantibodies is currently used in screening studies (317). Because ICA assays are difficult to standardize, their use has declined substantially.

It is likely that other islet cell antigens will be discovered, and such discoveries could lead to additional diagnostic and predictive tests for type 1 diabetes. Autoantibody screening of dried spots obtained from finger-stick blood samples appears quite feasible in the future. For individuals who are positive for islet cell autoantibodies, HLA-DR/HLA-DQ genotyping will help define the absolute risk of type 1 diabetes.

Several clinical trials to prevent or intervene with type 1 diabetes are being actively pursued (317). Such trials can now be done with relatives of patients with type 1 diabetes or in the general population on the basis of the islet cell autoantibody and HLA-DR/HLA-DQ genotype status. Risk can be assessed by islet cell autoantibodies alone, without the need for evaluating endogenous insulin reserves, as was done for the U.S. DPT-1 trial (306). Rates of islet cell autoantibody positivity are distinctly lower in the general population than in relatives of individuals with type 1 diabetes; consequently, trials with the latter group are more economical. Potential interventional therapies (for type 1 diabetes) undergoing clinical trials include oral insulin (317) or nasal insulin (318) given to nondiabetic (but islet cell autoantibody–positive) relatives of individuals with type 1 diabetes or to children with islet cell autoantibodies and HLA genotypes conferring increased risk. Phase II clinical trials with alum-formulated GAD65 have reported no adverse events and some preservation of endogenous insulin production in GAD65A-positive diabetic patients (319,320). Additional trials of other antigen-based immunotherapies, adjuvants, cytokines, and T-cell accessory molecule–blocking agents are likely in the future (270). Decreased islet cell autoimmunity will be one important outcome measure of these therapies.

ALBUMINURIA (FORMERLY MICROALBUMINURIA)

Albuminuria (formerly microalbuminuria) are a well-established cardiovascular risk marker, in which increases over time to macroalbuminuria (>300 mg/day) are associated with kidney disease and an increased risk for progression to end-stage renal disease. Annual testing for albuminuria is recommended by all major guidelines for patients with diabetes and/or kidney disease. To be useful, semiquantitative or qualitative screening tests must be shown to be positive in >95% of patients with albuminuria. Positive results of such tests must be confirmed by quantitative testing in an accredited laboratory.

1. Use

RECOMMENDATION: ANNUAL TESTING FOR ALBUMINURIA IN PATIENTS WITHOUT CLINICAL PROTEINURIA SHOULD BEGIN IN PUBERTAL OR POSTPUBERTAL INDIVIDUALS 5 YEARS AFTER DIAGNOSIS OF TYPE 1 DIABETES AND AT THE TIME OF DIAGNOSIS OF TYPE 2 DIABETES, REGARDLESS OF TREATMENT B (moderate). RECOMMENDATION: URINE ALBUMIN AT CONCENTRATIONS ≥30 mg/g CREATININE SHOULD BE CONSIDERED A CONTINUOUS RISK MARKER FOR CARDIOVASCULAR EVENTS B (moderate). 

A. Diagnosis/screening.

Diabetes is associated with a very high rate of cardiovascular events and is the leading cause of end-stage renal disease in the Western world (321). Early detection of risk markers, such as albumin in the urine (formerly termed “microalbuminuria”), relies on tests for urinary excretion of albumin. Conventional qualitative tests (chemical strips or “dipsticks”) for albuminuria do not detect the small increases of urinary albumin excretion. For this purpose, tests to detect albumin concentrations are used (Table 7) (322–324). Low levels of albuminuria have been defined by the Joint National Committee (JNC) 7 and the ADA and have more recently been redefined by the Kidney Disease: Improving Global Outcomes Committee (21,325–327) as excretion of 30–300 mg of albumin/24 h, 20–200 μg/min, or 30–300 μg/mg creatinine (Table 8) on two of three urine collections. Recent data, however, suggest that risk extends below the lower limit of 20 μg/min (328–330), reinforcing the notion that this factor is a continuous variable for cardiovascular risk (331–333).

The JNC 7, the National Kidney Foundation (NKF), and the ADA all recommend the use of morning spot albumin/creatinine measurement for annual quantitative testing for urine albumin in adults with diabetes (21,326,327). Individuals should be fasting. The optimal time for spot urine collection is the early morning, but for minimizing variation, all collections should be at the same time of day; the individual preferably should not have ingested food for at least 2 h (334).

Positive test results represent “albuminuria” in these guidelines, corresponding to protein excretion of >300 mg/24 h, >200 μg/min, or >300 mg/g creatinine (Table 8). In these patients, quantitative measurement of urine albumin excretion is used in assessing the severity of albuminuria and its progression, in planning treatment, and in determining the impact of therapy. To properly assess the stage of kidney disease, the estimated glomerular filtration rate (eGFR) can be calculated from the serum creatinine value, age, sex, and race of the patient (335). An eGFR of <60 mL/min, regardless of the presence of low levels of albuminuria, is an independent cardiovascular risk factor (325,327). A urine albumin value of <30 mg/g creatinine, although considered “normal,” should be reassessed annually, because values as low as 10 mg/g creatinine have been associated in some studies with an increased cardiovascular risk. If the value is ≥30 mg/g creatinine, changes should be reassessed after 6 to 12 months if antihypertensve therapy is required or annually in those who are normotensive (326). For children with type 1 diabetes, testing for low levels of albuminuria is recommended to begin after puberty and after a diabetes duration of 5 years. Of note is that most longitudinal cohort studies have reported significant increases in the prevalence of low levels of albuminuria only after diabetes has been present for 5 years (326,336).

In the algorithms of both the NKF and the ADA for urine protein testing (321), the diagnosis of low levels of albuminuria requires both the demonstration of increased albumin excretion (as defined above) on two of three tests repeated at intervals of 3 to 6 months and the exclusion of conditions that “invalidate” the test (Fig. 1).

B. Prognosis.

Albuminuria values >30 mg/g creatinine [and lower values if the eGFR is <60 mL/min (Table 8)] have prognostic significance. Multiple epidemiologic studies have shown it to be an independent risk marker for cardiovascular death (325,337,338). In 80% of patients with type 1 diabetes and low levels of albuminuria, urinary albumin excretion can increase by as much as 10%–20%/year, with the development of clinical proteinuria (>300 mg albumin/day) in 10–15 years in more than half the patients. After clinical-grade proteinuria occurs, >90% of patients develop a decreased GFR and, ultimately, end-stage renal disease. In type 2 diabetes, 20%–40% of patients with stage A2 albuminuria (Table 8) progress to overt nephropathy, but by 20 years after overt nephropathy, approximately 20% develop end-stage renal disease. In addition, patients with diabetes (type 1 or type 2) and stage A2 albuminuria are at increased risk for cardiovascular disease. Of note is that low levels of albuminuria alone indicate neither an increased risk for progression to end-stage kidney disease nor kidney disease per se; hypertension needs to be present for the risk of progression (339,340). Moreover, about 20% of people progress to end-stage kidney disease without an increase in low levels of albuminuria (341). Another factor that indicates progression is an increase in albuminuria from stage A2 to A3 over time despite achievement of blood pressure goals (342).

C. Monitoring.

The roles of routine urinalysis and albumin measurements are less clear in patients with stage A2 albuminuria. Some experts have advocated urine protein testing to monitor treatment, which may include improved glycemic control, more assiduous control of hypertension, dietary protein restriction, and therapy with blockers of the renin angiotensin system (321). Several factors are known to slow the rate of urinary albumin excretion or to prevent its development. They include reducing blood pressure (with a blocker of the renin angiotensin system as part of the regimen), glycemic control, and lipid-lowering therapy (45,343–345).

2. Rationale

Early detection of albuminuria allows early intervention with the goal of reducing cardiovascular risk and delaying the onset of overt diabetic nephropathy. Thus, it is an indicator of the need for more intensive efforts to reduce cardiovascular risk factors.

Albuminuria (stage A2) rarely occurs with a short duration of type 1 diabetes or before puberty. Thus, testing is less urgent in these situations. Nevertheless, the difficulty in precisely dating the onset of type 2 diabetes warrants initiation of annual testing at the time of diagnosis of diabetes. Although older patients (age >75 years or a life expectancy <20 years) may not be at risk for clinically significant nephropathy because of a short projected life span, they will be at higher cardiovascular risk. In such patients, the role of treating albuminuria is far from clear. Published studies have demonstrated that it is cost-effective to screen all patients with diabetes and/or kidney disease for albuminuria (346,347).

3. Analytical considerations

box50RECOMMENDATION: THE ANALYTICAL CV OF METHODS TO MEASURE LOW LEVELS OF ALBUMINURIA SHOULD BE <15% B (moderate). 

A. Analytical.

Analytical goals can be related to the degree of biological variation, with less precision required for analytes that vary widely. Detection limits and imprecision data are summarized in Table 7. Commercially available quantitative methods for low levels of albuminuria have documented detection limits of approximately 20 μg/L or less. Within-run imprecision and day-to-day (total) imprecision are well within the analytical goal of approximately 15% and are often considerably less. Most, but not all, methods agree well and support a reference interval of 2–20 μg albumin/mg creatinine (348).

The within-person variation in albumin excretion is large in people without diabetes and is even higher in patients with diabetes. Howey et al. (349) studied day-to-day variation, over 3–4 weeks, in the 24-h albumin excretion, the concentration of albumin, and the albumin–creatinine ratio. The last two variables were measured in the 24-h urine sample, the first morning void, and random untimed urine collections. In healthy volunteers, the lowest within-person CVs were obtained for the concentration of albumin in the first morning void (36%) and for the albumin–creatinine ratio in that sample (31%) (349). Multiple studies have evaluated the best procedure to assess albuminuria. Most studies have found that the spot urine albumin–creatinine concentration in the first morning void, rather than the 24-h urinary excretion of albumin or the timed collection, is the most practical and reliable technique (346,350,351).

To keep the analytical CV less than half the biological CV, an analytical goal of an 18% CV has been proposed (349). Alternatively, if the albumin–creatinine ratio is to be used, one may calculate the need for a somewhat lower imprecision (that is, a better precision) to accommodate the lower biological CV for the ratio and the imprecision contributed by the creatinine measurement. Assuming a CV of 5% for creatinine measurement, we calculate a goal of 14.7% for the analytical CV for albumin when it is used to estimate the albumin–creatinine ratio. A goal of 15% appears reasonable to accommodate use of the measured albumin concentration for calculating either the timed excretion rate or the albumin–creatinine ratio.

RECOMMENDATION: SEMIQUANTITATIVE OR QUALITATIVE SCREENING TESTS SHOULD BE POSITIVE IN >95% OF PATIENTS WITH LOW LEVELS OF ALBUMINURIA TO BE USEFUL FOR SCREENING. POSITIVE RESULTS MUST BE CONFIRMED BY ANALYSIS IN AN ACCREDITED LABORATORY GPP. 

Qualitative (or semiquantitative) assays have been proposed as screening tests for low levels of albuminuria. To be useful, screening tests must have high detection rates, i.e., a high clinical sensitivity. Although many studies have assessed the ability of reagent strips (“dipstick” methods) to detect increased albumin concentrations in urine, the important question is whether the method can detect low levels of albuminuria, that is, an increased albumin excretion rate or its surrogate, an increased albumin–creatinine ratio. We can find no documentation of any test in which the sensitivity for detection of an increased albumin excretion rate consistently reached 95% in >1 study. For example, in a large study (352), the sensitivity for detection of an albumin excretion rate >30 mg/24 h was 91% when the test was performed by a single laboratory technician, 86% when performed by nurses, and 66% when performed by general practitioners. In two subsequent studies (353,354), the sensitivities were 67%–86%. False-positive results also appear to be common, with rates as high as 15% (352). Thus, it appears that at least some of the tests, especially as used in practice, have the wrong characteristics for screening because of low sensitivity (high false-negative rates), and positive results must be confirmed by a laboratory method. Of the available methods, the immunoturbidimetric assay is the most reliable and should be considered the standard for comparison, because it has >95% sensitivity and specificity to detect very low levels of albuminuria. Semiquantitative or qualitative screening tests should be positive in >95% of patients for the detection of albuminuria to be useful for assessment of cardiovascular risk and progression of kidney disease. Positive results obtained with such methodologies must be confirmed by an immunoturbidimetric assay in an accredited laboratory (355).

RECOMMENDATION: CURRENTLY AVAILABLE DIPSTICK TESTS DO NOT HAVE ADEQUATE ANALYTICAL SENSITIVITY TO DETECT LOW LEVELS OF ALBUMINURIA B (moderate). 

Chemical-strip methods are not sensitive when the albumin concentration in the urine is in the interval of 20–50 mg/L. Thus, no recommendation can be made for the use of any specific screening test. Dipstick tests for low levels of albuminuria cannot be recommended as a replacement for the quantitative tests.

The available dipstick methods to detect low levels of albuminuria do not appear to lend themselves to viable screening strategies, either in the physician's office or for home testing. Usual screening tests (e.g., for phenylketonuria) have low false-negative rates, and thus only positive results require confirmation by a quantitative method. If a screening test has low sensitivity, negative results also must be confirmed, a completely untenable approach. With semiquantitative tests, it may be possible (or indeed necessary) to use a cutoff <20 mg/L to ensure the detection of samples with albumin values >20 mg/L as measured by laboratory methods.

Recent studies have compared selected dipstick methods to laboratory assays. One dipstick was found to have >95% sensitivity (322,324). One such study evaluated an office-screening test that uses a monoclonal antibody against human serum albumin (ImmunoDip; Genzyme Diagnostics) (322). Screening 182 patient samples with this method with an albumin–creatinine ratio of ≥30 μg/mg as positive yielded a sensitivity of 96%, a specificity of 80%, a positive predictive value of 66%, and a negative predictive value of 98%. In a separate study, 165 patients had the HemoCue point-of-care system for albumin compared with the Clinitek Microalbumin (Siemens) and Chemstrip Micral (Roche Diagnostics) tests, as well as with an HPLC assay, for spot albumin–creatinine ratio measurement (324). Further studies are needed before the dipstick tests for low levels of albuminuria can be recommended as replacements for the quantitative tests. The use of qualitative tests at the point of care is reasonable only when it can be shown that this approach eliminates quantitative testing in a sizeable proportion of patients and detects those patients who have early renal disease.

RECOMMENDATION: ACCEPTABLE SAMPLES TO TEST FOR INCREASED URINARY ALBUMIN EXCRETION ARE TIMED COLLECTIONS (e.g., 12 OR 24 h) FOR MEASUREMENT OF THE ALBUMIN CONCENTRATION AND TIMED OR UNTIMED SAMPLES FOR MEASUREMENT OF THE ALBUMIN–CREATININE RATIO B (moderate). RECOMMENDATION: THE OPTIMAL TIME FOR SPOT URINE COLLECTION IS THE EARLY MORNING. ALL COLLECTIONS SHOULD BE AT THE SAME TIME OF DAY TO MINIMIZE VARIATION. THE PATIENT SHOULD NOT HAVE INGESTED FOOD WITHIN THE PRECEDING 2 h BUT SHOULD BE WELL HYDRATED (i.e., NOT VOLUME DEPLETED) GPP. 

B. Preanalytical.

Collection of 24-h samples has disadvantages, specifically because many samples are collected inadequately and because total creatinine is not routinely checked to evaluate the adequacy of collection. The albumin–creatinine ratio is the superior method to predict renal events in patients with type 2 diabetes (356). The ratio has a within-person biological variation similar to that of the excretion rate and correlates well with both timed excretion and the albumin concentration in a first morning void of urine (349). For the ratio, a first morning void sample is preferable because this sample has a lower within-person variation than the ratio for a random urine sample taken during the day (349). Although the ratio appears entirely acceptable for screening, limited data are available on its use in monitoring the response to therapy. Recent post hoc analyses of clinical trials, however, have found that the albumin–creatinine ratio is a reasonable method to assess change over time (357). For screening, an untimed sample for albumin measurement (without creatinine) may be considered if one uses a concentration cutoff that allows high sensitivity for detecting an increased albumin excretion rate.

Albumin is stable in untreated urine stored at 4°C or 20°C for at least a week (358). Neither centrifugation nor filtration appears necessary before storage at −20°C or −80°C (359). Whether a urine sample is centrifuged, filtered, or not treated, the albumin concentration decreases by 0.27%/day at −20°C but shows no decreases over 160 days at −80°C (359). The urinary albumin excretion rate does not show marked diurnal variation in diabetes but does so in essential hypertension (360).

4. Interpretation

A. Nonanalytical sources of variation.

Transient increases in urinary albumin excretion have been reported with short-term hyperglycemia, exercise, urinary tract infections, marked hypertension, heart failure, acute febrile illness, and hyperlipidemia (321).

RECOMMENDATION: LOW URINE ALBUMIN CONCENTRATIONS (i.e., <30 mg/g CREATININE) ARE NOT ASSOCIATED WITH HIGH CARDIOVASCULAR RISK IF THE eGFR IS >60 mL · min−1 · (1.73 m2)−1 AND THE PATIENT IS NORMOTENSIVE. IF THE eGFR IS <60 mL · min−1 · (1.73 m2)−1 AND/OR THE LEVEL OF ALBUMINURIA IS ≥30 mg/g CREATININE ON A SPOT URINE SAMPLE, A REPEAT MEASUREMENT SHOULD BE TAKEN WITHIN THE YEAR TO ASSESS CHANGE AMONG PEOPLE WITH HYPERTENSION A (moderate). 

B. Frequency of measurement.

The NKF, ADA, and JNC 7 recommend annual measurement in diabetic patients with albumin–creatinine ratios <30 μg/mg. After the documentation of stage A2 albuminuria (i.e., with results as defined above on two of three tests performed within 3 to 6 months), repeated testing is reasonable to determine whether a chosen therapy is effective. It may also be useful in determining the rate of disease progression and thus may support planning for care of end-stage renal disease. Although the ADA recommendations suggest that such testing is not generally needed before puberty, testing may be considered on an individual basis if it appears appropriate because of an early onset of diabetes, poor control, or a family history of diabetic nephropathy. The duration of diabetes prior to puberty is reportedly an important risk factor in this age-group and thus can be used to support such testing in individual patients (361).

MISCELLANEOUS POTENTIALLY IMPORTANT ANALYTES. I. INSULIN AND PRECURSORS

1. Use

RECOMMENDATION: THERE IS NO ROLE FOR ROUTINE TESTING FOR INSULIN, C-PEPTIDE, OR PROINSULIN IN MOST PATIENTS WITH DIABETES. DIFFERENTIATION BETWEEN TYPE 1 AND TYPE 2 DIABETES MAY BE MADE IN MOST CASES ON THE BASIS OF THE CLINICAL PRESENTATION AND THE SUBSEQUENT COURSE. THESE ASSAYS ARE USEFUL PRIMARILY FOR RESEARCH PURPOSES. OCCASIONALLY, C-PEPTIDE MEASUREMENTS MAY HELP DISTINGUISH TYPE 1 FROM TYPE 2 DIABETES IN AMBIGUOUS CASES, SUCH AS PATIENTS WHO HAVE A TYPE 2 PHENOTYPE BUT PRESENT IN KETOACIDOSIS B (moderate). RECOMMENDATION: THERE IS NO ROLE FOR MEASUREMENT OF INSULIN CONCENTRATION IN THE ASSESSMENT OF CARDIOMETABOLIC RISK, BECAUSE KNOWLEDGE OF THIS VALUE DOES NOT ALTER THE MANAGEMENT OF THESE PATIENTS B (moderate). 

A. Diagnosis.

In the last several years, interest has increased in the possibility that measurements of the concentrations of plasma insulin and its precursors might be of clinical benefit. In particular, published evidence reveals that increased concentrations of insulin and/or proinsulin in nondiabetic individuals predict the development of coronary artery disease (362). Although this possibility may be scientifically valid, its clinical value is questionable. An increased insulin concentration is a surrogate marker that can be used to estimate resistance to insulin-mediated glucose disposal, and it can identify individuals at risk for developing syndrome X, also known as the insulin resistance syndrome or the metabolic syndrome (363). Accurate measurement of insulin sensitivity requires the use of complex methods, such as the hyperinsulinemic euglycemic clamp technique, which are generally confined to research laboratories (364,365). Because of the critical role of insulin resistance in the pathogenesis of type 2 diabetes, hyperinsulinemia would also appear to be a logical risk predictor for incident type 2 diabetes.

Earlier studies may not have controlled well for glycemic status and other confounders. More-recent analyses suggest that insulin values do not add significantly to diabetes risk prediction carried out with more traditional clinical and laboratory measurements (366) and that measures of insulin resistance (that include insulin measurements) predict the risk of diabetes or coronary artery disease only moderately well, with no threshold effects (367). Consequently, it seems of greater clinical importance to quantify the consequences of the insulin resistance and hyperinsulinemia (or hyperproinsulinemia) rather than the hormone values themselves, i.e., by measuring blood pressure, the degree of glucose tolerance, and plasma lipid/lipoprotein concentrations. It is these variables that are the focus of clinical interventions, not plasma insulin or proinsulin concentrations (366,367).

The clinical utility of measuring insulin, C-peptide, or proinsulin concentrations to help select the best antihyperglycemic agent for initial therapy in patients with type 2 diabetes is a question that arises from consideration of the pathophysiology of type 2 diabetes. In theory, the lower the pretreatment insulin concentration, the more appropriate might be insulin, or an insulin secretagogue, as the drug of choice to initiate treatment. Although this line of reasoning may have some intellectual appeal, there is no evidence that measurement of plasma insulin or proinsulin concentrations will lead to more efficacious treatment of patients with type 2 diabetes.

In contrast to the above considerations, measurement of plasma insulin and proinsulin concentrations is necessary to establish the pathogenesis of fasting hypoglycemia (368). The diagnosis of an islet cell tumor is based on the persistence of inappropriately increased plasma insulin concentrations in the face of a low glucose concentration. In addition, an increase in the ratio of fasting proinsulin to insulin in patients with hypoglycemia strongly suggests the presence of an islet cell tumor. The absence of these associated changes in glucose, insulin, and proinsulin concentrations in an individual with fasting hypoglycemia makes the diagnosis of an islet cell tumor most unlikely, and alternative explanations should be sought for the inability to maintain fasting euglycemia.

Measurement of the C-peptide response to intravenous glucagon can aid in instances in which it is difficult to differentiate between the diagnosis of type 1 and type 2 diabetes (5). Even in this clinical situation, however, the response to drug therapy will provide useful information, and measurement of C-peptide may not be clinically necessary. Measurement of C-peptide is essential in the investigation of possible factitious hypoglycemia due to surreptitious insulin administration (369).

In the past, some advocated insulin assays in the evaluation and management of patients with the polycystic ovary syndrome. Women with this syndrome manifest insulin resistance by androgen excess, as well as by abnormalities of carbohydrate metabolism; both abnormalities may respond to treatment with metformin or thiazolidinediones. Although clinical trials have generally evaluated insulin resistance by using the hyperinsulinemic euglycemic clamp, ratios of fasting glucose to insulin, and other modalities, the optimal laboratory evaluation of these patients in routine clinical care has not been clearly defined. It is unclear whether assessing insulin resistance through insulin measurement has any advantage over assessment of physical signs of insulin resistance (BMI, presence of acanthosis nigricans), and routine measurements of insulin are not recommended by the American College of Obstetrics and Gynecology (370).

2. Analytical considerations

RECOMMENDATION: BECAUSE CURRENT MEASURES OF INSULIN ARE POORLY HARMONIZED, A STANDARDIZED INSULIN ASSAY SHOULD BE DEVELOPED TO ENCOURAGE THE DEVELOPMENT OF MEASURES OF INSULIN SENSITIVITY THAT WILL BE PRACTICAL FOR CLINICAL CARE GPP. 

Although it has been assayed for >40 years, there is no standardized method available to measure serum insulin (371). Attempts to harmonize insulin assays with commercial insulin reagent sets have produced greatly discordant results (372). Recently, an insulin standardization workgroup of the ADA, in conjunction with the National Institute of Diabetes and Digestive and Kidney Diseases, the CDC, and the European Association for the Study of Diabetes, called for harmonization of insulin assay results through traceability to an isotope-dilution liquid chromatography–tandom mass spectrometry reference (373). The Insulin Standardization Workgroup called for harmonization of the insulin assay to encourage the development of measures of insulin sensitivity and secretion that will be practical for clinical care (374). Analogous to insulin, considerable imprecision among laboratories has also been observed for measurement of C-peptide. A comparison of 15 laboratories that used nine different routine C-peptide assay methods, found within- and between-run CVs as high as >10% and 18%, respectively (375). A committee has been established under the auspices of the CDC to harmonize C-peptide analysis.

Measurements of proinsulin and C-peptide are accomplished by immunometric methods. Proinsulin reference intervals are dependent on methodology, and each laboratory should establish its own reference interval. Although it has been suggested by some, insulin measurement should not be used in an OGTT to diagnose diabetes. In the case of C-peptide, there is a discrepancy in reliability because of variable specificity among antisera, lack of standardization of C-peptide calibration, and variable cross-reactivity with proinsulin. Of note is the requirement of the U.S. Centers for Medicare and Medicaid Services that Medicare patients have C-peptide measured in order to be eligible for coverage of insulin pumps. Initially, the requirement was that the C-peptide concentration be ≤0.5 ng/mL; however, because of the noncomparability of results from different assays, which led to denial of payment for some patients with values >0.5 ng/mL, the requirement now states that the C-peptide concentration should be ≤110% of the lower limit of the reference interval of the laboratory's measurement method (376).

MISCELLANEOUS POTENTIALLY IMPORTANT ANALYTES. II. INSULIN ANTIBODIES

RECOMMENDATION: THERE IS NO PUBLISHED EVIDENCE TO SUPPORT THE USE OF INSULIN ANTIBODY TESTING FOR ROUTINE CARE OF PATIENTS WITH DIABETES C (very low). 

Given sufficiently sensitive techniques, insulin antibodies can be detected in any patient being treated with exogenous insulin (371). In the vast majority of patients, the titer of insulin antibodies is low, and their presence is of no clinical significance. Very low values are seen in patients treated exclusively with human recombinant insulin (377). On occasion, however, the titer of insulin antibodies in the circulation can be quite high and associated with a dramatic resistance to the ability of exogenous insulin to lower plasma glucose concentrations. This clinical situation is quite rare, it usually occurs in insulin-treated patients with type 2 diabetes, and the cause-and-effect relationships between the magnitude of the increase in insulin antibodies and the degree of insulin resistance are unclear. There are several therapeutic approaches for treating these patients, and a quantitative estimate of the concentration of circulating insulin antibodies does not appear to be of significant benefit.

The prior version of these guidelines (14) contained short sections on amylin and leptin, both of which were the focus of active clinical studies. The evidence that has accumulated in the last 7 to 8 years has failed to identify any clinical value in measuring these analytes in patients with diabetes. Similarly, although cardiovascular disease is the major cause of mortality for persons with diabetes, no evidence supports the measurement of nontraditional cardiovascular risk factors for routine assessment of risk in patients with diabetes. These sections have, therefore, been removed.

 Supplementary Material

   

Figure 1

Algorithm for urine protein testing.

