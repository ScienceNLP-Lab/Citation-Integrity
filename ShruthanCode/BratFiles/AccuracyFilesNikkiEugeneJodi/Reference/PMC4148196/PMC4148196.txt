Classical Mathematical Models for Description and Prediction of Experimental Tumor Growth

Abstract

Despite internal complexity, tumor growth kinetics follow relatively simple laws that can be expressed as mathematical models. To explore this further, quantitative analysis of the most classical of these were performed. The models were assessed against data from two in vivo experimental systems: an ectopic syngeneic tumor (Lewis lung carcinoma) and an orthotopically xenografted human breast carcinoma. The goals were threefold: 1) to determine a statistical model for description of the measurement error, 2) to establish the descriptive power of each model, using several goodness-of-fit metrics and a study of parametric identifiability, and 3) to assess the models' ability to forecast future tumor growth. The models included in the study comprised the exponential, exponential-linear, power law, Gompertz, logistic, generalized logistic, von Bertalanffy and a model with dynamic carrying capacity. For the breast data, the dynamics were best captured by the Gompertz and exponential-linear models. The latter also exhibited the highest predictive power, with excellent prediction scores (≥80%) extending out as far as 12 days in the future. For the lung data, the Gompertz and power law models provided the most parsimonious and parametrically identifiable description. However, not one of the models was able to achieve a substantial prediction rate (≥70%) beyond the next day data point. In this context, adjunction of a priori information on the parameter distribution led to considerable improvement. For instance, forecast success rates went from 14.9% to 62.7% when using the power law model to predict the full future tumor growth curves, using just three data points. These results not only have important implications for biological theories of tumor growth and the use of mathematical modeling in preclinical anti-cancer drug investigations, but also may assist in defining how mathematical models could serve as potential prognostic tools in the clinic.

Author Summary

Tumor growth curves display relatively simple time curves that can be quantified using mathematical models. Herein we exploited two experimental animal systems to assess the descriptive and predictive power of nine classical tumor growth models. Several goodness-of-fit metrics and a dedicated error model were employed to rank the models for their relative descriptive power. We found that the model with the highest descriptive power was not necessarily the most predictive one. The breast growth curves had a linear profile that allowed good predictability. Conversely, not one of the models was able to accurately predict the lung growth curves when using only a few data points. To overcome this issue, we considered a method that uses the parameter population distribution, informed from a priori knowledge, to estimate the individual parameter vector of an independent growth curve. This method was found to considerably improve the prediction success rates. These findings may benefit preclinical cancer research by identifying models most descriptive of fundamental growth characteristics. Clinical perspective is also offered on what can be expected from mathematical modeling in terms of future growth prediction.

Introduction

Neoplastic growth involves a large number of complex biological processes, including regulation of proliferation and control of the cell cycle, stromal recruitment, angiogenesis and escape from immune surveillance. In combination, these cooperate to produce a macroscopic expansion of the tumor volume, raising the prospect of a possible general law for the global dynamics of neoplasia.

Quantitative and qualitative aspects of the temporal development of tumor growth can be studied in a variety of experimental settings, including in vitro proliferation assays, three-dimensional in vitro spheroids, in vivo syngeneic or xenograft implants (injected ectopically or orthotopically), transgenic mouse models or longitudinal studies of clinical images. Each scale has its own advantages and drawbacks, with increasing relevance tending to coincide with decreasing measurement precision. The data used in the current study are from two different in vivo systems. The first is a syngeneic Lewis lung carcinoma (LLC) mouse model, exploiting a well-established tumor model adopted by the National Cancer Institute in 1972 [1]. The second is an orthotopic human breast cancer xenografted in severe combined immunodeficient (SCID) mice [2].

Tumor growth kinetics has been an object of biological study for more than 60 years (see e.g. [3] as one of the premiere studies) and has been experimentally investigated extensively (see [4] for a thorough review and [5]–[8] for more recent work). One of the most common findings for animal [9] and human [10]–[12] tumors alike is that their relative growth rates decrease with time [13]; or equivalently, that their doubling times increase.

These observations suggest that principles of tumor growth might result from general growth laws, often amenable to expression as ordinary differential equations [14]. The utility of these models can be twofold: 1) testing growth hypotheses or theories by assessing their descriptive power against experimental data and 2) estimating the prior or future course of tumor progression [9], [15] either as a personalized prognostic tool in a clinical context [16]–[20], or in order to determine the efficacy of a therapy in preclinical drug development [21], [22].

Cancer modeling offers a wide range of mathematical formalisms that can be classified according to their scale, approach (bottom-up versus top-down) or integration of spatial structure. At the cellular scale, agent-based models [23], [24] are well-suited for studies of interacting cells and implications on population-scale development, but computational capabilities often limit such studies to small maximal volumes (on the order of the mm3). The tissue scale is better described by continuous partial differential equations like reaction-diffusion models [19], [25] or continuum-mechanics based models [26], [27], when spatial characteristics of the tumor are of interest. When focusing on scalar data of longitudinal tumor volume (which is the case here), models based on ordinary differential equations are more adapted. A plethora of such models exist, starting from proliferation of a constant fraction of the tumor volume, an assumption that leads to exponential growth. This model is challenged by the aforementioned observations of non-constant tumor doubling time. Consequently, investigators considered more elaborate models; the most widely accepted of which is the Gompertz model. It has been used in numerous studies involving animal [9], [28]–[31] or human [12], [15], [30], [32] data. Other models include logistic [30], [33] or generalized logistic [11], [31] formalisms. Inspired by quantitative theories of metabolism and its impact on biological growth, von Bertalanffy [34] derived a growth model based on balance equations of metabolic processes. These considerations were recently developed into a general law of biological growth [35] and brought to the field of tumor growth [36], [37]. When the loss term is neglected, the von Bertalanffy model reduces to a power law (see [5], [38] for applications to tumor growth). An alternative, purely phenomenological approach led others [39] to simply consider tumor growth as divided into two phases: an initial exponential phase then followed by a linear regimen. Recently, influences of the microenvironment have been incorporated into the modeling, an example being the inclusion of tumor neo-angiogenesis by way of a dynamic carrying capacity [40], [41].

Although several studies have been conducted using specific mathematical models for describing tumor growth kinetics, comprehensive work comparing broad ranges of mathematical models for their descriptive power against in vivo experimental data is lacking (with the notable exception of [30] and a few studies for in vitro tumor spheroids [33], [42]–[44]). Moreover, predictive power is very rarely considered (see [42] for an exception, examining growth of tumor spheroids), despite its clear relevance to clinical utility. The aim of the present study is to provide a rational, quantitative and extensive study of the descriptive and predictive power of a broad class of mathematical models, based on an adapted quantification of the measurement error (uncertainty) in our data. As observed by others [45], specific data sets should be used rather than average curves, and this is the approach we adopted here.

In the following sections, we first describe the experimental procedures that generated the data and define the mathematical models. Then we introduce our methodology to fit the models to the data and assess their descriptive and predictive powers. We conclude by presenting the results of our analysis, consisting of: 1) analysis of the measurement error and derivation of an appropriate error model, subsequently used in the parameters estimation procedure, 2) comparison of the descriptive power of the mathematical models against our two datasets, and 3) determination of the predictive abilities of the most descriptive models, with or without adjunction of a priori information in the estimation procedure.

Materials and Methods

Ethics statement

Animal tumor model studies were performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. Protocols used were approved by the Institutional Animal Care and Use Committee (IACUC) at Tufts University School of Medicine for studies using murine Lewis lung carcinoma (LLC) cells (Protocol: #P11-324) and at Roswell Park Cancer Institute (RPCI) for studies using human LM2-4LUC+ breast carcinoma cells (Protocol: 1227M). Institutions are AAALAC accredited and every effort was made to minimize animal distress.

Mice experiments

Cell culture

Murine Lewis lung carcinoma (LLC) cells, originally derived from a spontaneous tumor in a C57BL/6 mouse [46], were obtained from American Type Culture Collection (Manassas, VA). Human LM2-4LUC+ breast carcinoma cells are a metastatic variant originally derived from MDA-MD-231 cells and then transfected with firefly luciferase [47]. All cells were cultured in high glucose DMEM (obtained from Gibco Invitrogen Cell Culture, Carlsbad, CA or Mediatech, Manassas, VA) with 10%FBS (Gibco Invitrogen Cell Culture) and 5% CO2.

Tumor injections

For the subcutaneous mouse syngeneic lung tumor model, C57BL/6 male mice with an average lifespan of 878 days were used [48]. At time of injection mice were 6 to 8 weeks old (Jackson Laboratory, Bar Harbor, Maine). Subcutaneous injections of 106 LLC cells in 0.2 ml phosphate-buffered saline (PBS) were performed on the caudal half of the back in anesthetized mice.

For the orthotopic human xenograft breast tumor model, LM2-4LUC+ cells (1×106 cells) were orthotopically implanted into the right inguinal mammary fat pads of 6- to 8-week-old female severe combined immunodeficient (SCID) mice obtained from the Laboratory Animal Resource at RPCI, as previously described [2].

Tumor measurements

Tumor size was measured regularly with calipers to a maximum of 1.5 cm3 for the lung data set and 2 cm3 for the breast data set. Largest (L) and smallest (w) diameters were measured subcutaneously using calipers and the formula   was then used to compute the volume (ellipsoid). Volumes ranged 14–1492 mm3 over time spans from 4 to 22 days for the lung tumor model (two experiments of 10 animals each) and 202–1902 mm3 over time spans from 18 to 38 days for the breast tumor data (five experiments conducted with a total of 34 animals). Plots of individual growth curves for both data sets are reported in Figure S1.

Mathematical models

For all the models, the descriptive variable is the total tumor volume, denoted by V, as a function of time t. It is assumed to be proportional to the total number of cells in the tumor. To reduce the number of degrees of freedom, all the models (except the exponential V  ) had a fixed initial volume condition. Although the number of cells that actually remain in the established tumor is probably lower than the number of injected cells (∼60–80%), we considered 1 mm3 (  cells [49], i.e. the number of injected cells) as a reasonable approximation for V(t = 0).

Exponential-linear models

The simplest theory of tumor growth presumes all cells proliferate with constant cell cycle duration TC. This leads to exponential growth, which is also valid in the extended cases where either a constant fraction of the volume is proliferating or the cell cycle length is a random variable with exponential distribution (assuming that the individual cell cycle length distributions are independent and identically distributed). As one modification, initial exponential phase can be assumed to be followed by a linear growth phase [39], giving the following Cauchy problem for the volume rate of change (growth rate): Here, the coefficient a   is the fraction of proliferative cells times ln 2/TC where TC is either the constant cell cycle length or the mean cell cycle length (under the assumption of exponentially distributed cell cycle lengths). The coefficient a   drives the linear phase. Assuming that the solution of the problem (1) is continuously differentiable uniquely determines the value of τ as  . The coefficient V   denotes the initial volume. From this formula, three models were considered: a) initial volume fixed to 1 mm3 and no linear phase (a   = +∞), referred to hereafter as exponential 1, b) free initial volume and no linear phase, referred to as exponential V   and c) equation (1) with fixed initial volume of 1 mm3, referred to as the exponential-linear model.

Logistic and Gompertz models

A general class of models used for quantification of tumor growth kinetics have a sigmoid shape, i.e. an increasing curve with one inflection point that asymptotically converges to a maximal volume, the carrying capacity, denoted here by K. This qualitatively reproduces the experimentally observed growth slowdown [9]–[12] and is consistent with general patterns of organ and organismal growth. The logistic model is defined by a linear decrease of the relative growth rate   in proportion to the volume: where a is a coefficient related to proliferation kinetics. This model can be interpreted as mutual competition between the cells (for nutrients or space, for instance), by noticing that under this model the instantaneous probability for a cell to proliferate is proportional to  . The logistic model has been used for description of tumor growth, for instance, in [30]. Others (such as [11]) have considered a generalization of the logistic equation, defined by that will be referred to as the generalized logistic model. Equation (3) has the explicit solution which also provides an analytic solution to model (2) when ν = 1. When a different parameterization is employed, this model converges when ν→0 to the Gompertz model, defined by Coefficient a is the initial proliferation rate (at V = 1 mm3) and β is the rate of exponential decay of this proliferation rate. Although first introduced in [50] for a different purpose – the description of human mortality for actuarial applications – the Gompertz model became a widely-accepted representation of growth processes in general [51] and of tumor growth in particular. It was first successfully used in this regard [28] before its applicability was confirmed on large animal data sets [9], [29] and for human breast data [32]. The essential characteristic of the Gompertz model is that it exhibits exponential decay of the relative growth rate. An analytic formula can be derived for the solution of (4): where we can see that asymptotically, the volume converges to a carrying capacity given by  .

A unified model deriving these three sigmoidal models from specific biophysical assumptions about different types of cellular interactions can be found in [52].

Dynamic carrying capacity

Taking the next step up in complexity brings us to a model that assumes a dynamic (time-dependent) carrying capacity (CC) [40], [41] that can be taken, for example, to represent the tumor vasculature. If one assumes that stimulation of the carrying capacity is proportional to the tumor surface, and neglects angiogenesis inhibition, this model can be formulated in terms of two coupled equations: and will be referred to as the dynamic CC model. It should be noted that this model was first developed with the intent of modeling the effect of anti-angiogenic therapies on tumor growth and not strictly for describing or predicting the behavior of V alone. However, we integrated it into our analysis in order to investigate and quantify whether consideration of a dynamic carrying capacity could benefit these tasks.

Von Bertalanffy and power law

Von Bertalanffy [34], followed later on by others [35], proposed to derive general laws of organic growth from basic energetics principles. Stating that the net growth rate should result from the balance of synthesis and destruction, observing that metabolic rates very often follow the law of allometry (i.e. that they scale with a power of the total size) [34] and assuming that catabolic rates are in proportion to the total volume, he derived the following model for growth of biological processes Employing our usual assumption that V(t = 0) = 1 mm3, we will refer to this model as the von Bertalanffy model (note that others [14], [30] often identify this model as the specific case γ = 2/3, termed “second type growth” in [34]). It has already been successfully applied to describe tumor growth [36], [37]. More elaborate considerations linking tumor growth, metabolic rate and vascularization leading to equation (6) can be found in [37]. That work also provides expressions of the coefficients in terms of measurable energetic quantities. Explicit solution of the model is given by From the observation that our data does not exhibit a clear saturation phase, a qualitative feature of equation (6), we also considered another model, derived from (6), by neglecting the loss term, i.e. taking b = 0. This model will be termed the power law model. Pushing further the reasoning of [34] and arguing that the rate of synthesis of new material, in the context of tumor growth, should be proportional to the number of proliferative cells (under the assumption of a constant cell cycle length), this model suggests that the proliferative tissue is proportional to Vγ. This could be further interpreted as a possible fractional Hausdorff dimension of the proliferative tissue, when viewed as a metric subspace of the full tumor volume (viewed itself as a three-dimensional subset of the three-dimensional Euclidean space). This dimension would be equal to 3γ and could be less than 3 when γ<1. In this interpretation, the case   (i.e. dimension equal to 2) could correspond to a proliferative rim limited to the surface of the tumor. This implies that the tumor radius — proportional to V 1/3 — grows linearly in time. Such linear growth of the tumor radius has been experimentally reported for tumor growth, for instance in the case of gliomas [18]. At the other extreme, a three-dimensional proliferative tissue (γ = 1) represents proliferative cells uniformly distributed within the tumor and leads to exponential growth. Any power 0<γ<1 gives a tumor growth with decreasing growth fraction (and thus decreasing relative growth rate), for which the power law model provides a description in terms of a geometrical feature of the proliferative tissue. This model was first used for murine tumor growth description in [38] and was applied to human data in [5].

Fit procedures and goodness of fit criteria

Individual approach

The main method we used to fit the models is based on individual fits for each animal. The underlying statistical framework is to consider the volume data   for animal j (1≤j≤J) at time   (with 1<i<Ij as realizations of a random variable   being generated by a (deterministic) model M (itself dependent on a parameter vector of length P denoted by  ), as perturbed by random effects, assumed to be Gaussian. In mathematical terms: where the   are independent reduced centered Gaussian random variables and   is the standard deviation of the error. Statistical analysis of the measurement error was performed and resulted in the following expression (see the Results section) For a given animal j and parameter set βj, the likelihood L(βj) of the observations is defined as the probability of observing   under model M, parameter set βj and expression (7), i.e.  . Considering that maximizing L is equivalent to minimizing −ln L, it leads to a weighted least squares minimization problem with objective defined by Minimization was performed using the Matlab [53] function lsqcurvefit (trust-region algorithm), except for the generalized logistic model, for which the function fminsearch (Nelder-Mead algorithm) was employed (see supporting text S1 for details on the numerical procedures). The resulting best-fit parameter vector was denoted  . Standard errors (se) of the maximum likelihood estimator, from which confidence intervals can be derived, were used to quantify the reliability of the parameters estimated. These were computed from an a posteriori estimate of σ 2, denoted by NMSE, and the weighted jacobian matrix of the model for animal j, denoted by Jj, both defined by From these expressions, normalized standard errors can be approximated, in the context of nonlinear least squares regression, by [54]  Different initializations of the algorithm were systematically tested to establish the practical identifiability of the models (see supporting text S2).

From the obtained  , we derived various indicators of the goodness of fit. The Akaike Information Criterion (AIC) [55], [56] was used to compare models with different numbers of parameters by penalizing those that use a greater number of parameters. It is defined, up to an additive constant that does not depend on the model, by where K = P+1. Due to the limited number of data for a given individual, we also considered a corrected version of the AIC, termed AICc [55], [56]: The Root Mean Squared Error (RMSE) is another classical goodness of fit criterion that also penalizes the lack of parameter parsimony in a model: Yet another criterion is the coefficient of determination: where   is the time average of the data points. This metric quantifies how much of the variability in the data is described by the model M and how much the model is better at fitting the data than the mere mean value.

Finally, we considered as an additional criterion of validity of a fit the p-value obtained from the Kolmogorov-Smirnov statistical test for normality of the weighted residuals, these being defined by  

Population approach (mixed-effect models)

The procedure we explained above considers all the animals within a group to be independent. On the other hand, the mixed-effect approach [57] consists of pooling all the animals together and estimating a global distribution of the model parameters in the population. More precisely, the individual parameter vectors   are assumed to be realizations of a random variable β (here taken to be log-normally distributed). The statistical representation is then formula (7) with β instead of βj, together with Two coefficients (the vector μ of length p and the p×p matrix ω) represent the total population, instead of the J parameter sets in the individual approach (J = 20 for the lung data set and 34 for the breast data). Combined with an appropriate description of the error variance, a population likelihood of all the data pooled together can be defined. Usually, no explicit formula can be computed for its expression, making its maximization a more difficult task. This is implemented in a software called Monolix [58], which maximizes the likelihood using the stochastic approximation expectation maximization (SAEM) algorithm [59]. Consistently with our results on the measurement error (see the Results section), the error model (i.e. the expression of E in (7)) was taken to be proportional to a fixed power α = 0.84 of the volume, although with a threshold volume Vm = 0 (because Monolix does not permit the setting of a threshold volume). From this estimation process, a population AICc, denoted AICcpop, was defined, using the same formula as (12) and the AIC returned by Monolix.

Model prediction methods

For a given animal j and model M, the general setting considered for prediction was to estimate the model's parameter set using only the first n data points and to use these to predict at a depth d, i.e. to predict the value at time  , provided that a measurement exists at this day (in which case it will be denoted by  ). The resulting best-fit parameter set will be denoted  .

Prediction metrics and success score

Goodness of a prediction was quantified using the normalized error between a model prediction and the data point under consideration, defined by Prediction of a single time point was considered acceptable when the normalized error was lower than three, corresponding to a model prediction within three standard deviations of the measurement error of the data and generating success results in good agreement with direct visual examinations (see Figures 3, S2 and S3). This allowed us to define a prediction score at the level of the population (denoted by  ), by the proportion of successful predictions among all animals having measurements both at times tn and   (whose set will be denoted by   and total number by  ). This metric is formally defined by where # E denotes the number of elements of the set E. We then derived a global score for each model by averaging over all possible values of n and d. When the total number of animals over which the success score is computed is small, this could bias the success score (since for instance only one successfully predicted animal could give a success score of 100% if there is only one animal to predict). To lower this bias, we considered a minimal threshold for  , arbitrarily taken to 5 animals. The overall mean success is then defined by When assessing prediction over the total future curve, thus involving several time points, we considered the median of the normalized errors: together with its associated prediction score   and population average  .

The previous metrics being dependent on our underlying measurement error, we also considered the relative error and its population average, defined by  

 A priori information

For each dataset and model, the total population was randomly and equally divided into two groups. Individual fits for the first group (the “learning” group) were performed using all the available data, generating mean values   and standard deviations   of a parameter vector  , within the population. This information was then used when estimating the individual parameter set of a given animal from the second group (the “forecast group”), based only on a subset of n data points, by penalizing the sum of squared residuals in the following way with   defined in (15). This objective replaced the one defined in (8) for estimation of the parameters. The procedure was repeated 100 times (i.e. 100 random assignments of the total population between 10 “learning” animals and 10 “forecast” animals). This number was sufficiently large to have reached convergence in the law of large numbers (no significant difference between 20 and 100 replicates, p>0.2 by Student's t-test). Among these simulation replicates, we only considered as significant the cases where  , for the same reasons as explained earlier. For the lung tumor data set, this did not lead to any exclusion for most of the situations, the only exceptions being for S   and S   where only 89/100 and 72/100 replicates were eligible, respectively. In contrast, for the breast tumor data and depths 1 to 10, respectively 99, 16, 76, 3, 100, 3, 100, 0, 34 and 77 replicates were eligible. Therefore, results of S  , S  , S  , S   and S   were considered non-significant and were not reported.

Results

Measurement error

The following method was used for analysis of the error made when measuring tumor volume with calipers. One volume per time point per cage was measured twice within a few minutes interval. This gave a total of 133 measurements over a wide range of volumes (20.7–1429 mm3). These were subsequently analyzed by considering the following statistical representation where Y is a random variable whose realizations are the measured volumes,   is the true volume, ε is a reduced centered Gaussian random variable, and σE is the error standard deviation. The two measures, termed y   and y  , were, as expected, strongly correlated (Figure 1A,  ). Statistical analysis rejected variance independent of volume, i.e. constant E ( , χ 2 test) and a proportional error model (E = Y) was found only weakly significant ( , χ 2 test, see Figure 1B). We therefore introduced a dedicated error model, defined by Two main rationales guided this formulation. First, we argued that error should be larger when volume is larger, a fact that is corroborated by larger error bars for larger volumes on growth data reported in the literature (see Figure 4 in [2] for an example among many others). This was also supported by several publications using a proportional error model when fitting growth data (such as [42], [60]). Since here such a description of the error was only weakly significant, we added a power to account for lower-than-proportional uncertainty in large measurements. Second, based on our own practical experience of measuring tumor volumes with calipers, for very small tumors, the measurement error should stop being a decreasing function of the volume because of detectability limits. This motivated the introduction of the threshold Vm. After exploration of several values of Vm and α, we found   to be able to accurately describe dispersion of the error in our data ( , χ 2 test, see Figure 1C). This yielded an empirical value of   

We did not dispose of double measurements for the breast tumor data and the error analysis was performed using the lung tumor data set only. However, the same error model was applied to the breast tumor data, as both relied upon the same measurement technique.

This result allowed quantification of the measurement error inherent to our data and was an important step in the assessment of each model's descriptive power.

Descriptive power

We tested all the models for their descriptive power and quantified their respective goodness of fit, according to various criteria. Two distinct estimation procedures were employed. The first fitted each animal's growth curve individually (minimization of weighted least squares, with weights defined from the error model of the previous section, see Material and Methods). The second method used a population approach and fitted all the growth curves together. Results are reported in Figure 2 and Tables 1 and 2. Parameter values resulting from the fits are reported in Tables 3 and 4.

 Figure 2A depicts the representative fit of a given animal's growth curve for each data set using the individual approach. From visual examination, the exponential 1 (1), logistic (2) and exponential-linear (1) models did not well explain lung tumor growth and the exponential 1 (1) and logistic (2) models did not satisfactorily fit the breast tumor growth data. The other models seemed able to describe tumor growth in a reasonably accurate fashion.

These results were further confirmed by global quantifications over the total population, such as by residuals analysis (Figure 2C) and global metrics reported in Tables 1 and 2. When considering goodness-of-fit only, i.e. looking at the minimal least squared errors possibly reached by a model to fit the data (metric   in Tables 1 and 2), the generalized logistic model (3) exhibited the best results for both data sets (first column in Tables 1 and 2). This indicated a high structural flexibility that allowed this model to adapt to each growth curve and provided accurate fits. On the other hand, the exponential 1 (1) and logistic (2) models clearly exhibited poor fits to the data, a result confirmed by almost all the metrics (with the exception of the AICc).

Influence of the goodness-of-fit metric

Being able to closely match the data is not the only relevant criterion to quantify the descriptive power of a model since parameter parsimony of the model should also be taken into account. Other metrics were employed that balanced pure goodness-of-fit and the number of parameters (see Materials and Methods for their definitions). Among them, AICc exhibited the strongest penalization for a large number of parameters. However, this metric was in multiple instances in disagreement with the other metrics dealing with parsimony. For this reason, we also reported the values of AIC. These were found globally in accordance with the RMSE. The AICcpop gave a weaker importance to the number of parameters, due to the large number of data points in the setting of the population approach, since all the animals were pooled together. For the same reason, values of AICcpop were almost identical to values of AICpop and only the former were reported. Other structural and numerical differences (for instance, the individual approach used a deterministic optimizer while the population approach was based on a stochastic algorithm) also explained the discrepancies between the two approaches. When comparing the results generated by the two approaches, better individual fits were obtained using the individual approach (see Tables S2). Indeed, the population approach is better designed for settings where the number of data points is too low to individually estimate the parameters, which was not our case.

Taking all these considerations into account, we deemed the RMSE metric to be a good compromise and used this criterion for ranking the models in Tables 1 and 2.

Descriptive power and identifiability of the models for each data set

For the lung data, five models (generalized logistic (3), Gompertz (4), power law (6), dynamic CC (5) and von Bertalanffy (6)) were found to have similar RMSE (Table 1), suggesting an identical descriptive power among them. However, having one less parameter, the Gompertz and power law models had smaller AIC (and much smaller AICc) and should thus be preferred for parsimonious description of subcutaneous tumor growth of LLC cells. Having an additional degree of freedom translated into poor identifiability of the parameters for the generalized logistic (3), dynamic CC (5) and von Bertalanffy (6) models, as indicated by high standard errors on the parameter estimates (last column of Table 3) and low robustness of these estimates with regard to the initialization of the parameters (see the study of practical identifiability of the models in supplementary text S2 and Table S3). The Gompertz model (4) was also supported by the observation that the median value of ν estimated by the generalized logistic model was close to zero.

For the breast data, superior fitting power was obtained by the exponential-linear model (1), for all but one of the metrics considered (R 2, see Table 2). For all the animals, the fits were in the linear phase of the model indicating linear tumor growth dynamics in the range of volumes observed. The Gompertz (4), generalized logistic (3) and power law (6) models still had high descriptive power, with mean RMSE and AIC similar to the exponential-linear model (Table 2). Again, as a consequence of their larger number of parameters, the dynamic CC (5), von Bertalanffy (6) and generalized logistic (3) models exhibited very large standard errors of the parameter estimates as well as large inter-animal variability (Table 3). Consequently, moderate confidence should be attributed to the specific values of the parameters estimated by the fits, although this did not affect their descriptive power.

As a general result for both data sets, all the models with two parameters were found to be identifiable (Tables 2 and 3). This was confirmed by a study of practical identifiability performed by systematically varying the initial condition of the minimization algorithm (see supporting text S2 and Table S3). For the theories that were able to fit (power law (6) and Gompertz (4) models for the lung tumor data and additionally the exponential-linear model (1) for the breast tumor data), the values of the parameters and their coefficient of variability provided a fairly good characterization of the tumor growth curves dynamics and inter-animal variability. In particular, the power γ of the power law model identified in the lung tumor data set seemed to accurately represent the growth of the LLC experimental model (low standard errors and coefficient of variation). Results of inter-animal variability suggested a larger heterogeneity of growth curves in the breast tumor data than in the lung tumor data set, which could be explained by the different growth locations (orthotopic versus ectopic).

Taken together, our results show that, despite the complexity of internal cell populations and tissue organization, at the macroscopic scale tumor growth exhibits relatively simple dynamics that can be captured through mathematical models. Models with three parameters, and more specifically the generalized logistic model (3), were found highly descriptive but not identifiable. For description of subcutaneous in vivo tumor growth of LLC cells, the Gompertz (4) and power law (6) models were found to exhibit the best compromise between number of parameters and descriptive power. Orthotopic growth of LM2-4LUC+ cells showed a clear linear trend in the range of observed volumes, well captured by the exponential-linear (1), power law (6) and Gompertz (4) models.

Forecasting tumor growth: Individual curves

The two models that were shown unable to describe our data in the previous section, namely the exponential 1 (1) and logistic (3) models, were excluded from further analysis. The remaining ones were assessed for their predictive power. The challenge considered was to predict future growth based on parameter estimation performed on a subset of the data containing only n data points (with n<Ij for a given j). We refer to the Materials and Methods section for the definitions of prediction metrics and success scores.

Models' predictive power for n = 5

The initial scenario considered the prediction of future growth based on the first five data points.

We first describe the results for the lung data set. Figure 3 presents a representative example of predictions in this setting for a given animal of the lung tumor data set (mouse 2, see Figure S2A for specific predictions for each of the animals using the Gompertz model (4)). The success criterion that we defined in the Materials and Methods was found to be in agreement with direct visual examination. According to this metric, the power law (6), dynamic CC (5) and von Bertalanffy (6) models seemed able to accurately predict the global future growth curve while the exponential V   (1), exponential-linear (1), Gompertz (4) and generalized logistic (3) models, although passing close to the next data point, were less accurate for prediction of the remainder of the data.

Quantifications of the goodness of the prediction on the total population, reported in Table 5 (see the metric  ) showed that the prediction success depended on the mouse under consideration. Despite the low predictive power of the curve of Figure 3, the Gompertz model (together with the von Bertalanffy model), had the best global score  , predicting 9/20 mice. A more detailed examination of mice for when the Gompertz model (4) failed (Figure S2.A), indicated that most of time the model interpreted too strongly an initial slowdown. This resulted in large underestimation of future data points (see mice 3, 4, 5 and 13 in Figure S2.A). The same predictive pattern and almost identical predictive curves were observed for the von Bertalanffy (6), dynamic CC (5) and power law (6) models. On the other hand, when using the generalized logistic model (3), some growth curves showed a different predictive pattern (see Figure S2.B). Due to the high flexibility already observed in the descriptive study, this model often saturated early to fit the first five data points, resulting in poor future predictions.

Study of short term predictability, for instance at a depth of two days (score  , Table 5), showed that no more than an average relative precision of 19% should be expected, for all predictions taken together.

Substantial differences and overall better predictability were found for the same setting (n = 5) for the breast tumor data. For instance, the average relative precision at a depth of two days was 13%, using the exponential-linear model. This improved predictability was also expressed by a higher  , although caution should be employed in this comparison since the number of points predicted in   was lower in the breast tumor setting than in the lung tumor setting (see Figures S2A and S3). Predictions of all animals using the exponential-linear model were reported in Figure S3 and showed that the linear dynamics exhibited by the breast tumor growth curves could explain this better predictability.

Variable number of data points used for prediction and prediction depth

For evaluation of the global predictive properties of the models, we investigated varying the number n of data points used for estimation of the parameters (respectively   and   for the lung and breast data sets) and the prediction depth d (respectively   and  ). Results are reported in Figure 4 and Tables 5 and 6.

In contrast with its high descriptive power (Tables 1 and 2), the generalized logistic model (3) was found to have the lowest overall mean success rate with all (n,d) settings pooled together for both data sets (Tables 5 and 6). In this case, high descriptive power and low predictive ability were linked together. Indeed, the generalized logistic model (3) suffered from its flexibility when put in a predictive perspective. As expressed before for the case n = 5, the model fitted very well the initial parts of the curves, but this resulted in premature saturation of the tumor growth and eventually low prediction scores (see Figure S2.B). On the other hand, high success scores were obtained when the model was fed with a lot of data (n large, see Figure 4.A). This result emphasizes that a model's high descriptive abilities might not always translate into high predictive power.

We now focus on specific results of predictive patterns for each data set. For the lung tumors, according to their predictive patterns in the (n,d) plane, the four models von Bertalanffy (6), Gompertz (4), dynamic CC (5) and power law (6) could be grouped together, and only one of them is presented in Figure 4A (the von Bertalanffy model (6), see Figure S4.A for the predictive patterns of the other models). Interestingly, what occurred with the generalized logistic model (lower predictive power associated to high flexibility) was not observed for the two other three-parameter models (von Bertalanffy (6) and dynamic CC (5)). This indicates a rigidity of these models similar to the power law (6) and Gompertz (4) models, despite an additional degree of freedom. Taken together, these four models had moderate predictive power, with mean overall prediction scores lower than 45%. The exponential V   (1) and exponential-linear (1) models were found to have even lower predictive power (Table 5), suggesting that the exponential initial phase of the growth in this data set, might not be predictive of future growth. In most of the situations, the prediction success was found to increase with n and decrease with d (see the von Bertalanffy model (6) in Figure 4.A). Whenever this did not occur (such as in the exponential V   (1) predictive pattern of Figure 4.A) it was, for most of the cases, due to the fact that the two sets of animals predicted in the two situations were different. In other words, if   was observed with  , the animals in   were usually different from the ones in   (see Materials and Methods, Models prediction methods for the definition of   and see also Figure S2). This did not imply that the same data points were less accurately predicted with n larger. Surprisingly, this last case was nevertheless observed in some rare settings. For instance, with mouse 19, the generalized logistic model successfully predicted the volumes at days 17 and 18 using four data points (corresponding to   and (4,4)), but failed to do so with five data points (corresponding to   and (5,3)), see Figure S4.

For the breast tumor data, predictability was found to be higher than in the lung tumor data, with an excellent overall mean prediction success of the exponential-linear model (1) (83.8%, see Table 6). Consequently, this model ranked 20 percentage points higher than the second best model (dynamic CC (5)). The average score of the exponential-linear model (1) resulted from a wide spread predictability in the   plane (Figure 4.B), with high success rates even at the far future prediction depth with a small number of data points (for instance, all five of the animals having a data point at   were successfully predicted, S   = 100%). While the exponential V   (1) showed low predictive power, the von Bertalanffy (6), Gompertz (4), power law (6) and dynamic CC (5) models were similarly predictive, having relatively good overall mean success rates (ranging from 58.8% to 63.3%, see Table 6).

As a general result, based on the distribution of relative prediction errors (Figure 4, bottom) all the models had a general trend for underestimation of predictions.

Tumor growth was more predictable in late phases

Different tumor growth regimens exist within the same growth curve and, in a clinically relevant setting, diagnosis might occur when the tumor is already large. To explore this further, we tested the predictability of the next day data point (or the second next day when using the breast tumor data, because in this case measurements were performed every two days) in two opposite situations: either using the first three available data points (scores   and   and relative errors   and  ) or using the first three of the last four measurements, as quantified by similar metrics denoted  ,   and  . Volume ranges predicted were 303±128 mm3 and 909±273 mm3 in the early phase for the lung tumor and breast tumor data respectively, versus 1245±254 mm3 and 1383±211 mm3 in the late phases. In this last setting, in order not to artificially inject the information of the first volume being 1 mm3 at day 0, we modified the von Bertalanffy, dynamic CC, generalized logistic, Gompertz, and power law models by fixing their initial times and volumes to the previous measurement (the fifth from the end). Interestingly, the results obtained were substantially different between the two growth phases. Better predictions were obtained when predicting the end of the curve, reaching excellent scores of 12–15/16 animals successfully predicted in the case of the LLC data (and average relative errors smaller or equal than 15%, see Table 5). Similar improvements were observed for the breast tumor data, with a 63% increase from   to   for the power law model and up to an 87% increase for the exponential V   (see the bracketed numbers in Tables 5 and 6). Hence, the late phase of tumor growth appeared more predictable, possibly because of smaller curvatures of the growth curves that led to better identifiability of the models when using a limited number of data points for estimation of the parameters.

Overall, our results showed equivalent predictive power of the von Bertalanffy (6), dynamic CC (5), power law (6), and Gompertz (4) models for prediction of future tumor growth curves of subcutaneous LLC cells, with substantial prediction rates (≥70%) requiring at least four data points and at a depth no larger than one day. The exponential-linear model was better suited for the orthotopic xenograft breast tumor data, with success rates larger than 70% in most of the   cases, including excellent scores at greater depths.

Forecasting tumor growth: A priori information

When relatively fewer data points were used, for example with only three, individual predictions based on individual fits were shown to be globally limited for the lung tumor data, especially over a large time frame (Figure 4.A, Table 5). However, this situation is likely to be the clinically relevant since few clinical examinations are performed before the beginning of therapy. On the other hand, large databases might be available from previous examinations of other patients and this information could be useful to predict future tumor growth in a particular patient. In a preclinical setting of drug investigation, tumor growth curves of animals from a control group could be available and usable when inferring information on the individual time course of one particular treated animal.

An interesting statistical method that could potentiate this a priori information consists in learning the population distribution of the model parameters from a given database and to combine it with the individual parameter estimation from the available restricted data points on a given animal. We investigated this method in order to determine if it could improve the predictive performances of the models. Each dataset was randomly divided into two groups. One was used to learn the parameter distribution (based on the full time curves), while the other was dedicated to predictions (limited number of data points). For a given animal of this last group, no information from his growth curve was used to estimate the a priori distributions. The full procedure was replicated 100 times to ensure statistical significance, resulting in respectively 2000 and 3400 fits performed for each model. We refer to the Materials and Methods for more technical details. Results are reported in Figure 5.

Predictions obtained using this technique were significantly improved for the lung tumors, going from an average success score of 14.9%±8.35% to 62.7%±11.9% (means ± standard deviations) for prediction of the total future curve with the power law model (6) (see Figure 5.A). Prediction success rates were improved even at large future depths. For instance, predictions 7 days in the future reached an average success rate of 50.6%, power law model (6), see Figure 5.C, while their success rate was very low with direct individual prediction (6.07%). Prediction successes reached 90% (power law model (6)) at the closer horizon of the next day data point ( ), while success rate was only 57.1% using an individual approach (Figure 5.B). Other small horizon depths also reached excellent prediction scores (Figure 5.C). The largest improvement of success rates for the power law model was observed for   that went from an average score of 6.86% (with standard deviation 7.47) to an average score of 75.2% (with standard deviation 12.9), representing more than an 11-fold increase. We report in Figure S5 the details of predictions with and without a priori information for all the animals within a given forecast group from the lung tumor data set (power law model (6)). It can be appreciated how additional information on the parameter distribution in the estimation procedure significantly improved global prediction of the tumor growth curves. The impact of the addition of the a priori information was however less important when using more data points for the estimation (results not shown).

For the breast data, due to its already high prediction score without adjunction of a priori information, the exponential-linear model did not benefit from the method. For the next day data point of the breast tumor growth curves, predictability was already almost maximal without adjunction of a priori information and thus no important impact was observed.

For both data sets, not all the models equally benefited from the addition of a priori information (Figure 5). Models having the lowest parameter inter-animal variability, such as the power law (6), Gompertz (4), exponential-linear (1), and exponential V   (1) models (Table 3), which also had better practical identifiability (Tables 2 and S3), exhibited great benefit. In contrast, the models with three parameters showed only modest benefit or even decrease of their success rates (see   and   for the von Bertalanffy model (6) on the breast tumor data in Figure 5.B), with the exception of the generalized logistic model (3) on the breast tumor data. In these cases, adjunction of a priori information translated into poor enhancement of predictive power because the mean population parameters did not properly capture the average behavior within the population and were therefore not very informative. On the other hand, models such as the power law model (6) on the lung tumor data set, whose coefficient γ characterized particularly well the growth pattern (Table 3), had a more informative a priori distribution that translated into the highest improvement of predictive power. For the generalized logistic model (3) on the breast data, the mean parameters were able to inform the linear regimen of the growth phase and thus protected the model from too early saturation.

These results demonstrated that addition of a priori information in the fit procedure considerably improved the forecast performances of the models, in particular when using a small number of data points and low-parameterized models for data with low predictability, such as the power law model for the lung tumor data set.

Discussion

Error model

In our analysis, constant variance of the error was clearly rejected and although a proportional error (used by others [33]) was not strictly rejected by statistical analysis (p = 0.08), a more adequate error model to our data was developed. However, using a proportional or even constant error model did not significantly affect conclusions as to the descriptive power of the models, identifying the same models (Tables 1, 2) as most adequate for description of tumor growth (results not shown). Nevertheless, the use of an appropriate error model could have important implications in the quantitative assessment of a model's descriptive performance and rejection of inaccurate tumor growth theories. For instance, using the same human tumor growth data, Bajzer et al. [60] found the assumption of proportional error variance to favor the Gompertz model for descriptive ability, whereas Vaidya and Alexandro [30] had observed the logistic model to be favored, under a constant-variance assumption. The error model used might additionally have important implications on predictions. Although detailed analysis of the impact of the error model on prediction power is beyond the scope of the present study, we performed a prospective study of predictive properties when using a constant error model on the lung tumor data and found changes in the ranking of the models (results not shown).

Theories of growth

As expected, our results confirmed previous observations [9]–[11], [13], [29], [32] that tumor growth is not continuously exponential (constant doubling time) in the range of the tumor volumes studied, ruling out the prospect of a constant proliferating fraction. A less expected finding was that the logistic model (linear decay in volume of the relative growth rate) was also unable to describe our data, although similar results have been observed in other experimental systems [31], [33]. On the other hand, the Gompertz and power law models could give an accurate and identifiable description of the growth slowdown, for both data sets. More elaborate models such as the generalized logistic, von Bertalanffy, and dynamic CC models could describe them as well. However, their parameters were found not to be identifiable from only tumor growth curves, in the ranges of the observed volumes. Additional data could improve identifiability, such as related to later growth and saturation details. It should be noted in this case that the dynamic CC model was not designed with the intent to quantify tumor growth, but rather to describe the effects of anti-angiogenic agents on global tumor dynamics. Because the model carries angiogenic parameters that are not directly measureable, or even inferable, from the experimental systems we used, it stands to reason that they would not be easily identifiable from the data. Kinetics under the influence of antiangiogenic therapy might thus provide useful additional information that could render this model identifiable. For the breast tumor experimental system, the slowdown was characterized by linear dynamics and was most accurately fitted by the exponential-linear model. Observed was exponential growth from the number of injected cells (during the unobserved phase) that switched smoothly to a linear phase (exponential-linear model). It should be noted that in the breast tumor data set, no data were available during the initiation phase (below 200 mm3) and only the linear part of a putative exponential-linear growth was observed. Explorations of the kinetics of growth during the initial phase (at volumes below the mm3) are needed for further clarification.

Despite structural similarities, important differences were noted in the parameter estimates between the two experimental models, in agreement with other studies emphasizing differences between ectopic and orthotopic growth [61], [62]. Our results and methodology may help to identify the impact on kinetics of the site of implantation, although explicit comparisons could not be made here due to the differences in the cell lines used.

The Gompertz model (exponential decay in time of the relative growth rate) was able to fit both data sets accurately, consistently with the literature [13], [15], [29], [31], [33]. One of the main criticisms of the Gompertz model is that the relative tumor growth rate becomes arbitrarily large (or equivalently, the tumor doubling time gets arbitrarily small) for small tumor volumes. Without invoking a threshold this becomes biologically unrealistic. This consideration led investigators [13], [63] to introduce the Gomp-exp model that consists in an initial exponential phase followed by Gompertzian growth when the associated doubling time becomes realistic. This approach could also be applied to any decreasing relative growth rate model. We did not consider it in our analysis due to the already large initial volume and the lack of data on the initiation phase where the issue is most relevant.

The power law model was also able to describe the experimental data and appeared as a simple, robust, descriptive and predictive mathematical model for murine tumor growth kinetics. It suggests a general law of macroscopic in vivo tumor growth (in the range of the volumes observed): only a subset of the tumor cells proliferate and this subset is characterized by a constant, possibly fractional, Hausdorff dimension. In our results, this dimension (equal to 3γ) was found to be significantly different from two or three (p<0.05 by Student's t-test) in 14/20 mice for the lung tumor data set and 13/34 mice for the breast tumor data, effectively suggesting a fractional dimension. A possible explanation of this feature could come from the fractal nature of the tumor vasculature [64], [65], an argument supported by others who have investigated the link between tumor dynamics and vascular architecture [37]. More precisely, the branching nature of the vascularization generates a fractal organization [37], [64], [65] that could in turn produce a contact surface of fractional Hausdorff dimension. Considering further that the fraction of proliferative cells is proportional to this contact surface (for instance because proliferative cells are limited to an area at fixed distance from a blood vessel or capillary, due to diffusion limitations), this could make the connection between fractality of the vasculature and proliferative tissue. These considerations could therefore provide a mechanistic explanation for the growth rate decay that naturally happens when the dimension of the proliferative tissue is lower than three. Our results were obtained using two particular experimental systems: an ectopic mouse syngeneic lung tumor and an orthotopic human xenograft breast tumor model. Although consistent with other studies that found the power law model adequate for growth of a murine mammary cell line [38] or for description of human mammography density distribution data [5], these remain to be confirmed by human data. This model should also be taken with caution when dealing with very small volumes (at the scale of several cells for instance) for which the relative growth rate becomes very large. Indeed, the interpretation of a fractional dimension then fails, since the tumor tissue can no longer be considered a continuous medium. In this instance, it may be more appropriate to consider exponential growth in this phase [37].

Prediction

Our results showed that a highly descriptive model (associated to large flexibility) such as the generalized logistic model, might not be useful for predictions, while well-adapted rigidity – as provided by the exponential-linear model on the breast tumor data – could lead to very good predictive power. Interestingly, our study revealed that models having low identifiability (von Bertalanffy and dynamic CC) could nevertheless exhibit good predictive power. Indeed, over a limited time span, different parameter sets for a given model could generate the same growth curves, which would be equally predictive.

For the Gompertz model, predictive power might be improved by using possible correlations between the two parameters of this model, as reported by others [15], [63], [66]–[68] and suggested by our own parameter estimates (R = 0.99 for both data sets, results not shown).

If a backward prediction is desired (for instance for the identification of the inception time of the tumor), the use of exponential growth might be more adapted for the initial, latency phase, e.g. by employment of the Gomp-exp model [13], [63].

Clinical and preclinical implications

Translating our results to the clinical setting raises the possibility of forecasting solid tumor growth using simple macroscopic models. Use of a priori information could then be a powerful method and one might think of the population distribution of parameters being learned from existing databases of previous patient examinations. However, the very strong improvement of prediction success rates that we obtained partly comes from the important homogeneity of our growth data (in particular the LLC data) that generated a narrow and very informative distribution of some parameters (for instance parameter γ of the power law model), which in turn powerfully assisted the fitting procedure. In more practical situations such as with patient data, more heterogeneity of the growth data should be expected that could alter the benefit of the method. For instance, in some situations, growth could stop for arbitrarily long periods of time. These dormancy phases challenge the universal applicability of a generic growth law such as the Gompertz or power law [69]. Description of such dormancy phenomena could be integrated using stochastic models that would elaborate on the deterministic models reviewed here, as was done by others [70] to describe breast cancer growth data using the Gompertz model. Moreover, further information than just tumor volume could be extracted from (functional) imaging devices, feeding more complex mathematical models that could help design more accurate in silico prediction tools [18], [71].

Our analysis also has implications for the use of mathematical models as valuable tools for helping preclinical anti-cancer research. Such models might be used, for instance, to specifically ascertain drug efficacy in a given animal, by estimating how importantly the treated tumor deviates from its natural course, based on a priori information learned from a control group. Another application can be for rational design of dose and scheduling of anti-cancerous drugs [22], [72], [73]. Although integration of therapy remains to be added (and validated) to models such as the power law, more classical models (exponential-linear [39] or dynamic CC [41]) have begun to predict cytotoxic or anti-angiogenic effects of drugs on tumor growth. Our methods have allowed precise quantification of their respective descriptive and predictive powers, which, in combination with the models' intrinsic biological foundations, could be of value when deciding among such models which best captures the observed growth behaviors in relevant preclinical settings.

Supporting Information

Data. Plots of the brute data sets from the lung and breast experiments. A. All animals' growth curves. B. Average curves. C. Per group averages (lung and breast data resulted from combinations of respectively two and three separate experiments). G = group.. (TIF). Click here for additional data file. 
Examples of individual predictions: Lung data. Prediction success of the model are reported for the next day (OK1) or global future curve (OKglob), based on the criterion of a normalized error smaller than 3 (meaning that the median model prediction is within 3 standard deviations of the measurement error) for OK1 and the median of this metric over the future curve for OKglob. Future growth was predicted using 5 data points and the von Bertalanffy model.. (PDF). Click here for additional data file. 
Examples of individual predictions: Breast data. Prediction success of the model are reported for the second next day data point (OK2) or global future curve (OKglob), based on the criterion of a normalized error smaller than 3 (meaning that the median model prediction is within 3 standard deviations of the measurement error) for OK2 and the median of this metric over the future curve for OKglob. Future growth was predicted using 5 data points and the exponential-linear model.. (PDF). Click here for additional data file. 
Prediction. Top: Prediction success for models that were not reported in Figure 4. Bottom: Example where prediction was less successful when using n = 5 data points than when using n = 4 data points, with the generalized logistic model.. (TIF). Click here for additional data file. 
Forecast improvement of the power law model when using 
a priori
 information and the lung data set. Fits were performed using the first three data points for each animal. A priori information (learned on a different data set) was added during the fit procedure for the predictions on the right.. (TIF). Click here for additional data file. 
Initializations of the least squares minimization algorithm. Also reported are bounds used in lsqcurvefit for estimation of parameters of the power law, von Bertalanffy and exponential-linear models.. (DOCX). Click here for additional data file. 
Comparison of individual fits between the individual and population approaches. Fits were performed using either an individual estimation of the growth curves based on weighted least-squares estimation or a population approach. In both settings, the error model was proportional to the volume to the power α = 0.84. The only difference was that Monolix estimation did not allow for a setting with a threshold volume Vm, which was thus taken to be 0. However, due to its low value (Vm = 83 mm3), it was not very active in the individual approach. Reported are the mean (over the time points) weighted least squares (i.e. the ones of the first column of Tables 1, 2 except with Vm = 0, i.e. the Monolix setting), for both approaches. More precisely, if  with  being the individual estimate of parameter set β in animal j, using either the individual approach () or the population approach (). The numbers reported are the mean value of (over the population, i.e. over index j) as well as minimal and maximal values. Note that due to the relatively large volumes of the breast data, Vm was not active and the values of the individual approach are exactly the ones of Table 2 in this case (S2.B). Last column is the p-value of Student's t-test for significant differences between the individual and population approaches. A. Lung data set. B. Breast data set.. (PDF). Click here for additional data file. 
Practical identifiability. Two identifiability scores were reported. The fit score is the proportion of minimization runs, among the 20× NP performed, for which the resulting minimized objective converged to the same value as when starting from the baseline value. The global parametric score is the proportion of minimization runs that converged to the same parameter vector, within a 10% relative error. When this last score was lower than 100%, further analysis was conducted and the same score was computed for each parameter of the model. We also reported their median relative deviation to the base value, in percent. Par. = Parameter. Dev. = Deviation.. (PDF). Click here for additional data file. 
Numerical procedures for estimation of parameters.
. (DOCX). Click here for additional data file. 
Practical identifiability of the models.
. (DOCX). Click here for additional data file. 

Figure 1

A. First measured volume y   against second one y  . Also plotted is the regression line (correlation coefficient R = 0.98, slope of the regression  = 0.96). B. Error   against approximation of the volume given by the average of the two measurement  . The χ 2 test rejected Gaussian distribution of constant variance ( ) C. Histogram of the normalized error   applying the error model given by   with α = 0.84 and Vm = 83 mm3. It shows Gaussian distribution (χ 2 test not rejected, p = 0.196) with standard deviation  .

Figure 2

A. Representative examples of all growth models fitting the same growth curve (animal 10 for lung, animal 14 for breast). Error bars correspond to the standard deviation of the a priori estimate of measurement error. In the lung setting, curves of the Gompertz, power law, dynamic CC and von Bertalanffy models are visually indistinguishable. B. Corresponding relative growth rate curves. Curves for von Bertalanffy and power law are identical in the lung setting. C. Residuals distributions, in ascending order of mean RMSE (13) over all animals. Residuals (see formula (15) for their definition) include fits over all the animals and all the time points. Exp1 = exponential 1, Exp-L = exponential-linear, Exp V   = exponential V  , Log = logistic, GLog = generalized logistic, PL = power law, Gomp = Gompertz, VonBert = von Bertalanffy, DynCC = dynamic CC.

Figure 3

Representative examples of the forecast performances of the models for the lung data set (mouse number 2). Five data points were used to estimate the animal parameters and predict future growth. Prediction success of the models are reported for the next day data point (OK ) or global future curve (OK ), based on the criterion of a normalized error smaller than 3 (meaning that the model prediction is within 3 standard deviations of the measurement error) for OK  and the median of this metric over the future curve for OK  (see Materials and Methods for details).

Figure 4

Predictive power of some representative models depending on the number of data points used for estimation of the parameters (n) and the prediction depth in the future (d). Top: at position (n,d) the color represents the percentage of successfully predicted animals when using n data points and forecasting the time point  , as quantified by the score   (multiplied by 100), defined in (17). This proportion only includes animals having measurements at these two time points, thus values at different row d on the same column n or reverse might represent predictions in different animals. White squares correspond to situations where this number was too low (<5) and thus success score, considered not significant, was not reported. Bottom: distribution of the relative error of prediction (20), all animals and (n,d) pooled together. Models were ranked in ascending order of overall mean success score reported in Tables 5 and 6. A. Lung tumor data. B. Breast tumor data.

Figure 5

Predictions were considered when randomly dividing the animals between two equal groups, one used for learning the parameters distribution and the other for prediction, using n = 3 data points. Success rates are reported as mean ± standard deviation over 100 random partitions into two groups. A. Prediction of global future curve, quantified by the score   (see Materials and Methods, Models predictions methods for its definition). B. Benefit of the method for prediction of the next day, using three data points (score  ). C. Prediction improvement at various prediction depths, using the power law model (lung data) or the exponential-linear model (breast data). Due to lack of animals to be predicted for some of the random assignments, results of depths 2, 4, 6 and 9 for the breast data were not considered significant and were not reported (see Materials and Methods). * = p<0.05, ** = p<0.001, Student's t-test.

