{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26f337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af8ff291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(extract_data(get_nxml_from_pmcid(\"PMC7581548\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a47faa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "        html_doc = ''.join(f.readlines())\n",
    "    return html_doc\n",
    "\n",
    "\n",
    "allowed_text_between_refs = [',', ';', '-', '–', ' ']\n",
    "def sentence_extract(p, full_text, annotation, markers, surrounding_markers):\n",
    "    p_text = ''\n",
    "    prev_3_tags = (None, None, None)\n",
    "    for n in p.contents:\n",
    "        has_annotation = False\n",
    "        if n.name == None:\n",
    "            p_text += n.replace('\\n', ' ')\n",
    "\n",
    "        elif n.name == 'sup':\n",
    "            full_text += p_text\n",
    "            p_text = ''\n",
    "            full_text, annotation = sentence_extract(n, full_text, annotation, markers, surrounding_markers)\n",
    "            full_text = full_text[:-2]\n",
    "\n",
    "        elif n.name  == 'xref' and markers is not None and (n['rid'] in markers):\n",
    "            xref_text = n.text.replace('\\n', ' ')\n",
    "            \n",
    "            # annotate marker\n",
    "            ann_tag = 'Citation'\n",
    "            \n",
    "            # if at least 1 of the previous 2 tags is xref,\n",
    "            # then this citations is part of a multi-citation\n",
    "            if (prev_3_tags[2] and prev_3_tags[2].startswith('xref')) or \\\n",
    "            (prev_3_tags[1] and prev_3_tags[1].startswith('xref') and prev_3_tags[2] in allowed_text_between_refs):\n",
    "                ann_tag = 'MultiCitation'\n",
    "            # to do: check for cases other than [',', ';', '-', '–']\n",
    "            offset = len(full_text) + len(p_text)\n",
    "            annotation.append(f'T{len(annotation)}\\t{ann_tag} {offset} {offset + len(xref_text)}\\t{xref_text}')\n",
    "            has_annotation = True\n",
    "            \n",
    "            p_text += xref_text\n",
    "            \n",
    "        #########\n",
    "        elif n.name == 'xref' and markers is not None and surrounding_markers is not None:\n",
    "            xref_text = n.text.replace('\\n', ' ')\n",
    "            if prev_3_tags[2] and prev_3_tags[2].startswith('xref'):\n",
    "                _, prev_id, prev_len = prev_3_tags[2].split(\"$\")\n",
    "                prev_len = int(prev_len)\n",
    "                \n",
    "                if prev_id in surrounding_markers and n['rid'] in surrounding_markers:\n",
    "                    ann_tag = 'MultiCitation'\n",
    "                    # to do: check for cases other than [',', ';', '-', '–']\n",
    "                    offset = len(full_text) + len(p_text)\n",
    "                    annotation.append(f'T{len(annotation)}\\t{ann_tag} {offset-prev_len} {offset + len(xref_text)}\\t{p_text[-prev_len:] + xref_text}')\n",
    "                    has_annotation = True\n",
    "                p_text += xref_text\n",
    "       \n",
    "                    \n",
    "            elif (prev_3_tags[1] and prev_3_tags[1].startswith('xref') and prev_3_tags[2] in allowed_text_between_refs):\n",
    "\n",
    "                _, prev_id, prev_len = prev_3_tags[1].split(\"$\")\n",
    "                prev_len = int(prev_len)\n",
    "                if prev_id in surrounding_markers and n['rid'] in surrounding_markers:\n",
    "                    ann_tag = 'MultiCitation'\n",
    "                    # to do: check for cases other than [',', ';', '-', '–']\n",
    "                    offset = len(full_text) + len(p_text)\n",
    "                    annotation.append(f'T{len(annotation)}\\t{ann_tag} {offset-prev_len-1} {offset + len(xref_text)}\\t{p_text[-prev_len-1:] + xref_text}')\n",
    "                    has_annotation = True\n",
    "                p_text += xref_text\n",
    "            else:\n",
    "                p_text += n.text.replace('\\n', ' ')          \n",
    "            \n",
    "        #############\n",
    "            \n",
    "        elif n.name in ['xref', 'sup', 'italic', 'named-content']:\n",
    "            p_text += n.text.replace('\\n', ' ')\n",
    "        elif n.name == 'table-wrap':\n",
    "            # title of figure and table\n",
    "            label = n.label.text.replace('\\n', ' ') if n.label else ''\n",
    "            caption = n.caption.text.replace('\\n', ' ') if n.caption else ''\n",
    "            caption_text = label + \" \" + caption + \". \"\n",
    "            full_text += caption_text\n",
    "#             print(caption_text)\n",
    "        elif n.name == \"title\":\n",
    "            p_text += n.get_text() + \"\\n\\n\"\n",
    "        elif n.name == \"ext-link\":\n",
    "            p_text += n.get_text()\n",
    "        elif n.name == 'fig':\n",
    "            continue\n",
    "        else:\n",
    "            n_text = '. '.join([i.get_text() for i in n.findAll('p')])\n",
    "            p_text += n_text + \" \"\n",
    "        \n",
    "        if has_annotation:\n",
    "            prev_3_tags = (prev_3_tags[1], prev_3_tags[2], 'annotation')\n",
    "            \n",
    "            \n",
    "        ##############\n",
    "        elif n.name == 'xref':\n",
    "            prev_3_tags = (prev_3_tags[1], prev_3_tags[2], n.name + \"$\" + n['rid'] + \"$\" + str(len(n.text.replace('\\n', ' '))))\n",
    "            \n",
    "        ###############\n",
    "            \n",
    "        elif n.name == None:\n",
    "            prev_3_tags = (prev_3_tags[1], prev_3_tags[2], n.strip())\n",
    "        else:\n",
    "            prev_3_tags = (prev_3_tags[1], prev_3_tags[2], n.name)\n",
    "            \n",
    "        if prev_3_tags[0] == 'annotation' and '\\tCitation ' in annotation[-1] \\\n",
    "            and (prev_3_tags[1] == 'xref' or (prev_3_tags[2] == 'xref' and \\\n",
    "                                            prev_3_tags[1] in allowed_text_between_refs)):\n",
    "            annotation[-1] = annotation[-1].replace('\\tCitation ', '\\tMultiCitation ')\n",
    "    full_text += p_text + '\\n\\n'\n",
    "    return full_text, annotation\n",
    "\n",
    "\n",
    "def paragraph_extract(sec, full_text, annotation, markers, surrounding_markers, paragraph_markers, offset):\n",
    "    if sec.find('p', recursive=False):\n",
    "        for p in sec.findAll('p', recursive=False):\n",
    "            full_text, annotation = sentence_extract(p, full_text, annotation, markers, surrounding_markers)\n",
    "            full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "        full_text += '\\n\\n'\n",
    "        full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers, False)\n",
    "    return full_text, annotation, paragraph_markers, offset\n",
    "\n",
    "\n",
    "def iter_extract(sec, full_text, text_section, annotation, markers, surrounding_markers,  paragraph_markers, offset):\n",
    "    if sec.find('sec', recursive=False): # if there are subsections\n",
    "        section_level = 0\n",
    "        pre_c = len(full_text)\n",
    "        if sec.title:\n",
    "            full_text += sec.title.text + '\\n\\n'\n",
    "            full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "#         if sec.find('fig'):\n",
    "#             print('first if')\n",
    "#             for fig in sec.findAll('fig', recursive=False):\n",
    "#                 label = fig.label.text.replace('\\n', ' ') if fig.label else ''\n",
    "#                 caption = fig.caption.text.replace('\\n', ' ') if fig.caption else ''\n",
    "#                 caption_text = label + \" \" + caption + \". \"\n",
    "#                 full_text += caption_text + \"\\n\"\n",
    "                \n",
    "#                 # each figure is it's own paragraph\n",
    "#                 full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "#                                                                                 offset, paragraph_markers)\n",
    "        full_text, annotation, paragraph_markers, offset = paragraph_extract(sec, full_text, \n",
    "                                                             annotation, markers, surrounding_markers, paragraph_markers, offset)\n",
    "        full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "        \n",
    "        if len(sec.findAll('sec', recursive=False)) != 0:\n",
    "            section_level += 1\n",
    "                \n",
    "        for i in sec.findAll('sec', recursive=False):\n",
    "            full_text, text_section, annotation, paragraph_markers, offset = iter_extract(i, full_text, \n",
    "                                                  text_section, annotation, markers, surrounding_markers, paragraph_markers, offset)\n",
    "\n",
    "        after_c = len(full_text)\n",
    "\n",
    "        sec_name = sec.title.text if sec.title else ''\n",
    "        if sec_name in text_section.keys():\n",
    "            if text_section[sec_name][-1]-pre_c == -1:\n",
    "                text_section[sec_name][-1] = after_c-1\n",
    "                text_section[sec_name][0] = section_level\n",
    "            elif text_section[sec_name][-2] == pre_c and text_section[sec_name][-1] == after_c-1:\n",
    "                pass\n",
    "            else:\n",
    "                text_section[sec_name].extend([pre_c, after_c-1,section_level])\n",
    "        else:\n",
    "            text_section[sec.title.text if sec.title else ''] = [pre_c, after_c-1,section_level]\n",
    "        return full_text, text_section, annotation, paragraph_markers, offset\n",
    "    elif not sec.find('p', recursive=False):\n",
    "        section_level = 0\n",
    "        if sec:\n",
    "            pre_c = len(full_text)\n",
    "            full_text, annotation = sentence_extract(sec, full_text, annotation, markers, surrounding_markers)\n",
    "            full_text += '\\n\\n'\n",
    "            full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "            \n",
    "            after_c = len(full_text)\n",
    "            sec_name = sec.title.text if sec.title else ''\n",
    "            if sec_name in text_section.keys():\n",
    "                if text_section[sec_name][-1]-pre_c == -1:\n",
    "                    text_section[sec_name][-1] = after_c-1\n",
    "                    text_section[sec_name][0] = section_level\n",
    "                else:\n",
    "                    text_section[sec_name].extend([pre_c, after_c-1,section_level])\n",
    "            else:\n",
    "                text_section[sec.title.text if sec.title else ''] = [pre_c, after_c-1,section_level]\n",
    "            return full_text, text_section, annotation, paragraph_markers, offset\n",
    "    else: # if this is the only section\n",
    "        section_level = 0\n",
    "        pre_c = len(full_text)\n",
    "        if sec.title:\n",
    "            full_text += sec.title.text.replace('\\n', ' ') + '\\n\\n'\n",
    "            full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "        \n",
    "        full_text, annotation, paragraph_markers, offset = paragraph_extract(sec, full_text, \n",
    "                                                             annotation, markers, surrounding_markers,  paragraph_markers, offset)\n",
    "        full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "        # full_text += ' '.join([j.get_text().replace('\\n', ' ') for j in sec.findAll('p')]) + '\\n'\n",
    "        after_c = len(full_text)\n",
    "        sec_name = sec.title.text if sec.title else ''\n",
    "        if sec_name in text_section.keys():\n",
    "            if text_section[sec_name][-1]-pre_c == -1:\n",
    "                text_section[sec_name][-1] = after_c-1\n",
    "                text_section[sec_name][0] = section_level\n",
    "            else:\n",
    "                text_section[sec_name].extend([pre_c, after_c-1,section_level])\n",
    "        else:\n",
    "            text_section[sec.title.text if sec.title else ''] = [pre_c, after_c-1,section_level]\n",
    "        return full_text, text_section, annotation, paragraph_markers, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5eb3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(extract_data(get_nxml_from_pmcid(\"PMC7581548\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0e3c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################  CHANGE START #####################################\n",
    "def figure_caption_extract(sec, full_text, annotation, offset, markers, surrounding_markers, paragraph_markers):\n",
    "# def figure_caption_extract(sec, full_text, text_section, annotation, markers, paragraph_markers, offset):\n",
    "    #if sec.find('fig', recursive=True):\n",
    "    for fig in sec.findAll('fig', recursive=True):\n",
    "        label = fig.label.text.replace('\\n', ' ') if fig.label else ''\n",
    "        full_text += label + \"\\n\\n\"\n",
    "        \n",
    "        full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "        \n",
    "#         full_text, annotation = iter_extract(fig, full_text, text_section , annotation, markers, \n",
    "#                                              paragraph_markers, offset)\n",
    "#         full_text, annotation = sentence_extract(fig.find('caption'), full_text, annotation, markers)\n",
    "        if fig.caption:\n",
    "            for p in fig.caption.findAll('p', recursive=False):\n",
    "                full_text, annotation = sentence_extract(p, full_text, annotation, markers, surrounding_markers)\n",
    "                full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                              offset, paragraph_markers)\n",
    "\n",
    "        #caption = fig.caption.text.replace('\\n', ' ') if fig.caption else ''\n",
    "        #full_text += caption + \"\\n\\n\"\n",
    "        \n",
    "#         full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "#                                                                           offset, paragraph_markers)\n",
    "        \n",
    "    return full_text, annotation, offset, paragraph_markers\n",
    "#######################################  CHANGE END #######################################\n",
    "\n",
    "def cleanup_text_and_add_paragraph_marker(full_text, current_offset, paragraph_markers, add_marker = True):\n",
    "    while '\\n\\n\\n' in full_text:\n",
    "        full_text = full_text.replace('\\n\\n\\n', '\\n\\n')\n",
    "    if add_marker and not current_offset == len(full_text):\n",
    "        paragraph_markers.append(f\"{current_offset} {len(full_text)}\")\n",
    "    new_offset = len(full_text)\n",
    "    return full_text, new_offset, paragraph_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cb939ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file, num = None, markers = None, surrounding_markers=None):\n",
    "    html_doc = load_data(file)\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser').findAll('article', recursive=False)[0]\n",
    "\n",
    "    for c in soup.children:\n",
    "        if c.name not in ['front', 'body', 'back', 'floats-group']:\n",
    "            c.replaceWith('')\n",
    "\n",
    "    section_header = []\n",
    "    text_section = dict()\n",
    "    article_meta = soup.findAll('article-meta')[0].findAll('article-id')\n",
    "\n",
    "    article_meta = [i.text for i in article_meta if i['pub-id-type'] == 'pmid'][0]\n",
    "    if num:\n",
    "        if article_meta in num:\n",
    "            return False, False, False\n",
    "\n",
    "    full_text = ''\n",
    "    annotation = []\n",
    "    paragraph_markers = []\n",
    "    \n",
    "#     # title section\n",
    "    offset = 0\n",
    "    title = soup.findAll('title-group')\n",
    "    if len(title) == 1:\n",
    "        title = title[0].find('article-title').get_text(separator=' ').replace('\\n', ' ')\n",
    "        full_text += title+'\\n'\n",
    "    else:\n",
    "        text_section['title']=[0, full_text.__len__()-1]\n",
    "        \n",
    "    # title is it's own paragraph\n",
    "    full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "                        \n",
    "    # abstract section (fixed by Shruthan)\n",
    "    abstract = soup.findAll('abstract')\n",
    "    if abstract:\n",
    "        for abs in abstract:\n",
    "            if (not abs.get('abstract-type')) or abs.get('abstract-type') not in \\\n",
    "                                ['toc', 'graphical', 'teaser', 'author-highlights']:\n",
    "                if not abs.find('title', recursive=False):\n",
    "                    full_text += '\\nAbstract\\n\\n'\n",
    "                    full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers, False)\n",
    "                abs_sec = abs.contents\n",
    "                for sec in abs_sec:\n",
    "                    if type(sec) is bs4.element.NavigableString:\n",
    "                        full_text += sec\n",
    "                        full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "                    elif type(sec) is bs4.element.Comment:\n",
    "                        pass\n",
    "                    else:\n",
    "                        full_text, text_section, annotation, paragraph_markers, offset = iter_extract(\n",
    "                                    sec, full_text, text_section, annotation, markers, surrounding_markers, paragraph_markers, offset)\n",
    "    else:\n",
    "        abstract = ''\n",
    "        if title in text_section: # check these cases\n",
    "            text_section['abstract'] = [text_section['title'][1], full_text.__len__()-1]\n",
    "\n",
    "    # body section\n",
    "    body = soup.findAll('body')\n",
    "    if len(body) > 0:\n",
    "        full_text += '\\n'\n",
    "        full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers, False)\n",
    "        if len(body) == 1:\n",
    "            body = body[0].contents\n",
    "            for sec in body:\n",
    "                if type(sec) is bs4.element.NavigableString:\n",
    "                    full_text += sec\n",
    "                    full_text, offset, paragraph_markers = cleanup_text_and_add_paragraph_marker(full_text, \n",
    "                                                                                offset, paragraph_markers)\n",
    "                elif type(sec) is bs4.element.Comment:\n",
    "                    pass\n",
    "                else:\n",
    "                    full_text, text_section, annotation, paragraph_markers, offset = iter_extract(sec, full_text, \n",
    "                                                                      text_section, annotation, \n",
    "                                                                      markers, surrounding_markers, paragraph_markers, offset)\n",
    "    full_text, annotation, offset, paragraph_markers = figure_caption_extract(soup, full_text, \n",
    "                                                              annotation, offset, markers, surrounding_markers, paragraph_markers)\n",
    "#     full_text, annotation, offset, paragraph_markers = figure_caption_extract(sec, full_text, \n",
    "#                                        text_section, annotation, markers, paragraph_markers, offset)\n",
    "    \n",
    "#     float_group = soup.findAll('floats-group')\n",
    "#     print(len(float_group))\n",
    "    # back section\n",
    "#     back_matter_text = \"\"\n",
    "#     back = soup.findAll('back')\n",
    "#     if len(back) > 0:\n",
    "#         for sec in back[0].contents:\n",
    "#             #foot note\n",
    "#             if sec.name == \"fn-group\":\n",
    "#                 foot_notes = sec.findAll(\"fn\")\n",
    "#                 for foot_note in foot_notes:\n",
    "#                     foot_note_text = '\\n'.join([i.get_text() for i in foot_note.findAll('p')])  \n",
    "#                     back_matter_text += foot_note_text\n",
    "#                 back_matter_text += \"\\n\"                      \n",
    "#             #acknowledgement\n",
    "#             if sec.name == \"ack\":\n",
    "#                 sec_title = sec.find(\"title\").get_text()\n",
    "#                 back_matter_text += sec_title\n",
    "#                 back_matter_text += \"\\n\"\n",
    "#                 sec_text = ' '.join([i.get_text() for i in sec.findAll('p', recursive=False)])          \n",
    "#                 back_matter_text += sec_text\n",
    "#                 sub_sections = sec.findAll('sec')\n",
    "#                 for sub_sec in sub_sections:\n",
    "#                     if sub_sec.find(\"title\"):\n",
    "#                         back_matter_text += \"\\n\"\n",
    "#                         sub_sec_title = sub_sec.find(\"title\").get_text()\n",
    "#                         back_matter_text += sub_sec_title\n",
    "#                         back_matter_text += \"\\n\"\n",
    "#                         sub_sec_text = ' '.join([i.get_text() for i in sub_sec.findAll('p')])\n",
    "#                         back_matter_text += sub_sec_text\n",
    "                        \n",
    "#             #notes\n",
    "#             if sec.name == \"notes\":\n",
    "#                 sub_sections = sec.findAll('sec')\n",
    "#                 for sub_sec in sub_sections:\n",
    "#                     if sub_sec.find(\"title\"):\n",
    "#                         back_matter_text += \"\\n\" \n",
    "#                         sub_sec_title = sub_sec.find(\"title\").get_text()\n",
    "#                         back_matter_text += sub_sec_title\n",
    "#                         back_matter_text += \"\\n\"\n",
    "#                         sub_sec_text = ' '.join([i.get_text() for i in sub_sec.findAll('p')])\n",
    "#                         back_matter_text += sub_sec_text\n",
    "            \n",
    "#             #sections\n",
    "#             if sec.name == \"sec\":\n",
    "#                 if sec.find(\"title\"):\n",
    "#                     sec_title = sec.find(\"title\").get_text()\n",
    "#                     back_matter_text += sec_title\n",
    "#                     back_matter_text += \"\\n\"\n",
    "#                     sec_text = ' '.join([i.get_text() for i in sec.findAll('p')])\n",
    "#                     back_matter_text += sec_text\n",
    "                    \n",
    "#             #glossary\n",
    "#             if sec.name == \"glossary\":\n",
    "#                 if sec.find(\"title\"):\n",
    "#                     sec_title = sec.find(\"title\").get_text()\n",
    "#                     back_matter_text += sec_title\n",
    "#                     terms = sec.findAll(\"def-item\")\n",
    "#                     for term in terms:\n",
    "#                         back_matter_text += \"\\n\"\n",
    "#                         term_abb = term.find(\"term\").get_text()\n",
    "#                         term_meaning = term.find(\"p\").get_text()\n",
    "#                         back_matter_text += term_abb + \" \" + term_meaning\n",
    "                        \n",
    "#     full_text +=back_matter_text\n",
    "#     for j in soup.find_all('floats-group', recursive=True):\n",
    "#         print(j.name)\n",
    "    return full_text, article_meta, text_section, annotation, paragraph_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adac8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brat_data(input_file, output_filename, markers = None, surrounding_markers=None):   \n",
    "    annotation = \"\"\n",
    "    processed_full_text = \"\"\n",
    "\n",
    "    full_text, PMID, section_header, annotation, paragraph_markers = extract_data(input_file, markers = markers, surrounding_markers=surrounding_markers)\n",
    "   \n",
    "    with open(output_filename + \".txt\", \"w+\") as o:\n",
    "        o.write(full_text) \n",
    "        \n",
    "    with open(output_filename + \"_par.csv\", \"w\") as o:\n",
    "        o.write('\\n'.join(paragraph_markers))\n",
    "        \n",
    "    with open(output_filename + \"_sec.json\", \"w\") as o:\n",
    "        json.dump(section_header, o)\n",
    "\n",
    "    if markers is not None:\n",
    "        with open(output_filename + \".ann\", \"w\") as o:\n",
    "            o.write('\\n'.join(annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d128c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "citation_context = pd.read_csv(\"covid_context_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6a2142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sampled_res_30.json') as f:\n",
    "    oa_paper_citations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0384b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"pmc-fulltext-nxml\"\n",
    "output_folder = \"output30\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e1fcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pmid</th>\n",
       "      <th>location</th>\n",
       "      <th>IMRaD</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>total_sentences</th>\n",
       "      <th>intxt_id</th>\n",
       "      <th>intxt_pmid</th>\n",
       "      <th>intxt_mark</th>\n",
       "      <th>citation</th>\n",
       "      <th>progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47218</td>\n",
       "      <td>PMC7236719</td>\n",
       "      <td>32840252</td>\n",
       "      <td>body</td>\n",
       "      <td>NoIMRaD</td>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>PMC7236719_sref21</td>\n",
       "      <td>32311448</td>\n",
       "      <td>21&gt;|sref21|</td>\n",
       "      <td>In view of the previously mentioned (prelimina...</td>\n",
       "      <td>34.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47222</td>\n",
       "      <td>PMC7236719</td>\n",
       "      <td>32840252</td>\n",
       "      <td>body</td>\n",
       "      <td>NoIMRaD</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>PMC7236719_sref21</td>\n",
       "      <td>32311448</td>\n",
       "      <td>21&gt;|sref21|</td>\n",
       "      <td>Thromboprophylaxis. Recommendations on prophyl...</td>\n",
       "      <td>51.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47230</td>\n",
       "      <td>PMC7236719</td>\n",
       "      <td>32840252</td>\n",
       "      <td>body</td>\n",
       "      <td>NoIMRaD</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "      <td>PMC7236719_sref21</td>\n",
       "      <td>32311448</td>\n",
       "      <td>21&gt;|sref21|</td>\n",
       "      <td>This is based on the preference for parenteral...</td>\n",
       "      <td>79.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47437</td>\n",
       "      <td>PMC7236820</td>\n",
       "      <td>32398297</td>\n",
       "      <td>body</td>\n",
       "      <td>NoIMRaD</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>PMC7236820_C9</td>\n",
       "      <td>32311448</td>\n",
       "      <td>9&gt;|C9|</td>\n",
       "      <td>The cumulative incidence of venous thromboembo...</td>\n",
       "      <td>16.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49287</td>\n",
       "      <td>PMC7239079</td>\n",
       "      <td>32511451</td>\n",
       "      <td>body</td>\n",
       "      <td>NoIMRaD</td>\n",
       "      <td>51</td>\n",
       "      <td>290</td>\n",
       "      <td>PMC7239079_R49</td>\n",
       "      <td>32291278</td>\n",
       "      <td>Kissler et al . 2020&gt;|R49|</td>\n",
       "      <td>More typical, however, is for R 0 to vary with...</td>\n",
       "      <td>17.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       pmcid      pmid location    IMRaD sentence_id  \\\n",
       "0       47218  PMC7236719  32840252     body  NoIMRaD          15   \n",
       "1       47222  PMC7236719  32840252     body  NoIMRaD          22   \n",
       "2       47230  PMC7236719  32840252     body  NoIMRaD          34   \n",
       "3       47437  PMC7236820  32398297     body  NoIMRaD           9   \n",
       "4       49287  PMC7239079  32511451     body  NoIMRaD          51   \n",
       "\n",
       "  total_sentences           intxt_id  intxt_pmid                  intxt_mark  \\\n",
       "0              43  PMC7236719_sref21    32311448                 21>|sref21|   \n",
       "1              43  PMC7236719_sref21    32311448                 21>|sref21|   \n",
       "2              43  PMC7236719_sref21    32311448                 21>|sref21|   \n",
       "3              53      PMC7236820_C9    32311448                      9>|C9|   \n",
       "4             290     PMC7239079_R49    32291278  Kissler et al . 2020>|R49|   \n",
       "\n",
       "                                            citation progression  \n",
       "0  In view of the previously mentioned (prelimina...       34.88  \n",
       "1  Thromboprophylaxis. Recommendations on prophyl...       51.16  \n",
       "2  This is based on the preference for parenteral...       79.07  \n",
       "3  The cumulative incidence of venous thromboembo...       16.98  \n",
       "4  More typical, however, is for R 0 to vary with...       17.59  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9369e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getnxml import get_nxml_from_pmcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936ecc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid2pmcid = {}\n",
    "pmid2pmcid[\"33930320\"] = \"PMC8078878\"\n",
    "pmid2pmcid['32311448'] = \"PMC7164881\"\n",
    "pmid2pmcid['32731257'] = \"PMC7581548\"\n",
    "pmid2pmcid['32839612'] = \"PMC7578095\"\n",
    "pmid2pmcid['33378609'] = \"PMC7787219\"\n",
    "pmid2pmcid['32416070'] = \"PMC7227586\"\n",
    "pmid2pmcid['32445440'] = \"PMC7262788\"\n",
    "pmid2pmcid['32841599'] = \"PMC7418704\"\n",
    "pmid2pmcid['32366695'] = \"PMC7199903\"\n",
    "pmid2pmcid['32291278'] = \"PMC7164482\"\n",
    "pmid2pmcid['32540903'] = \"PMC7299280\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93dcecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"sampled_res_30.json\", 'w') as f:\n",
    "#     json.dump(oa_paper_citations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d085726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMC9375576\n",
      "PMC8434920\n",
      "PMC9187102\n",
      "PMC9621022\n",
      "PMC9349458\n",
      "PMC8284046\n",
      "PMC8454213\n",
      "PMC8649466\n",
      "PMC9412348\n",
      "PMC9317287\n",
      "PMC8885466\n",
      "PMC9587126\n",
      "PMC8623766\n",
      "PMC8473168\n",
      "PMC9296083\n",
      "PMC8428325\n",
      "PMC8623604\n",
      "PMC8563977\n",
      "PMC9396110\n",
      "PMC8992638\n",
      "PMC8531069\n",
      "PMC9016488\n",
      "PMC8389568\n",
      "PMC8879968\n",
      "PMC8949184\n",
      "PMC8700804\n",
      "PMC8755369\n",
      "PMC8586723\n",
      "PMC9480732\n",
      "PMC8875598\n",
      "PMC8442752\n",
      "PMC9520447\n",
      "PMC7454798\n",
      "PMC9214161\n",
      "PMC7871721\n",
      "PMC9225593\n",
      "PMC8837491\n",
      "PMC9044512\n",
      "PMC8056322\n",
      "PMC9412042\n",
      "PMC8894812\n",
      "PMC7331864\n",
      "PMC7361754\n",
      "PMC7485709\n",
      "PMC7392617\n",
      "PMC8621119\n",
      "PMC7492826\n",
      "PMC7430069\n",
      "PMC8352775\n",
      "PMC7733673\n",
      "PMC7396456\n",
      "PMC7938644\n",
      "PMC7743107\n",
      "PMC9104617\n",
      "PMC7487272\n",
      "PMC9043882\n",
      "PMC7539230\n",
      "PMC8064159\n",
      "PMC7423832\n",
      "PMC8024143\n",
      "PMC9075903\n",
      "PMC7928010\n",
      "PMC8366622\n",
      "PMC8366625\n",
      "PMC8172228\n",
      "PMC8451603\n",
      "PMC8219099\n",
      "PMC8428573\n",
      "PMC9240059\n",
      "PMC8288147\n",
      "PMC8497464\n",
      "PMC8539008\n",
      "PMC8393506\n",
      "PMC8325333\n",
      "PMC7937514\n",
      "PMC8748674\n",
      "PMC8638770\n",
      "PMC7808328\n",
      "PMC8139703\n",
      "PMC8687884\n",
      "PMC9426593\n",
      "PMC7834972\n",
      "PMC8357629\n",
      "PMC8223959\n",
      "PMC8654298\n",
      "PMC9119307\n",
      "PMC8926328\n",
      "PMC7969912\n",
      "PMC9556142\n",
      "PMC8144958\n",
      "PMC8524637\n",
      "PMC9349213\n",
      "PMC8075028\n",
      "PMC8662225\n",
      "PMC8262502\n",
      "PMC7877310\n",
      "PMC9166226\n",
      "PMC9612296\n",
      "PMC9573230\n",
      "PMC9451097\n",
      "PMC8402925\n",
      "PMC9239116\n",
      "PMC8894356\n",
      "PMC8435761\n",
      "PMC8568958\n",
      "PMC8618556\n",
      "PMC8624180\n",
      "PMC8669038\n",
      "PMC9145451\n",
      "PMC8618284\n",
      "PMC8811947\n",
      "PMC8942849\n",
      "PMC8410055\n",
      "PMC8074524\n",
      "PMC8628512\n",
      "PMC8540328\n",
      "PMC8315069\n",
      "PMC8929698\n",
      "PMC8705082\n",
      "PMC8811630\n",
      "PMC8290372\n",
      "PMC9226983\n",
      "PMC9402447\n",
      "PMC8350975\n",
      "PMC8993078\n",
      "PMC8491895\n",
      "PMC9215841\n",
      "PMC9176697\n",
      "PMC8500299\n",
      "PMC9047227\n",
      "PMC8109204\n",
      "PMC8893246\n",
      "PMC8799714\n",
      "PMC9377515\n",
      "PMC8623509\n",
      "PMC8613264\n",
      "PMC9164443\n",
      "PMC8876225\n",
      "PMC8437699\n",
      "PMC8242561\n",
      "PMC9245563\n",
      "PMC8812364\n",
      "PMC8413252\n",
      "PMC8513403\n",
      "PMC8127950\n",
      "PMC9297000\n",
      "PMC9132351\n",
      "PMC9454633\n",
      "PMC8450283\n",
      "PMC8780073\n",
      "PMC7955763\n",
      "PMC9116414\n",
      "PMC8406741\n",
      "PMC8966731\n",
      "PMC9022977\n",
      "PMC8635865\n",
      "PMC8858956\n",
      "PMC8558639\n",
      "PMC8982434\n",
      "PMC8425443\n",
      "PMC9261903\n",
      "PMC9085217\n",
      "PMC7931055\n",
      "PMC8663850\n",
      "PMC8812869\n",
      "PMC8690910\n",
      "PMC7768267\n",
      "PMC7906979\n",
      "PMC8936487\n",
      "PMC9220273\n",
      "PMC8647662\n",
      "PMC8328275\n",
      "PMC7419602\n",
      "PMC8099704\n",
      "PMC9537957\n",
      "PMC7864945\n",
      "PMC7884845\n",
      "PMC8065320\n",
      "PMC7886129\n",
      "PMC7873370\n",
      "PMC9284529\n",
      "PMC8286829\n",
      "PMC8344477\n",
      "PMC8406741\n",
      "PMC7871226\n",
      "PMC9457067\n",
      "PMC8458001\n",
      "PMC8874841\n",
      "PMC9226470\n",
      "PMC8244650\n",
      "PMC8636940\n",
      "PMC8606629\n",
      "PMC7954552\n",
      "PMC8747159\n",
      "PMC8196270\n",
      "PMC8580554\n",
      "PMC8120990\n",
      "PMC8626754\n",
      "PMC7852167\n",
      "PMC9049514\n",
      "PMC9393547\n",
      "PMC9367483\n",
      "PMC8493324\n",
      "PMC8669856\n",
      "PMC8109186\n",
      "PMC7941637\n",
      "PMC9318242\n",
      "PMC9117775\n",
      "PMC9319826\n",
      "PMC7679035\n",
      "PMC8490018\n",
      "PMC8637828\n",
      "PMC9594980\n",
      "PMC8135853\n",
      "PMC8989122\n",
      "PMC8421091\n",
      "PMC9550860\n",
      "PMC8863906\n",
      "PMC8590475\n",
      "PMC9011732\n",
      "PMC8635972\n",
      "PMC8458794\n",
      "PMC8798691\n",
      "PMC8185188\n",
      "PMC9275729\n",
      "PMC8043452\n",
      "PMC7672574\n",
      "PMC8320097\n",
      "PMC7828525\n",
      "PMC8597642\n",
      "PMC7885913\n",
      "PMC8696472\n",
      "PMC9236659\n",
      "PMC8538289\n",
      "PMC9604950\n",
      "PMC9032924\n",
      "PMC8902888\n",
      "PMC8881326\n",
      "PMC8319916\n",
      "PMC9032413\n",
      "PMC8353666\n",
      "PMC8513636\n",
      "PMC8261716\n",
      "PMC8729800\n",
      "PMC9058402\n",
      "PMC9539805\n",
      "PMC7894318\n",
      "PMC9282386\n",
      "PMC8466820\n",
      "PMC7905038\n",
      "PMC8140746\n",
      "PMC7865145\n",
      "PMC8582233\n",
      "PMC8043454\n",
      "PMC7825899\n",
      "PMC8456623\n",
      "PMC7477106\n",
      "PMC7543629\n",
      "PMC7877779\n",
      "PMC8262170\n",
      "PMC8196891\n",
      "PMC9388967\n",
      "PMC9250814\n",
      "PMC8398183\n",
      "PMC9435400\n",
      "PMC8137902\n",
      "PMC7574254\n",
      "PMC8156887\n",
      "PMC9033091\n",
      "PMC8020978\n",
      "PMC9465520\n",
      "PMC7799106\n",
      "PMC8251678\n",
      "PMC8513629\n",
      "PMC8407866\n",
      "PMC8316696\n",
      "PMC7508557\n",
      "PMC8361246\n",
      "PMC7979159\n",
      "PMC8144838\n",
      "PMC8189449\n",
      "PMC7705849\n",
      "PMC7790451\n",
      "PMC8929656\n",
      "PMC7310630\n",
      "PMC8889828\n",
      "PMC9455844\n",
      "PMC9605950\n",
      "PMC7556502\n",
      "PMC7827929\n",
      "PMC8324827\n",
      "PMC8415352\n",
      "PMC7888632\n",
      "PMC7452887\n",
      "PMC8277363\n",
      "PMC7505695\n",
      "PMC7417187\n",
      "PMC8381858\n",
      "PMC7274133\n",
      "PMC8546681\n",
      "PMC8183521\n",
      "PMC9155146\n",
      "PMC8439218\n",
      "PMC8567933\n",
      "PMC7543487\n",
      "PMC8118541\n",
      "PMC8637828\n",
      "PMC8994590\n",
      "PMC7642679\n",
      "PMC8650110\n",
      "PMC8201996\n",
      "PMC8221499\n",
      "PMC7654894\n",
      "PMC7685319\n",
      "PMC7676675\n",
      "PMC9016638\n",
      "PMC7536878\n",
      "PMC8978934\n",
      "PMC8642242\n",
      "PMC8903276\n",
      "PMC8193764\n",
      "PMC8553742\n",
      "PMC8536561\n",
      "PMC7843981\n",
      "PMC9270183\n",
      "PMC7852275\n",
      "PMC7878817\n",
      "PMC8424621\n",
      "PMC8653399\n",
      "PMC9273039\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for ref_paper, citing_papers in oa_paper_citations.items():\n",
    "    if len(citing_papers) >= 20:\n",
    "        # ref_paper_pmcid = list(oa_file_list[oa_file_list[3] == 'PMID:' + ref_paper][2])[0]\n",
    "        ref_paper_pmcid = pmid2pmcid[ref_paper]\n",
    "        output_subfolder = os.path.join(output_folder, ref_paper_pmcid)\n",
    "        if not os.path.exists(output_subfolder):\n",
    "            os.mkdir(output_subfolder)\n",
    "        \n",
    "    \n",
    "        path = get_nxml_from_pmcid(ref_paper_pmcid)\n",
    "        generate_brat_data(path, \n",
    "                           os.path.join(output_subfolder, ref_paper_pmcid))\n",
    "\n",
    "        for citing_paper in citing_papers:\n",
    "            print(citing_paper)\n",
    "\n",
    "#             if citing_paper != '21219646': continue\n",
    "            citing_paper_pmcid = citing_paper\n",
    "#             print(ref_paper, citing_paper)\n",
    "            markers = citation_context[(citation_context['intxt_pmid'] == int(ref_paper)) & \n",
    "                                      (citation_context['pmcid'] == citing_paper)]['intxt_id']\n",
    "            surrounding_markers = citation_context[(citation_context['intxt_pmid'] == ref_paper) & \n",
    "                                      (citation_context['pmcid'] == citing_paper)]['intxt_mark']\n",
    "            markers = [m.split('_')[1] for m in set(markers)]\n",
    "#             print(markers)\n",
    "            citing_path = get_nxml_from_pmcid(citing_paper)\n",
    "            generate_brat_data(os.path.join(citing_path), \n",
    "                       os.path.join(output_subfolder, citing_paper_pmcid), markers, surrounding_markers)\n",
    "#             print((citing_paper_pmcid, citing_paper))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation_context[(citation_context['intxt_pmid'] == 33378609) & \n",
    "#                                       (citation_context['pmcid'] == 'PMC8513403')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(extract_data(get_nxml_from_pmcid(\"PMC7581548\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5069e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_subfolder = os.path.join('test')\n",
    "# citing_path = get_nxml_from_pmcid(\"PMC7654894\")\n",
    "# generate_brat_data(os.path.join(citing_path), \n",
    "#            os.path.join(output_subfolder, \"PMC7654894\"), \"PMC7654894_R23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3100eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = {'': [139, 1466, 0, 1467, 1943, 0, 1944, 2490, 0, 2491, 3666, 0, 3667, 4951, 0, 4952, 6399, 0, 6400, 7919, 0, 7920, 8369, 0, 8370, 10261, 0, 74448, 74477, 0], 'Baseline: no interventions': [10271, 11946, 0], 'Minimum number of cases': [12546, 13598, 0], 'Minimum intervention': [13599, 14629, 0], 'Minimum use of non-quarantine interventions': [14630, 15301, 0], 'Minimum quarantine': [15302, 15943, 0], 'Optimal interventions for four objectives': [11947, 15943, 1], 'Results': [10262, 15943, 1], 'Discussion': [15944, 20784, 0], 'Uncontrolled university model': [20794, 47500, 0], 'Equilibrium points': [47548, 47795, 0], 'Basic reproduction number': [47796, 49582, 0], 'Proposition 1': [49603, 49716, 0], 'Proof': [49717, 52174, 0], 'Stability analysis': [49583, 52174, 1], 'Analysis of the uncontrolled university model': [47501, 52174, 1], 'Formulation of the controlled university model': [52208, 69927, 0], 'Formulation of the optimal control problem': [69928, 71354, 0], 'Implementation of four different scenarios': [71355, 74420, 0], 'Control of the university model': [52175, 74420, 1], 'Methods': [20785, 74420, 1], 'Supplementary Information': [74421, 74477, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0fff693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"test.json\", 'w') as f:\n",
    "#     json.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40d975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(extract_data(get_nxml_from_pmcid(\"PMC7581548\"))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ca91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
