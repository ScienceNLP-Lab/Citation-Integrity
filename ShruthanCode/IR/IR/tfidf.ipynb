{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a75c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a2e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea6870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "nlp = spacy.load(\"en_core_sci_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e93898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy Tokenize the sentences of reference articles:\n",
    "# for file in os.listdir(\"Articles\"):\n",
    "#     if file.endswith('txt'):\n",
    "#         print(file)\n",
    "#         with open(f\"Articles/{file}\") as f:\n",
    "#             text = f.read()\n",
    "#             text = text[text.find('\\n')+2:]\n",
    "#             doc = nlp(text)\n",
    "#             sentences_all = [str(s) for s in list(doc.sents) if str(s) != '\\n\\n']\n",
    "#             sentences = []\n",
    "#             for s in sentences_all:\n",
    "#                 if \"references\" in s.lower():\n",
    "#                     break\n",
    "#                 sentences.append(s)\n",
    "#             sentences = [s.strip() for s in sentences if s.strip().count(' ') >= 2]\n",
    "            \n",
    "#         with open(f'Sentences/{file[:-4]}.json', 'w') as g:\n",
    "#             json.dump(sentences, g)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc5d5ab-357d-4ce1-b598-5bd6d314f3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shrut/Work/NewData/IR'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d106bfd1-41f8-4923-bb85-5a230482f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sent_context.json\") as f:\n",
    "    con = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d78409c3-50ef-4cf5-90d6-c559d9a652f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031_PMC7536538.txt\n",
      "036_PMC7225046.txt\n",
      "024_PMC7588823.txt\n",
      "029_PMC7906955.txt\n",
      "026_PMC7462354.txt\n",
      "040_PMC7144857.txt\n",
      "041_PMC7194244.txt\n",
      "022_PMC7328313.txt\n",
      "028_PMC7488216.txt\n",
      "032_PMC7675243.txt\n",
      "038_PMC7124956.txt\n",
      "023_PMC7604159.txt\n",
      "030_PMC7165103.txt\n",
      "025_PMC7173821.txt\n",
      "034_PMC8136807.txt\n",
      "035_PMC6954302.txt\n",
      "027_PMC7775777.txt\n",
      "039_PMC7239666.txt\n",
      "037_PMC7808278.txt\n",
      "033_PMC7267384.txt\n"
     ]
    }
   ],
   "source": [
    "# # Spacy Tokenize the sentences of reference articles:\n",
    "# for file in os.listdir(\"Articles\"):\n",
    "#     if file.startswith('0') and file.endswith('txt'):\n",
    "#         print(file)\n",
    "#         with open(f\"Articles/{file}\") as f:\n",
    "#             text = f.read()\n",
    "#             text = text[text.find('\\n')+2:]\n",
    "#             doc = nlp(text)\n",
    "#             sentences_all = [str(s) for s in list(doc.sents) if str(s) != '\\n\\n']\n",
    "#             sentences = []\n",
    "#             for s in sentences_all:\n",
    "#                 if \"references\" in s.lower():\n",
    "#                     break\n",
    "#                 sentences.append(s)\n",
    "#             sentences = [s.strip() for s in sentences if s.strip().count(' ') >= 2]\n",
    "        \n",
    "#         output_name = file[4:][:-4]\n",
    "#         with open(f'Sentences/{output_name}.json', 'w') as g:\n",
    "#             json.dump(sentences, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ac6283-6857-4056-960b-2aa585563c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in os.listdir(\"Articles\"):\n",
    "#     if file.startswith(\"0\"):\n",
    "#         new_name = file.split(\"_\")[1]\n",
    "#         os.rename(f\"Articles/{file}\", f\"Articles/{new_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c5b02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "def get_relevant_sentences(cs, num_tfidf=10):\n",
    "    global results\n",
    "\n",
    "    for pmcid in cs:\n",
    "        if pmcid.startswith('0'):\n",
    "            curr_ref_file = pmcid.split('_')[1]\n",
    "        else:\n",
    "            curr_ref_file = pmcid\n",
    "            \n",
    "        CURR_PMC = pmcid\n",
    "        \n",
    "\n",
    "        with open(f'Sentences/{curr_ref_file}.json') as f:\n",
    "            sentences = json.load(f)\n",
    "\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "        results[CURR_PMC] = {}\n",
    "        idx = 0\n",
    "        for file, d in cs[pmcid].items():\n",
    "            if len(d['support']) == 0:\n",
    "                continue\n",
    "            claim = con[pmcid][file]\n",
    "            idx += 1\n",
    "            \n",
    "            y = vectorizer.transform([claim])\n",
    "            cosine_similarities = linear_kernel(y, X).flatten()\n",
    "            related_docs_indices = cosine_similarities.argsort()[::-1]\n",
    "            current_sentences = []\n",
    "            for i in range(0, num_tfidf):\n",
    "                current_sentences.append(sentences[related_docs_indices[i]])\n",
    "            results[CURR_PMC][file] = current_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3130e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(cs, results):\n",
    "    def overlap(start, end, s, e):\n",
    "        return start <= e and s <= end\n",
    "\n",
    "    for pmcid in results:\n",
    "        if pmcid.startswith('0'):\n",
    "            curr_ref_file = pmcid.split('_')[1]\n",
    "        else:\n",
    "            curr_ref_file = pmcid\n",
    "        with open(f'Articles/{curr_ref_file}.txt') as f:\n",
    "            content = f.read()\n",
    "        for file in results[pmcid]:\n",
    "            indices = [[content.find(s.strip()), content.find(s.strip())+len(s.strip())] for s in results[pmcid][file]]\n",
    "            count = 0\n",
    "            support_indices = [[content.find(s.strip()), content.find(s.strip())+len(s.strip())] for s in cs[pmcid][file]['support']]\n",
    "            for start, end in support_indices:\n",
    "                for s, e in indices:\n",
    "                    if overlap(start, end, s, e):\n",
    "                        count += 1\n",
    "            cs[pmcid][file]['count'] = count\n",
    "    res = 0\n",
    "    total = 0\n",
    "    for pmcid in cs:\n",
    "        for file in cs[pmcid]:\n",
    "            if 'count' in cs[pmcid][file]:\n",
    "                res += (cs[pmcid][file]['count'] / len(cs[pmcid][file]['support']))\n",
    "                total += 1\n",
    "\n",
    "    return res/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea13b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recon_cs.json') as f:\n",
    "    cs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705982fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recon_cs_no_title.json') as f:\n",
    "    cst = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ae92bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Eugene_ContextAndSupport.json') as f:\n",
    "    cs1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ff54a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Eugene_ContextAndSupport_No_Title.json') as f:\n",
    "    cs2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c5177d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Degaulle_ContextAndSupport.json') as f:\n",
    "    cs3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b475f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Degaulle_ContextAndSupport_No_Title.json') as f:\n",
    "    cs4 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "700ce89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2552227342549923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs1)\n",
    "calculate_recall(cs1, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2380da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41884057971014493"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs2)\n",
    "calculate_recall(cs2, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f0060ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17680491551459293"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs1, 5)\n",
    "calculate_recall(cs1, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b97db12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2900966183574879"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs2, 5)\n",
    "calculate_recall(cs2, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "901acd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41779661016949154"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs3)\n",
    "calculate_recall(cs3, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0e02219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4401785714285715"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs4)\n",
    "calculate_recall(cs4, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "106dc4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43079399141630903"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs)\n",
    "calculate_recall(cs, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7114cf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5436241610738256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cst)\n",
    "calculate_recall(cst, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3933df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4141630901287553"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cs)\n",
    "calculate_recall(cs, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3095f16c-4d29-428b-ac08-3d40bbbb650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5221476510067116"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "get_relevant_sentences(cst)\n",
    "calculate_recall(cst, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42ba1e63-34bb-4d4d-8573-ce419cf12c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shrut/Work/NewData/IR'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c71f69-6548-48f8-9585-5a662f89426d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
